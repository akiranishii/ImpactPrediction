{"paper_id": "B0OwtVEejJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper effectively bridges the gap between gradient-based NAS methods and weight-entanglement, providing a novel and efficient approach for neural architecture search. The integration of these paradigms allows for efficient exploration, lower memory usage, and high performance across various search spaces. The empirical results are comprehensive and show a clear advantage over existing methods.", "Weaknesses": "While the method is promising, the paper may lack detailed analysis on scalability for even larger architectural spaces beyond those tested. Some architectural parameters and the zero-padding approach might be sensitive to certain hyperparameters or architectures, though this is not deeply explored.", "Questions": "How does TangleNAS handle very large search spaces, and what are the specific limitations in terms of scalability and computational overhead when compared to existing methods? Are there specific architectural types where TangleNAS might struggle relative to traditional approaches?"}}
{"paper_id": "ZlEtXIxl3q", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel application of contrastive loss functions in learning fitness functions affected by global epistasis, demonstrating improved efficiency and robustness.", "Weaknesses": "While the method shows promise, the paper could improve clarity in explaining the theoretical underpinnings of contrastive loss implications in global epistasis contexts.", "Questions": "How does the method perform under different types of nonlinearity, and are there specific scenarios where contrastive loss might not be optimal?"}}
{"paper_id": "6yJuDK1DsK", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a highly efficient approach to lifelong test-time adaptation that significantly reduces the number of parameters needing adaptation. FEATHER's method allows the source model to remain unchanged and does not require access to the source data, making it robust for real-world applications.", "Weaknesses": "While the method appears to work well across various benchmarks, the paper may benefit from a deeper exploration of potential limitations or edge cases where the approach might underperform.", "Questions": "How does FEATHER perform in settings with extreme domain shifts or very limited test data? Are there any specific types of models or domains where the approach might not be applicable or effective?"}}
{"paper_id": "lt6xKGGWov", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel feature selection method, MINERVA, that effectively captures complex non-linear dependencies using neural estimation of mutual information. The method shows improved accuracy over existing methods in synthetic benchmarks.", "Weaknesses": "The method has been tested primarily on synthetic datasets, which may not fully demonstrate its effectiveness on real-world data. Limited discussion on computational complexity and scalability of the approach.", "Questions": "How does MINERVA perform on large-scale real-world datasets compared to existing methods? What is the computational cost associated with using MINE for feature subsets, and how does this scale with the size of the dataset?"}}
{"paper_id": "Bvrc6kobWd", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel gradient-based analysis of the effects of margins in contrastive learning, offering new insights into the mechanism that underlies their effectiveness.", "Weaknesses": "The paper may lack extensive experimental validation beyond a limited set of datasets, and the theoretical arguments might be seen as not entirely exhaustive.", "Questions": "How does the proposed gradient-based perspective on margins compare quantitatively to previous methods in terms of convergence speed and overall performance in contrastive learning tasks?"}}
{"paper_id": "FJjHQS2DyE", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel framework called CASA that effectively addresses the label shift problem in unsupervised domain adaptation. The theoretical contributions are well-justified and supported by strong empirical results on benchmark datasets, demonstrating superiority over state-of-the-art methods.", "Weaknesses": "While the paper is strong, one potential weakness might be the complexity of the proposed method, which could be a barrier to adoption in practical settings without significant expertise. The applicability of CASA to more diverse or real-world datasets could also be explored further.", "Questions": "How does CASA perform in extended use cases such as domain generalization and universal domain adaptation, which are mentioned as future work?"}}
{"paper_id": "xelrLobW0n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark and methodology for evaluating continual learning in LLMs, addressing the gap in existing benchmarks. The TRACE benchmark is comprehensive, covering diverse and challenging tasks. The reasoning-augmented continual learning approach (RCL) effectively mitigates catastrophic forgetting, which is a significant contribution to the field.", "Weaknesses": "The paper may be limited by the complexity and computational cost associated with the TRACE benchmark and RCL approach. Additionally, the evaluation of new metrics may need further validation to ensure they accurately measure their intended outcomes.", "Questions": "How does the computational cost of using the RCL approach with the TRACE benchmark compare to existing continual learning baselines? Are there any plans to open source the TRACE benchmark and datasets for wider community use and validation?"}}
{"paper_id": "bYQkOPvgDw", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel probabilistic graphical model-based framework that handles noisy labels in GNNs without relying on the label smoothness assumption. It performs well across various noise types and rates, especially in high noise-rate situations, and is effective in both homophilous and heterophilous graphs.", "Weaknesses": "The presentation could be improved, as the methodology and the use of terms like ELBOs and contrastive loss might be complex for readers unfamiliar with these concepts.", "Questions": "How does the PRGNN framework handle different levels of prior knowledge in practice? Are there any specific limitations in scalability or computational cost associated with using two versions (PRGNN-v1 and PRGNN-v2)?"}}
{"paper_id": "sKPzAXoylB", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant challenge in continual learning by simultaneously tackling catastrophic forgetting and loss of plasticity with a novel approach. It demonstrates applicability across various datasets and reinforcement learning tasks.", "Weaknesses": "The paper could benefit from more extensive empirical evaluations and comparisons with a broader set of baseline methods to solidify the claims of superiority.", "Questions": "How does the UPGD method scale with larger, more complex datasets and architectures? Could the approach be adapted for tasks with explicit task boundaries, and what would be the potential limitations?"}}
{"paper_id": "H8Qg1IIMaR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper identifies a critical vulnerability in LLMs and VLLMs that is largely unexplored, providing valuable insights into their limitations in real-world applications. The experimental setup is thorough, testing across various models and datasets.", "Weaknesses": "The effectiveness of the proposed mitigation strategies is limited, and the paper does not offer novel solutions to enhance model robustness against permutation attacks.", "Questions": "What specific approaches could be developed to improve model robustness against such adversarial permutations in the future?"}}
{"paper_id": "tth2qXY7RU", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The proposed Super Floating-Point (SuFP) method shows excellent performance in maintaining or surpassing FP32 accuracy while significantly improving computational efficiency and energy usage. The method’s flexibility to adapt to varying data distributions and its efficient hardware implementation are notable strengths.", "Weaknesses": "The paper does not provide detailed analysis on potential limitations or edge cases where the SuFP method might not perform optimally, especially in comparison to emerging alternative quantization methods.", "Questions": "How does the SuFP quantization method scale with even larger models, and how does it perform with different outlier data distributions?"}}
{"paper_id": "fjf3YenThE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach by introducing a generalized variance-reduced zeroth-order hard-thresholding algorithm. The theoretical analysis is solid and supported by experimental validation, showcasing improved convergence rates over existing methods.", "Weaknesses": "The presentation could be improved for clarity, particularly in explaining the theoretical assumptions and how they apply to practical scenarios. Details about the computational complexity of the proposed algorithm compared to existing methods could also be more thoroughly discussed.", "Questions": "How would the algorithm perform in other high-dimensional optimization tasks beyond portfolio optimization and adversarial attacks? Are there any limitations concerning the types of datasets or specific applications where this approach may not be as effective?"}}
{"paper_id": "H9DYMIpz9c", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method, FARZI, which effectively summarizes large autoregressive datasets into smaller, synthetic sequences, maintaining or even improving model performance. The method demonstrates significant computational efficiency and openness for resource-efficient scaling of large models.", "Weaknesses": "The presentation of the method could be improved to enhance clarity, especially concerning the implementation details of the Hessian-Vector Products and the factorization process. Further experimental validation across a more diverse range of tasks could strengthen the evidence for broader applicability.", "Questions": "Can the FARZI method be extended to other types of tasks beyond autoregressive models? Are there any limitations concerning the types of datasets that FARZI can effectively distill?"}}
{"paper_id": "4kLVvIh8cp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant gap by providing a non-linear function approximation algorithm that offers instance-dependent regret guarantees, which is a novel contribution to the field of offline RL. The proposed PNLSVI algorithm is rigorously defined and shown to achieve statistically optimal performance with a tight dependency on function class complexity.", "Weaknesses": "The empirical evaluation is not detailed in the summary, leaving some uncertainty about the real-world application and performance of the algorithm in varied conditions beyond theoretical guarantees.", "Questions": "How does the PNLSVI algorithm perform empirically compared to existing methods in diverse and complex scenarios? What specific experiments were performed to validate the theoretical claims, and what were the results?"}}
{"paper_id": "CSpWgKo0ID", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper explores an under-examined area of LLM capabilities in social interactive settings using a structured approach from game theory. It provides insights into LLM strategies in different types of games and suggests methods for improving coordination capabilities.", "Weaknesses": "The study may lack sufficient diversity in game types and scenarios to fully generalize its findings. Additionally, the reliance on specific LLMs like GPT-4 might limit broader applicability.", "Questions": "How do the findings change with different LLM architectures or configurations? Can the proposed modifications to improve coordination truly align LLM behaviors with human social interaction goals in varied real-world contexts?"}}
{"paper_id": "gwbQ2YwLhD", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides theoretical insights and empirical evidence on how scale affects the performance of DAG structure learning algorithms. It extends existing knowledge to high-dimensional and non-linear settings, which is a significant contribution to the field.", "Weaknesses": "The presentation could be improved for clarity, as some theoretical explanations are dense and might be difficult for readers unfamiliar with the technical details. Additionally, while the paper discusses scale issues, it could further explore practical guidelines for normalization and handling free variances.", "Questions": "How do the authors suggest practitioners implement normalization techniques in practice? Are there specific recommendations for dealing with scale in various real-world scenarios?"}}
{"paper_id": "eIYDKNqXuV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The proposed Village-Net Clustering method is innovative in combining K-Means with community detection for handling complex datasets. It offers significant improvements in computational efficiency and scalability.", "Weaknesses": "The accuracy of the method is limited by the initial K-Means step, and there is a need for iterative refinement for improved cluster representation. The paper may require more detailed comparisons with similar methods in terms of accuracy.", "Questions": "How does Village-Net Clustering perform with datasets that have a very high number of clusters? Are there any scenarios where the method underperforms compared to existing techniques?"}}
{"paper_id": "bAMPOUF227", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel framework that successfully integrates task-specific supervised knowledge into LLMs for enhanced performance in OOD scenarios. The use of 16 curated datasets across 9 tasks and the combination of zero-shot and few-shot experiments provide strong empirical support for the proposed method's effectiveness.", "Weaknesses": "The framework's reliance on specific SLMs for task performance might limit generalizability to new or unanticipated tasks where suitable SLMs are unavailable. Additionally, the computational resources required for integrating multiple models during inference could be a practical limitation.", "Questions": "How does the method perform when there is minimal or no prior task-specific data to fine-tune the SLMs? Are there plans to open-source the framework for broader evaluation?"}}
{"paper_id": "eNoiRal5xi", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces UDIM, a novel framework combining parameter and data space perturbations to enhance domain generalization, showing statistically significant improvements over existing methods.", "Weaknesses": "The theoretical guarantees for the method may need further validation, specifically in cases outside the evaluated benchmarks.", "Questions": "How does UDIM perform on datasets with extremely sparse domain information compared to traditional methods?"}}
{"paper_id": "uU0Adp7Sfo", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel collaborative-competitive framework (CCGAN) that successfully addresses the limitations of traditional GANs in multi-modal data generation by introducing a regularization scheme. It demonstrates both theoretical and empirical improvements over baseline models. The experimental results are comprehensive and validate the enhanced performance of the proposed model in generating images of regularly shaped objects.", "Weaknesses": "The paper might be lacking in discussion regarding the potential limitations or trade-offs introduced by the collaborative aspect of the framework. Additionally, insights into how CCGAN performs across a broader range of datasets or applications might be constrained.", "Questions": "How does the introduction of the regularization term specifically influence the training stability, and are there any potential downsides in terms of computational complexity? Are there any applications where CCGAN might not perform well compared to traditional GANs?"}}
{"paper_id": "dKju7tbe6D", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel approach that integrates both iterative and parallel computations, leading to improved efficiency and generalizability. It outperforms existing models on several benchmarks, demonstrating state-of-the-art performance, particularly in zero-shot and transfer learning tasks. The method is tested rigorously against competitive baselines.", "Weaknesses": "The paper does not address potential computational overhead in scenarios with extremely large datasets or complex reasoning tasks. Further, it might benefit from a deeper exploration of limitations or failure cases of the proposed IPRM.", "Questions": "How does IPRM handle extremely complex scenes compared to a purely iterative or purely parallel approach? Are there specific cases where IPRM struggles, and how can those be addressed?"}}
{"paper_id": "DL7JWbdGr3", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach by incorporating pre-trained transformer-based models for epidemic time-series forecasting, significantly improving over state-of-the-art methods in terms of accuracy and adaptability. It leverages diverse datasets and self-supervised learning tasks, showcasing strong results and real-world applicability.", "Weaknesses": "While the study demonstrates remarkable improvements, it may focus heavily on the technical details of model training and evaluation, potentially overlooking broader implications or limitations in specific real-world scenarios.", "Questions": "How well does the model perform in low-data settings where historical data may be sparse? Also, can the approach be easily adapted to related fields outside of epidemic forecasting?"}}
{"paper_id": "1PaDPHDhwe", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a simple yet effective post-processing technique that improves both robust and average accuracies across various datasets. It does not require additional training, making it computationally efficient. The introduction of a novel evaluation metric adds value to the analysis of debiasing algorithms.", "Weaknesses": "The paper may lack detailed analysis on the scalability of the proposed method and its applicability to a wide range of model architectures. The trade-off analysis, while comprehensive, might not account for all possible biases across different domains.", "Questions": "How does the class-specific scaling method perform on models with high initial bias toward specific classes? Are there any situations where this technique might worsen performance?"}}
{"paper_id": "iI7hZSczxE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The proposed method, DIOSC, effectively addresses the challenge of disentangling correlated attributes in time series data. Introducing independence-of-support via contrastive learning, combined with attentive l-variational inference, offers significant improvements in generalization and interpretability, which is demonstrated through substantial performance gains.", "Weaknesses": "The paper could improve its clarity in presenting the implementation details of DIOSC. Additionally, more comprehensive evaluations across diverse datasets beyond NILM would strengthen the claims regarding the method's applicability and robustness.", "Questions": "How does the proposed Time Disentangling Score (TDS) compare against other metrics in assessing disentanglement? Are there specific scenarios where DIOSC might struggle compared to traditional methods?"}}
{"paper_id": "qrGjFJVl3m", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a well-designed series of vision-language models with superior performance in multilingual and fine-grained visual understanding tasks. The methodology, including a three-stage training pipeline and diverse dataset utilization, is comprehensive and robust.", "Weaknesses": "The paper may lack empirical comparisons with proprietary models, which could provide a more complete evaluation of Qwen-VL's competitive standing. Additionally, details on how well the models generalize to untested real-world scenarios could be expanded.", "Questions": "How do the Qwen-VL models perform on proprietary benchmarks used by industry leaders? Are there plans to incorporate additional modalities beyond vision and language, such as speech, in future iterations of the model?"}}
{"paper_id": "qup9xD8mW4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel method, HaDES, that effectively adapts dataset distillation to reinforcement learning by synthesizing small datasets of state-action pairs using evolutionary strategies. The approach is validated across a range of environments and tasks, demonstrating its generalization and efficiency.", "Weaknesses": "The paper does not deeply explore potential limitations of HaDES, such as scalability in more complex RL environments or the sensitivity of the method to different hyperparameters during its application.", "Questions": "How does HaDES perform when applied to more complex RL environments such as those with higher-dimensional state spaces? Is the method sensitive to the choice of initial parameters or hyperparameters during optimization?"}}
{"paper_id": "Zw8YxUWL4R", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel conditioning space, P+, which enhances control and expressiveness in text-to-image synthesis. The proposed method, XTI, improves upon existing techniques like Textual Inversion and DreamBooth, providing better reconstruction quality and faster convergence.", "Weaknesses": "The paper could benefit from clearer explanations and visualizations of how P+ tokens are specifically used within the architecture to aid understanding. Additionally, more quantitative comparisons against baseline methods across varied datasets would strengthen the findings.", "Questions": "How does the proposed method perform on more complex prompts or in different domains beyond the initial experiments? Are there any limitations regarding computational efficiency with the introduction of multiple per-layer tokens?"}}
{"paper_id": "3NXhwkZGjz", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses the privacy concerns associated with using labeled source data in domain adaptation tasks by proposing a method that only uses a pre-trained source model and unlabeled target data. The method enhances pseudo-label reliability and achieves state-of-the-art performance in SFUDA tasks, which is a significant contribution.", "Weaknesses": "The complexity of the method could limit its accessibility to practitioners who are not familiar with GradCAM and semi-supervised learning techniques. Additionally, the reliance on pre-trained models could pose a limitation in scenarios where such models are not readily available.", "Questions": "How does the method perform when the pre-trained model is not well-suited to the target domain due to significant domain shifts? Can the method be effectively adapted to scenarios with limited computational resources?"}}
{"paper_id": "Fn655mJ4bv", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method, SOInter, which effectively interprets structured output models by incorporating output correlations. It demonstrates improved explanation quality and computational efficiency in experiments compared to existing techniques.", "Weaknesses": "The presentation could benefit from clearer articulation of complex concepts and the Gumbel-Softmax trick's application. More comprehensive comparisons with a wider array of interpretation methods could strengthen the evaluation.", "Questions": "How does the method perform with different types of structured output models beyond those tested? Are there any limitations in specific domains or settings where SOInter might not be applicable or effective?"}}
{"paper_id": "VyMW4YZfw7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper challenges the complexity of modern GNNs and proposes a simpler alternative using spectral methods, which could simplify model explainability and analysis. It also raises awareness of how changes in evaluation standards might affect performance comparisons.", "Weaknesses": "The paper may lack novelty for those deeply familiar with both spectral methods and GNNs. Additionally, while the results are competitive, they might not be compelling enough to encourage a paradigm shift away from more sophisticated GNN methods.", "Questions": "How does the proposed method perform on larger, more diverse datasets not covered in the paper? Are there specific cases where the proposed simpler methods fail compared to complex GNNs?"}}
{"paper_id": "09xFexjhqE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces AutoLoRa, a novel method that effectively separates natural and adversarial objective optimization in RFT through a low-rank branch, thereby enhancing adversarial robustness and reducing sensitivity to hyperparameters.", "Weaknesses": "The paper may not fully explore the limitations of the proposed AutoLoRa method, particularly in terms of computational overhead or complexity introduced by the low-rank branch.", "Questions": "How does the AutoLoRa method perform compared to other state-of-the-art RFT methods in terms of computational efficiency and speed? Are there specific scenarios where the method's performance might degrade?"}}
{"paper_id": "nmBjBZoySX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper introduces a novel approach for uncovering Graph Lottery Tickets within GNNs using an Adaptive, Dynamic, and Automated framework, which significantly contributes to addressing the current limitations in scalability and flexibility of existing GLT methods. Theoretical proofs and extensive experimental validation support the effectiveness and superiority of the method over state-of-the-art approaches.", "Weaknesses": "The paper might need to present more extensive ablation studies to thoroughly establish the contribution of each component in the AdaGLT framework. Furthermore, there could be more clarity on the computational overhead introduced by the layer-adaptive and dynamic workflow mechanisms.", "Questions": "What are the computational trade-offs or overheads introduced by the dynamic pruning and restoration processes in AdaGLT, particularly in large-scale applications?"}}
{"paper_id": "di52zR8xgf", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a significant enhancement over existing open generative models by introducing SDXL, which features a larger architecture and novel conditioning schemes that contribute to its competitive performance with state-of-the-art black-box models like Midjourney. It also offers transparency and reproducibility benefits.", "Weaknesses": "While the model shows substantial improvements, it still suggests the need for future work in areas like single-stage generation and the incorporation of additional text synthesis improvements. There might also be concerns about the computational resource requirements due to the larger model size.", "Questions": "How does the computational complexity and resource usage of SDXL compare to the state-of-the-art black-box models? Are the enhancements universally applicable across different visual domains or are there limitations?"}}
{"paper_id": "0b328CMwn1", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach, activation prompts (AP), that enhances the performance and efficiency of existing visual prompting methods. It connects AP to normalization tuning and provides extensive experimentation across 29 datasets, highlighting its practical impact and depth of analysis.", "Weaknesses": "The performance gap between AP and traditional fine-tuning methods is mentioned but not fully explored. It would be beneficial to understand more deeply why AP performs better and under what specific circumstances.", "Questions": "How does the choice of layer depth in different models specifically impact the performance of AP? Are there particular task types or datasets where AP consistently underperforms compared to other methods?"}}
{"paper_id": "AMDKqZcZbi", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach by integrating biologically inspired architectures into machine learning models. It effectively addresses the problem of catastrophic forgetting and demonstrates the model's superior performance over baseline methods in both continual and few-shot learning contexts.", "Weaknesses": "The paper might rely heavily on the analogy with biological systems without providing extensive experimental validation across diverse datasets beyond the proposed sWM scenarios.", "Questions": "How does the proposed model perform when applied to tasks outside the designed sWM, especially on more complex and larger scale datasets? Are there any specific limitations in scaling the model inspired by biological systems?"}}
{"paper_id": "am7BPV3Cwo", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to addressing the issue of class imbalance in OOD detection, which is a significant gap in existing literature. The proposed ImOOD framework shows a strong performance improvement on standard benchmarks.", "Weaknesses": "The presentation could be clearer, particularly in explaining the technical details of the post-hoc normalization and training-time regularization. Additionally, the paper might benefit from more detailed analysis of when the method could potentially fail.", "Questions": "How does the performance of ImOOD compare in scenarios with varying degrees of imbalance? Are there specific types of imbalance where the improvement is more pronounced?"}}
{"paper_id": "R1crLHQ4kf", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel and efficient method for detecting adversarial attacks in ASR systems by leveraging statistical properties of output token distributions. The method achieves high accuracy across different systems and is robust against certain adaptive attacks.", "Weaknesses": "The presentation could be improved for clarity, particularly in how the statistical measurements are explained and the classifier choices justified. Additionally, the approach's performance against highly sophisticated adaptive attacks is not fully explored.", "Questions": "How does the proposed method perform under real-world conditions and with more complex adaptive attacks? What are the computational overheads associated with the implemented detection mechanisms?"}}
{"paper_id": "i7P2mK3x3o", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a notable gap in flow-based models by directly computing a dynamic optimal transport map between arbitrary distributions, supported by a proposed model that demonstrates strong empirical performance in high-dimensional tasks.", "Weaknesses": "Details on the specific limitations of the Q-flow model, or potential scalability issues in extremely high-dimensional applications, are not extensively discussed.", "Questions": "How does the model's performance scale with dimensionality, particularly beyond the tasks demonstrated? Are there specific scenarios where the Q-flow model fails to find an accurate transport map?"}}
{"paper_id": "YIls9HEa52", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper introduces a novel model, irSLDS, that overcomes limitations of traditional rSLDS by incorporating flexible state cardinality and latent geometric structures. The model is validated on real and synthetic data, demonstrating its ability to uncover non-stationary processes in neural data effectively. The computational methods employed, including the PDE framework, enhance inference performance.", "Weaknesses": "The complexity of the model might limit its accessibility to researchers not familiar with advanced probabilistic models and PDEs. The paper does not extensively discuss potential limitations or areas where the model might struggle in comparison to alternative approaches.", "Questions": "How does the irSLDS model perform relative to other state-of-the-art models in terms of computational efficiency and scalability with very large datasets? Are there specific types of datasets where the model might underperform due to its assumptions?"}}
{"paper_id": "koYsgfEwCQ", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach, DynaVol, which effectively addresses unsupervised 3D dynamic scene decomposition by capturing the 3D nature of scenes. It outperforms existing methods and shows potential for downstream tasks like scene editing.", "Weaknesses": "The complexity of the model and training process might limit accessibility to researchers with less resources. Presentation could be improved for clarity and accessibility.", "Questions": "How does DynaVol perform in real-time scenarios? Are there limitations in scalability for larger scenes with more objects?"}}
{"paper_id": "o6AN2ZoNw2", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel and effective approach to open-vocabulary semantic segmentation that does not rely on large pre-trained models or annotated masks, achieving state-of-the-art results. The use of a pseudo-mask generator and language supervision for training a MaskFormer model is innovative and scalable.", "Weaknesses": "The paper may lack detailed comparison with alternative methods that use similar self-supervised techniques. Additional clarity in the presentation of the method and results could further enhance understanding.", "Questions": "How does the performance of P-Seg compare to other contemporary methods that also utilize language supervision in segmentation tasks?"}}
{"paper_id": "HXZK1Z8tHa", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper introduces an innovative approach to Transformer-based image restoration, focusing on reducing computational overhead and improving trainability. The ShareFormer model shows state-of-the-art performance across multiple benchmarks, balancing speed and accuracy. The methodology is sound and well-justified, with extensive evaluations against existing methods.", "Weaknesses": "The complexity of the approach might make implementation challenging for practitioners who are not familiar with advanced Transformer architectures. The paper could provide more insight into the limitations and potential drawbacks of the proposed method.", "Questions": "How does the performance of ShareFormer compare with CNN-based methods for specific applications such as denoising? Are there any scenarios where ShareFormer does not perform as well compared to existing methods?"}}
{"paper_id": "QO3yH7X8JJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses the significant gap in arbitrary-scale super-resolution by introducing a novel method that leverages pre-trained diffusion models without the need for additional fine-tuning, saving computational resources. The results are validated through extensive experiments demonstrating superior performance and adaptability across various datasets.", "Weaknesses": "The paper relies heavily on pre-trained models, which assumes the availability of such models for different application scenarios. There might be limitations if models need to be specifically trained for domains not covered by existing pre-trained models.", "Questions": "How does the method perform in comparison to architecture-specific DGMs when applied to specific real-world applications such as medical imaging or satellite photo resolution enhancement?"}}
{"paper_id": "sNtDKdcI1f", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses an important gap in the understanding of reward model biases in Reinforcement Learning from Human Feedback by providing empirical evidence that models excessively optimize for length. It also systematically evaluates interventions to mitigate this effect across multiple datasets.", "Weaknesses": "The study may not fully capture all aspects of language model improvement beyond output length. The interventions to adjust for length biases might be limited in scope, and more exploration may be needed to generalize findings across diverse RLHF applications.", "Questions": "How do the proposed interventions affect the qualitative aspects of language model responses beyond length? Are there specific types of language tasks where length bias significantly alters model performance perceptions?"}}
{"paper_id": "HFtrXBfNru", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The proposed method, SMART, effectively addresses the challenge of estimating temporal generalization in evolving graphs by using self-supervised learning. It shows strong empirical results across both synthetic and real-world datasets, and the methodology of using graph reconstruction techniques is well-founded.", "Weaknesses": "The presentation could be improved for better clarity, particularly in explaining the technical details of the self-supervised learning approach and theoretical bounds. Further comparisons with baseline models could strengthen the claims.", "Questions": "How does SMART compare with baseline models in terms of computational efficiency? Are there any limitations of SMART when dealing with extremely large-scale graphs?"}}
{"paper_id": "4u0ruVk749", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method using diffusion models to handle unobserved confounders in causal inference, demonstrating superior performance in ITE estimation over existing models.", "Weaknesses": "Limited discussion on the computational cost and practical implementation details for using diffusion models in large-scale real-world datasets.", "Questions": "How does the method perform in terms of computational efficiency compared to traditional methods? Are there specific domains where this approach might struggle?"}}
{"paper_id": "Pa6SiS66p0", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an under-explored gap in multi-modal continual learning and proposes a novel method leveraging multi-modal data to mitigate catastrophic forgetting in DNNs. It also establishes a new benchmark and demonstrates improvements over baseline methods.", "Weaknesses": "While the approach is promising, the paper lacks comprehensive analysis on why specific multi-modal integrations work better, and there might be limitations in generalizing the results beyond the VGGSound dataset and settings.", "Questions": "How does the method perform on other datasets not included in the study? What are the computational costs associated with maintaining modality-specific representations?"}}
{"paper_id": "rkplYfqUr0", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a significant issue in the robustness of language model prompting and proposes a strong methodological framework, GEN-Z, that shows improved performance over existing baselines. The use of generative methods for text classification is innovative, and the empirical results across multiple tasks and models demonstrate the approach's effectiveness.", "Weaknesses": "The manual crafting of label descriptions and reliance on ChatGPT for paraphrasing may limit the framework's applicability and scalability. The paper could also provide more detail on the challenges encountered and mitigation strategies during the manual process.", "Questions": "How does GEN-Z compare to other state-of-the-art methods on tasks not covered in the paper? Are there automated ways to generate label descriptions without manual intervention?"}}
{"paper_id": "pTU2X9mUBe", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces LaDe, a large-scale and diverse dataset for last-mile delivery research, filling a significant gap in the field by addressing the limitations of existing datasets. It demonstrates the dataset's utility through comprehensive benchmarking on various relevant tasks.", "Weaknesses": "The presentation could provide more detailed explanations of the baseline models used for validation and possibly explore a broader range of tasks beyond the ones benchmarked.", "Questions": "How do the authors plan to maintain and update the LaDe dataset over time to ensure its continued relevance and utility for evolving research needs?"}}
{"paper_id": "uhtQyRrTzY", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel data-curation method (MIMIC) that leverages unannotated real-world videos and synthetic environments to generate large-scale multi-view datasets useful for dense vision tasks. The approach is scalable and outperforms models trained on traditional annotated datasets, showcasing significant improvements in dense prediction tasks.", "Weaknesses": "The reliance on computer vision techniques like SIFT and RANSAC might limit the method’s applicability if these techniques become outdated. Additionally, it is unclear how well the datasets generalize across different types of dense vision tasks without extensive experimentation.", "Questions": "How does the performance of models trained with MIMIC compare on a wider range of dense vision benchmarks beyond those presented? Are there any limitations in terms of data diversity or types of scenes that MIMIC can effectively process and utilize?"}}
{"paper_id": "WZfatbNdLV", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces the innovative TrASPr model, which significantly outperforms existing models in predicting tissue-specific splicing, offering a novel approach with practical applications in RNA splicing design.", "Weaknesses": "The presentation could be improved to enhance clarity, especially regarding the complex methodologies and datasets utilized, as well as the comparison metrics with existing models.", "Questions": "How well does the TrASPr model generalize to splicing events not present in the training dataset, and can TrASPr be adapted to predict splicing outcomes in non-mammalian systems?"}}
{"paper_id": "YkRwadXWHd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel multi-modal framework for continuous sign language recognition that significantly improves performance by integrating video, keypoints, and optical flow. It introduces a hierarchical knowledge distillation method to reduce computational costs effectively. The approach demonstrates state-of-the-art results on multiple datasets.", "Weaknesses": "The paper might have increased complexity due to the integration of multiple modalities, which could pose challenges in real-world deployment. The specifics of the computational savings are not fully detailed.", "Questions": "How does the proposed method perform in real-time scenarios? Are there plans to test the model in more diverse environmental settings to gauge its robustness?"}}
{"paper_id": "q4Bim1dDzb", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The UniVoxel framework introduces a novel approach by unifying the modeling of geometry, materials, and illumination, significantly reducing the computational resources required compared to existing methods. It effectively integrates illumination modeling with Spherical Gaussians, showing robustness across diverse lighting conditions.", "Weaknesses": "The approach may still rely on certain assumptions about scene complexity that might not hold in all real-world scenarios. Limited information is provided on how it generalizes to unforeseeable illumination variance.", "Questions": "How does UniVoxel perform in scenarios with highly dynamic lighting changes? Could there be a comparative analysis with more diverse datasets in future work?"}}
{"paper_id": "39cPKijBed", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method for time-dependent importance reweighting in diffusion models, addressing dataset bias issues effectively. The theoretical framework is sound and the method is validated with robust experimental results across multiple datasets.", "Weaknesses": "The paper may not address potential computational overhead introduced by the time-dependent approach. Further analysis on the scalability of the method to larger datasets or more complex models could strengthen the claims.", "Questions": "How does the time-dependent reweighting approach perform when applied to more complex or larger-scale datasets? Are there any specific computational challenges involved in implementing this approach?"}}
{"paper_id": "aG3EARrrd1", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes the OSRT model, which dynamically and appropriately expands and refines network components, providing improved efficiency over traditional RBF and hybrid methods. The model's adaptive and incremental approach to handling streaming data is innovative and appears to be well-validated by experimental results.", "Weaknesses": "While the paper presents a compelling model, the presentation could be improved to better convey complex concepts, particularly for readers less familiar with RBF and tree-based integration. Additionally, more details on the computational complexity and scalability of the model with extremely large datasets would be beneficial.", "Questions": "How does the OSRT model perform in real-world applications beyond the benchmark datasets like Mackey-Glass and Lorenz time series? Could you provide more comparison details with state-of-the-art methods in a broader range of application domains?"}}
{"paper_id": "Ts95eXsPBc", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach by integrating spatial information into episodic memory models, which enhances their efficiency and accuracy in a variety of tasks.", "Weaknesses": "The presentation could be improved, particularly in terms of clarity and detail when explaining technical implementations.", "Questions": "How does the Adaptive Memory Allocator specifically influence performance across different environments and tasks?"}}
{"paper_id": "LfhG5znxzR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a key gap in neural network interpretability by introducing a novel method that enhances interpretability and control through sparse and discrete bottlenecks. It offers a practical approach to achieve these qualities without significant performance loss, validated through experiments on various datasets.", "Weaknesses": "The paper could provide more in-depth analysis of the trade-offs between increased interpretability and any potential impacts on model flexibility or generalization. Further comparisons with existing interpretability methods may also strengthen the claims.", "Questions": "How do the introduced codebook features scale with large-scale models and more complex datasets? Are there specific domains or tasks where this approach might be less effective?"}}
{"paper_id": "bUGzjiUsIq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel PAPG framework that addresses the challenges of partially annotated multi-label classification effectively. It integrates reinforcement learning and supervised learning to improve performance. The approach demonstrates significant improvements in F1 scores and other metrics across different datasets and domains.", "Weaknesses": "The paper may lack detailed comparison with a broader range of baseline methods. In addition, there might be a need for more comprehensive evaluation or ablation studies to fully understand the contribution of each component of the PAPG framework.", "Questions": "How does PAPG perform in extremely large-scale datasets? Are there any limitations regarding computational requirements for the proposed method?"}}
{"paper_id": "uMAujpVi9m", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant bottleneck in protein-ligand modeling by creating a novel pretraining approach that improves on the data scarcity issue. ProFSA's ability to outperform existing methods on key tasks demonstrates its effectiveness.", "Weaknesses": "While the method is innovative, the presentation of results could be clearer, especially regarding how results compare across baseline methods.", "Questions": "How does the performance of ProFSA scale with the size of the pseudo-complex dataset, and is there an optimal size for this dataset?"}}
{"paper_id": "uqxBTcWRnj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to bridging the gap between neural and symbolic representations, which is a vital area of research in integrating AI systems. The Transitional Dictionary Learning framework is innovative, and the proposed evaluation metrics provide a new lens on symbolic interpretability. The method outperforms existing techniques in unsupervised part segmentation, demonstrating strong experimental results.", "Weaknesses": "The paper might lack in-depth theoretical analysis to support the empirical findings fully. A direct comparison to a broader set of baseline models could strengthen the claims. The proposed approach relies on specific architectural choices that may not generalize to other types of data outside the tested datasets.", "Questions": "How does the TDL framework handle cases where visual input does not have a clear compositional structure? Are there limitations in the types of symbolic knowledge that can be derived using this model?"}}
{"paper_id": "o4CLLlIaaH", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel point-based rendering approach to overcome the challenges in existing NeRFs, presenting significant advancements in rendering quality, geometry accuracy, and scene interactivity. It addresses key issues like occlusions and feature inconsistencies effectively.", "Weaknesses": "The paper could provide more detailed analysis on computational costs and practical limitations of the proposed method in real-world scenarios.", "Questions": "How does the proposed point-based approach handle extremely complex scenes with high occlusion levels, and are there any specific limitations in such scenarios?"}}
{"paper_id": "KNzL1nglNB", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative approach by extending ERM with Label-encoding Risk Minimization, effectively leveraging unlabeled data to maintain prediction diversity and discriminability. Theoretical analysis and extensive experimental validation across various challenging domains enhance its credibility.", "Weaknesses": "The presentation could be improved for better clarity, especially in explaining complex concepts such as neural collapse and its integration with LRM. Some technical details could be more elaborated to ensure easier reproducibility of results.", "Questions": "How does the LRM approach scale with extremely large unlabeled datasets in practice? Are there any specific limitations or assumptions that might hinder its applicability in certain domains beyond those tested?"}}
{"paper_id": "pvhyBB86Bt", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an important gap by extending the analysis of Jacobian stability from initialization to include the training phase, using novel applications of random matrix theory. The results are both theoretically sound and practically relevant, enhancing understanding of DNN training dynamics.", "Weaknesses": "The paper might lack clarity in some sections, which could make it difficult for readers not familiar with advanced random matrix theory to fully grasp the contributions. The investigation may benefit from more empirical validation across diverse network architectures.", "Questions": "How does the proposed stability theorem generalize to architectures beyond MLPs, such as CNNs or RNNs? Are there specific limitations when applying the findings to real-world deep learning tasks?"}}
{"paper_id": "Mylk5iamJC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The proposed Latent Gaussian Mixture Model (L-GMM) effectively combines generative and discriminative modeling, offering a unified approach to address both closed-set and open-set recognition problems. The method demonstrates superior performance in both CSR and OSR tasks when compared to existing specialized methods.", "Weaknesses": "The paper may require more extensive comparisons with alternative methods across diverse datasets to comprehensively validate the approach. Additionally, the technical details of the collaborative training algorithm might be challenging for some readers to fully grasp.", "Questions": "How does the computational complexity of the L-GMM model compare to traditional discriminative models, particularly during inference? Are there specific types of unknown classes or scenarios where the model's performance degrades?"}}
{"paper_id": "MsOcVFzv8D", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant gap in multi-domain text classification by providing a robust theoretical foundation through margin discrepancy. The proposed MDAT method outperforms current state-of-the-art methods, demonstrating strong empirical results and offering new theoretical insights.", "Weaknesses": "The integration of theoretical components with practical algorithm development could be more thoroughly discussed. Additionally, more details on the limitations of the proposed method would strengthen the paper.", "Questions": "How does the proposed method handle domains with extreme scarcity of labeled data compared to other domains? Are there specific cases where the MDAT approach may not perform as effectively?"}}
{"paper_id": "fBlHaSGKNg", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to enhancing SSL by focusing on efficient sample selection for annotation under budget constraints. The UPA method shows significant improvements in SSL performance across different datasets and frameworks, demonstrating its potential for practical applications.", "Weaknesses": "While the methodological innovation is strong, the presentation could benefit from clearer explanations of the implementation details and more comprehensive comparisons with a broader range of baseline methods.", "Questions": "How does the performance of UPA vary with different values of the budget constraints, and are there any scenarios where traditional methods outperform UPA?"}}
{"paper_id": "HwQ8NVvdmm", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to integrating fully quantized training with continual learning, achieving minimal accuracy loss while significantly improving computational efficiency for edge applications.", "Weaknesses": "While the method shows promise, the evaluation could benefit from a broader range of datasets and comparison with more varied baseline methods. There is also limited discussion on the potential limitations of the approach.", "Questions": "How does the method perform on tasks outside of HAR and CIFAR100? Are there scenarios where the quantization approach might not be effective?"}}
{"paper_id": "cZo6pDtDZr", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces two novel algorithms for estimating collision probability under local differential privacy. The proposed estimation algorithm achieves near-optimal sample complexity and improves over previous methods. The sequential testing algorithm is efficient and does not require pre-specified sample limits, allowing it to adaptively determine hypothesis distinctions.", "Weaknesses": "While the algorithms show promising theoretical results, empirical validation with real-world datasets is not discussed. This could limit the understanding of the practical utility and scalability of the proposed methods.", "Questions": "How do the proposed methods perform when applied to real-world datasets, especially in diverse fields like ecology or economics? Are there specific examples or benchmarks used to validate the algorithms practically?"}}
{"paper_id": "F7QnIKlC1N", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel self-attention mechanism in a Graph Transformer model that directly predicts 3D ground-state molecular conformations with high accuracy, outperforming existing state-of-the-art models. It is validated on notable datasets like Molecule3D and QM9, showing significant improvements.", "Weaknesses": "The paper primarily focuses on the technical development and evaluation of the model. It may lack comprehensive analysis on computational efficiency compared to traditional methods like DFT.", "Questions": "How does the computational efficiency of the proposed model compare with traditional methods in terms of time and resource usage? Are there specific types of molecules or conditions where the model performs notably better or worse?"}}
{"paper_id": "8JCn0kmS8W", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative framework that leverages Large Language Models to produce complex audio content from text, achieving state-of-the-art results on established benchmarks. It offers a novel approach to generating comprehensive and harmonious audio by integrating various elements such as speech, music, and sound effects.", "Weaknesses": "The paper mentions potential limitations in areas such as efficiency and artificial composition, hinting that there may be challenges in the practical application or scalability of the approach. Additionally, the reliance on existing audio models without additional training may affect the flexibility and adaptability of the system.", "Questions": "How does WavJourney's performance and efficiency compare to existing state-of-the-art systems across various audio genres and complexities? Are there specific scenarios where the system underperforms?"}}
{"paper_id": "XbLffB0T2z", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a critical gap in the transferability of availability data poisoning attacks by proposing a novel method that significantly improves attack efficacy across different learning paradigms. The experiments are well-designed and demonstrate substantial performance improvements over existing methods.", "Weaknesses": "The paper may lack exploration into potential defenses against the proposed attacks, which could offer a more comprehensive understanding of the implications and mitigation strategies.", "Questions": "How does the approach perform when applied to other types of data, such as text or audio, beyond image datasets? Can the perturbations generated by this method be detected and countered effectively by current defense mechanisms?"}}
{"paper_id": "4y3GDTFv70", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel theoretical framework based on Bayesian inference to explain the emergent abilities in large language models. The use of latent space theory to distinguish between unambiguous and ε-ambiguous languages is innovative. The framework is supported by simulation experiments that validate the theory.", "Weaknesses": "The model relies heavily on theoretical assumptions and uses synthetic data for validation, which may not fully capture the complexities of real-world language processing. The explanations, while novel, need more empirical validation with actual LLMs beyond synthetic simulations.", "Questions": "How well does the proposed latent space theory align with observations of LLM behavior in practical, real-world applications? Can the Bayesian inference framework be extended or tested with larger, more realistic datasets?"}}
{"paper_id": "ODSgo2m8aE", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses an important gap in GNN research by proposing a novel method to apply Lipschitz bounds for stabilizing outputs in biased graph data. JacoLip, the method presented, is easy to integrate into existing frameworks and shows significant improvements in model fairness and stability with minimal overhead.", "Weaknesses": "While the method is theoretically motivated, there could be more extensive empirical validation across a wider range of datasets and potentially different types of biases to demonstrate robustness and effectiveness.", "Questions": "How well does JacoLip perform across varying degrees of bias in datasets? Are there specific types of biases or datasets where the method is less effective?"}}
{"paper_id": "RlfD5cE1ep", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a novel theoretical perspective on the role of feature normalization in non-contrastive learning, presents a rigorous analysis of learning dynamics with cosine loss, and supports theoretical findings with numerical experiments.", "Weaknesses": "The practical implications of the theoretical findings could be further elaborated, and the analysis is primarily limited to synthetic settings and specific datasets/frameworks.", "Questions": "How well do the theoretical insights generalize to other datasets or architectures beyond CIFAR-10 and ResNet-18?"}}
{"paper_id": "18TfucMNTr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper proposes a novel method that integrates regularization into Gaussian continuation to improve the training of deep neural networks. The method is experimentally validated on standard benchmark datasets, showing faster convergence and improved accuracy. It provides insights into addressing saddle points in non-convex optimization.", "Weaknesses": "The paper could provide more in-depth analysis of the theoretical foundations behind the regularization approach used in Gaussian continuation. The scalability and applicability of the method to larger or more complex datasets remain to be demonstrated.", "Questions": "How does the proposed regularization method compare to other regularization techniques in handling saddle points? Are there any specific constraints or limitations when applying this method to different types of neural network architectures?"}}
{"paper_id": "JGTC6WgO4T", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant gap in Black-Box Domain Adaptation by proposing a novel framework for multi-source scenarios. The proposed method is theoretically sound and empirically validated, demonstrating competitive performance across multiple benchmark datasets.", "Weaknesses": "The paper could improve in clarity, especially concerning technical details and experimental setup. Additionally, while the results are promising, more diverse datasets and real-world applications could be considered to further validate the method.", "Questions": "How does the proposed framework handle scenarios where source domains have conflicting pseudo labels? Are there any limitations to the applicability of the method in extremely diverse source and target domain settings?"}}
{"paper_id": "fQHb1uZzl7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel architecture that effectively combines feature and cost aggregation using transformers, leading to significant improvements in dense matching tasks. The approach is validated on various benchmarks, showing its robustness and efficacy even under challenging conditions.", "Weaknesses": "The paper may not thoroughly explore the limitations or drawbacks of the method, such as potential computational complexity or limitations when handling extreme cases of deformation or intra-class variation.", "Questions": "How does the computational complexity of the proposed UFC model compare to existing methods, particularly in real-time applications? Are there specific scenarios where the UFC model does not perform as well as expected?"}}
{"paper_id": "YjG29CIOP7", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses significant vulnerabilities in Data-free Meta-learning with a novel approach combining TEAPOT and ROSY. The methods effectively enhance robustness against task-distribution shifts and corruption, demonstrated by strong experimental results on multiple datasets.", "Weaknesses": "While the memory-based and reinforcement learning strategies are innovative, the complexity of the approach may hinder reproducibility and real-world implementation. The paper's explanation of the methods could be clearer to aid understanding.", "Questions": "How does the method scale with larger and more diverse sets of pre-trained models? Are there specific limitations or assumptions about the model selection policy that practitioners should be aware of?"}}
{"paper_id": "DmDpu3r8iU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel framework, VUM, to evaluate LLMs on both 'know what' and 'know why' aspects of value understanding, which is a significant gap in current methodologies.", "Weaknesses": "The reliance on scaling laws and dataset annotations using GPT-4 might limit the generalizability of the findings. Additionally, the paper might not sufficiently address how to enhance 'know why' capabilities.", "Questions": "How can future LLMs be trained to improve their 'know why' capabilities? Are there alternative frameworks or methods that can be used to evaluate values in LLMs beyond what is proposed?"}}
{"paper_id": "kXHEBK9uAY", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel hierarchical approach to diffusion-based generative planning that improves computational efficiency and generalization for long-horizon tasks. Empirical results show significant improvement over existing methods.", "Weaknesses": "The presentation of the method and results could be more detailed, particularly in explaining the implementation details of the Sparse Diffuser and the specific metrics used for evaluation.", "Questions": "How does the choice of subgoal affect the overall planning performance? Are there specific criteria or features of the trajectories that guide subgoal selection in the Sparse Diffuser?"}}
{"paper_id": "i7LCsDMcZ4", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses a significant gap in the application of Spiking Neural Networks for event-based data by introducing SLTRP and SLRP methods for generating saliency maps. It also proposes novel data augmentation techniques, RPGDrop and RPGMix, which are experimentally shown to improve generalization in SNNs and achieve state-of-the-art results on benchmark datasets.", "Weaknesses": "The application of the proposed techniques is currently limited to classification tasks, and the scalability to other types of neural network tasks has not been explored or experimentally validated. Additionally, the computational cost of implementing the relevance propagation methods in complex scenarios is not clearly addressed.", "Questions": "How do the proposed saliency map generation techniques compare in terms of computational efficiency with existing methods outside of SNNs? Can the proposed methods be adapted to benefit other types of SNN tasks beyond classification, such as regression or reinforcement learning?"}}
{"paper_id": "jHdz0CIS2y", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes an innovative method for voice conversion using entangled speech representations from self-supervised learning and speaker verification. It demonstrates significant improvements over existing models, especially in zero-shot and cross-lingual contexts. The iterative refinement training strategy is a notable strength.", "Weaknesses": "The presentation could be clearer in explaining the technical details of the proposed method. Additionally, more comprehensive evaluations could further solidify the claims of state-of-the-art performance.", "Questions": "How does the method handle extremely diverse linguistic attributes beyond accent, like tonal languages? What are the limitations in terms of computational requirements for training the SelfVC model?"}}
{"paper_id": "NkYCuGM7E2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to integrating LLMs into autonomous driving systems, enhancing decision-making through human-like reasoning and interpretability. The results indicate improved performance in complex scenarios, suggesting a viable path for future research.", "Weaknesses": "The practical implementation details of the system integration may not be thoroughly explored, and there might be a lack of comprehensive testing in real-world environments or edge cases.", "Questions": "How do the authors plan to address potential real-time processing constraints of LLMs in on-vehicle systems? Are there specific scenarios where the approach might not perform well?"}}
{"paper_id": "RtDok9eS3s", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a novel simplification of transformer blocks that achieves significant resource efficiency without compromising performance. The experimental results on both autoregressive and BERT models enhance its credibility.", "Weaknesses": "The paper might lack a comprehensive analysis of how these simplifications impact generalization across various datasets and tasks beyond the specific setups used.", "Questions": "How do the proposed modifications generalize to other transformer architectures or larger scale models like those used in industry settings?"}}
{"paper_id": "YCPDFfmkFr", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel method to handle infeasible QP layers in neural networks, which is a significant enhancement to the domain of differentiable optimization. The approach is well-grounded in theory and offers practical solutions with demonstrated numerical robustness and improved performance in experiments, such as Sudoku solving.", "Weaknesses": "The paper could improve in presentations, such as providing clearer explanations or visual aids to elaborate on the complex mathematical concepts introduced. Additionally, the reliance on a custom C++ package may limit accessibility and widespread adoption by the machine learning community.", "Questions": "How does the proposed method perform on a broader set of real-world tasks beyond Sudoku solving? Are there any plans to release the QPLayer package as open-source to encourage community engagement and testing?"}}
{"paper_id": "ueTdErd5Ib", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel method for addressing contextual stochastic optimization by integrating learning directly with the optimization task, which significantly improves robustness against uncertainty. Theoretical guarantees are provided for the regret of decisions, and experimental results show practical improvements in real-world applications such as electricity generation.", "Weaknesses": "The paper may benefit from more extensive experimental validation across different domains to fully establish the general applicability and effectiveness of the proposed approach.", "Questions": "How does the proposed method perform on optimization problems with larger and more complex feasible regions? Are there any limits to the discretization approach that could impact scalability?"}}
{"paper_id": "sDmjlpphdB", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to prompt optimization for large language models by introducing a Mixture-of-Prompts framework. It effectively leverages specialized experts to handle homogeneous regions of the problem space, which leads to a significant performance improvement of up to 43% on benchmark NLP tasks.", "Weaknesses": "While the methodology appears sound, the paper may not fully explore the scalability of the Mixture-of-Prompts framework when applied to a broader range of tasks beyond the tested NLP benchmarks. The complexity of the proposed method could also pose challenges in terms of interpretability and computational cost.", "Questions": "How does the Mixture-of-Prompts framework handle tasks with rapidly evolving problem spaces or those needing dynamic prompt adaptation? Additionally, how scalable is the framework when applied to an increased number of experts or more complex task domains?"}}
{"paper_id": "Mdk7YP52V3", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a novel theoretical framework using statistical physics to explain the overfitting behaviors in overparameterized heteroskedastic regression models. The use of a nonparametric free energy framework and phase diagram to validate theoretical insights is innovative and potentially impactful for regularization strategies.", "Weaknesses": "The reliance on complex theoretical constructs from statistical physics may limit accessibility to readers unfamiliar with these methods. Additionally, the empirical validation, while present, might not cover a wide enough range of datasets and architectures, which could impact the generalizability of the findings.", "Questions": "How does the proposed framework scale with larger, more complex datasets typical in deep learning applications? Are there any limitations observed when applying the NFE framework to different types of data distributions or neural network architectures?"}}
{"paper_id": "YGTSLDAPqb", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel method that significantly improves OOD performance, demonstrating impressive results across multiple challenging datasets. The 'Connect Later' framework is well-validated and addresses clear limitations of existing techniques.", "Weaknesses": "The approach may rely heavily on domain-specific knowledge to craft targeted augmentations, which could limit its general applicability across datasets where these shifts are less understood.", "Questions": "How do the authors propose to determine and implement targeted augmentations when the distribution shifts between source and target domains are not well-defined or understood?"}}
{"paper_id": "JTcaziw7G1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The proposed method provides a novel solution for privacy-preserving retrieval in distributed databases using LLMs, leveraging MPC techniques. It demonstrates efficacy through both synthetic and real datasets, highlighting its applicability.", "Weaknesses": "The computational costs associated with the approach could hinder its practical deployment. Additionally, the solution may require further optimization to be viable on a larger scale.", "Questions": "How can the computational costs be reduced to make this solution more practical? Are there any specific scenarios where this approach may not be applicable or fail to maintain privacy effectively?"}}
{"paper_id": "lEkFq4RUCX", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel and efficient metric for evaluating 3D point clouds that improves accuracy and computational efficiency compared to existing methods. It effectively addresses the limitations of traditional metrics like EMD and CD by focusing on surface differences.", "Weaknesses": "The paper may lack detailed experimental comparisons with a broader set of methods beyond EMD and CD, and the methodology could be explained in more depth to improve clarity.", "Questions": "How does the DDF metric perform across datasets not mentioned in the study? Are there scenarios where DDF might not offer improvements over traditional metrics?"}}
{"paper_id": "Fq8tKtjACC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper demonstrates that high-quality data can significantly improve model performance, achieving results comparable to larger models with less computational resources. The approach of using filtered data and synthetic generation is innovative and shows promise in breaking the existing scale-performance relationship.", "Weaknesses": "The model's performance is noted to be specialized in Python and sensitive to prompt variations, which could limit its general applicability. The paper might lack details on the specific methods used for filtering and synthetic data generation.", "Questions": "How can the approach be adapted to other languages or domains beyond Python? What are the specifics of the data filtering process using GPT-4 annotations?"}}
{"paper_id": "8fQlGQkj0S", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper provides a novel theoretical framework distinguishing in-context task learning and retrieval modes, supported by both theoretical analysis and numerical validation.", "Weaknesses": "The paper may lack empirical validation on a wider range of models and datasets beyond Transformers, and the assumptions made in the generative model might not perfectly align with real-world scenarios.", "Questions": "How do the derived risk bounds compare against empirical errors observed in different LLMs and datasets? Are there scenarios where the generative model assumptions significantly deviate from practical settings?"}}
{"paper_id": "hRos9WldRK", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The proposed L2B method effectively addresses the challenge of label noise without relying on explicit noise assumptions or a clean validation set. It integrates well with existing techniques and demonstrates improved performance across various datasets.", "Weaknesses": "While the method shows promise, the paper may lack a detailed comparison with more recent or less standard noisy label learning methods. Additionally, clarity in the presentation of the meta-learning framework could be improved.", "Questions": "How does the method perform in extremely high noise scenarios compared to the latest techniques in the field? Are there any limitations on the type or level of noise that the method can handle effectively?"}}
{"paper_id": "ttRSBZiCiu", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel model, WaveFluid, which efficiently synthesizes high-fidelity audio using a unique adversarial training approach, requiring only one inference step. The model successfully reduces computational overhead while maintaining audio quality comparable to state-of-the-art methods.", "Weaknesses": "The paper could improve on the clarity of the presentation, particularly in explaining the technical details of the model architecture and training process. The empirical evaluations might benefit from additional comparison metrics to fully establish the model's advantages.", "Questions": "How does WaveFluid's performance vary across different types of audio data beyond speech synthesis? Are there any limitations or specific scenarios where WaveFluid does not perform as well compared to other generative models?"}}
{"paper_id": "WYsLU5TEEo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The framework effectively combines interpretability with robustness, demonstrating competitive results in image classification tasks. The use of GANs for generating counterfactuals and the integration with adversarial training is novel and impactful.", "Weaknesses": "The paper might lack detailed comparisons with other similar methods in both interpretability and robustness. Additionally, it may not fully explore the limitations or potential biases introduced by the GAN-generated data.", "Questions": "How does the unified framework perform relative to other state-of-the-art models in different dataset domains beyond the two tested? Are there specific cases where the framework might fail or become less effective?"}}
{"paper_id": "KKZaj2QS3G", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach, CoInception, which effectively addresses noise resilience in time series representation learning and demonstrates strong performance across multiple benchmarks, while also being parameter-efficient.", "Weaknesses": "The detailed performance comparison with baseline models could be expanded to further validate the efficacy across diverse datasets. Additionally, implementation details may need clarification for reproducibility.", "Questions": "How does CoInception perform on time series with varying levels of noise, and are there specific thresholds where the method's effectiveness diminishes?"}}
{"paper_id": "LWDRiFzbHQ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel and well-justified method that improves the reliability of OOD generalization assessments by using a vicinal approach. The method builds on existing work but offers a substantial enhancement with consistent performance improvements across multiple datasets. The approach is elegant in its simplicity and effectiveness.", "Weaknesses": "The primary weakness could be an assumption on the availability of sufficiently similar neighboring samples, which may not hold in all practical scenarios. Additionally, the application of VRP may be computationally intensive if the computation of similarity weights is costly.", "Questions": "How does VRP perform in cases where the density of test samples is low or unevenly distributed? Are there any specific limitations on the selection of neighboring samples that the method requires?"}}
{"paper_id": "Yp01vcQSNl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to handling edge directionality in graph transformers, outperforming state-of-the-art models in tasks where directionality is key. The method is innovative, integrating dual role encodings and dynamic multi-head attention, enhancing applicability to directed graphs.", "Weaknesses": "The evaluation relies heavily on newly designed datasets, which may not comprehensively represent all real-world scenarios of directed graphs. The complexity of the proposed method might hinder straightforward applicability or understanding.", "Questions": "How does DiGT's performance compare to existing models on widely-used benchmark datasets with directed edges that were not specifically designed for directionality evaluation?"}}
{"paper_id": "LndMyiBl3n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel attack strategy, SheAttack, specifically targeting GNNs under the more challenging restricted black-box setting. The method generalizes across both homophilic and heterophilic graphs without requiring knowledge of node labels or model parameters. The use of Modified Silhouette Score (MSS) is an innovative approach to guide the attack process, which has been shown to effectively degrade the performance of GNNs.", "Weaknesses": "The paper might lack a comprehensive comparison with a broader range of existing adversarial attack methods, especially in terms of performance metrics on real-world datasets. Furthermore, the scalability and computational efficiency on extremely large graphs are not extensively discussed.", "Questions": "How does the MSS-based approach perform in comparison to other non-assumption-based attacking methods across various datasets? What are the computational costs associated with SheAttack when applied to significantly larger graphs?"}}
