{"paper_id": "u3xwwfHmBC", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel approach to capture spatio-temporal relationships through three tense-specific attention modules, which significantly improves traffic forecasting accuracy.\\n2. The proposed Tri-Tense Former (TTformer) model effectively handles incomplete traffic data by employing contrastive learning with negative filtering technique.\\n3. The paper provides a comprehensive evaluation of the model's performance on various metrics and datasets.\",\n  \"Weaknesses\": \"1. The paper assumes that the traffic flow can be categorized into three tense dimensions, which might not be universally applicable to all traffic scenarios.\\n2. The model's performance might be sensitive to the choice of hyperparameters and the quality of the input data.\\n3. The paper does not provide a detailed comparison with other state-of-the-art models on a wide range of traffic datasets.\",\n  \"Questions\": \"1. How does the model handle traffic scenarios with multiple tense dimensions, such as past-to-present, present, and future, simultaneously?\\n2. Can the TTformer model be applied to other domains that require sp"}
{"paper_id": "YKvBiRWdQC", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel benchmark, the Overcooked Generalisation Challenge (OGC), which is a significant contribution to the field of reinforcement learning.\\n2. The challenge is designed to study zero-shot cooperation abilities in agents, which is a critical aspect of human-AI cooperation.\\n3. The paper presents a comprehensive evaluation of state-of-the-art dual curriculum design methods on the OGC, providing valuable insights into their limitations.\",\n  \"Weaknesses\": \"1. The paper assumes that the reader is familiar with the Overcooked-AI environment, which might limit its accessibility to a broader audience.\\n2. The evaluation of the OGC is primarily focused on the performance of dual curriculum design methods, and it would be beneficial to explore other approaches as well.\",\n  \"Questions\": \"1. How does the OGC compare to other existing benchmarks in terms of its ability to capture generalisation abilities in agents?\\n2. Are there any plans to extend the OGC to other cooperative multi-agent environments or tasks?\"\n}"}
{"paper_id": "tePFpDgyqg", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant challenge in long context training, which is a crucial step for large language models.\\n2. The proposed data pipeline, LongPack, is innovative and well-designed to generate high-quality long documents.\\n3. The experimental results demonstrate the effectiveness and scalability of LongPack, outperforming state-of-the-art methods.\",\n  \"Weaknesses\": \"1. The paper relies heavily on the assumption that hyper-links are a reliable indicator of referral relationships, which may not always be the case in real-world scenarios.\\n2. The evaluation metrics used to measure the quality of the constructed documents may not capture all aspects of long context understanding.\\n3. The paper does not provide a clear analysis of the potential limitations and biases of the LongPack pipeline.\",\n  \"Questions\": \"1. How does the LongPack pipeline handle cases where the hyper-link connections between web pages are not well-represented or are missing?\\n2. Can the LongPack pipeline be adapted to other types of documents, such as books or academic"}
{"paper_id": "gx3LMRB15C", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed method, T-JEPA, is a novel and effective augmentation-free SSL method for tabular data, which is a significant contribution to the field.\\n2. The experimental results demonstrate substantial improvement in both classification and regression tasks, outperforming models trained directly on samples in their original data space.\\n3. The paper introduces regularization tokens, a novel regularization method critical for training of JEPA-based models on structured data.\\n4. The authors extensively characterize the obtained representations and show that T-JEPA effectively identifies relevant features for downstream tasks without access to the labels.\",\n  \"Weaknesses\": \"1. The paper assumes that the tabular data is structured, but does not discuss how the method would perform on unstructured data.\\n2. The authors do not provide a detailed analysis of the regularization tokens and how they impact the performance of the model.\\n3. The comparison with traditional methods is limited to Gradient Boosted Decision Trees.\",\n  \"Questions\": \"1. How does T-JEPA perform on datasets"}
{"paper_id": "kTH3bEH6hW", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant challenge in few-shot learning for tabular domains, and the proposed augmentation method is well-motivated and effective. The introduction of FeSTa benchmark is also a valuable contribution to the community.\\n2. The evaluation is comprehensive and systematic, with a thorough comparison with various existing approaches.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The augmentation method is limited to shuffling or sampling values within predefined feature-specific ranges, which might not be applicable to all tabular domains.\\n2. The evaluation is based on a single benchmark, FeSTa, which might not be representative of all possible tabular domains.\\n3. The paper assumes that the predefined feature-specific ranges are known, which might not be the case in practice.\",\n  \"Questions\": \"1. How does the augmentation method perform when the predefined feature-specific ranges are not known?\\n2. Can the augmentation method be extended to other types of tabular data, such as time-series"}
{"paper_id": "EqcLAU6gyU", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a comprehensive framework for agent-oriented planning in multi-agent systems, addressing critical design principles of solvability, completeness, and non-redundancy.\\n2. The proposed framework leverages a fast task decomposition and allocation process, followed by an effective evaluation via a reward model, and integrates a feedback loop for enhanced effectiveness and robustness.\\n3. The paper conducts extensive experiments demonstrating the advancement of the proposed framework in solving real-world problems compared to single-agent systems and existing planning strategies.\",\n  \"Weaknesses\": \"1. The paper assumes the existence of expert agents with diverse tools and expertise, which might not be realistic in all scenarios.\\n2. The framework's effectiveness in real-world problems might be limited by the quality and availability of the expert agents.\",\n  \"Questions\": \"1. How does the framework handle the scenario where the meta-agent is not aware of the capabilities and limitations of the expert agents?\\n2. Can the framework be applied to domains where the tasks are not decomposable into sub-tasks"}
{"paper_id": "qrTrnrEi9d", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel and effective approach to address the challenge of information extraction in low-resource languages by leveraging English translations of low-resource language data.\\n2. The proposed framework, TransFusion, is well-designed and demonstrates significant improvement in cross-lingual transfer.\\n3. The experiments are thorough and provide a comprehensive evaluation of the proposed method.\\n4. The paper has the potential to make a significant impact in the field of natural language processing.\\n5. The authors' ability to improve low-resource language named entity recognition using proprietary models such as GPT-4 is impressive.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of English translations of low-resource language data, which might not be feasible in all cases.\\n2. The evaluation metrics used are not entirely clear, and the choice of metrics might be biased towards the proposed method.\\n3. The paper could benefit from a more detailed analysis of the limitations of the proposed approach.\",\n  \"Questions\": \"1. How does the proposed method handle"}
{"paper_id": "Bp0HBaMNRl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents new theoretical results on the identifiability of nonlinear latent hierarchical causal models, relaxing previous assumptions in literature about the deterministic nature of latent variables and exogenous noise.\\n2. The authors develop a novel differentiable causal discovery algorithm that efficiently estimates the structure of such models, outperforming existing methods in both accuracy and scalability.\\n3. The paper demonstrates the practical utility of the approach by learning interpretable hierarchical latent structures from high-dimensional image data and its effectiveness on downstream tasks.\",\n  \"Weaknesses\": \"\",\n  \"Questions\": \"\"\n}"}
{"paper_id": "JzLcKWtGnl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant gap in existing 3D Multimodal LLMs by incorporating a progressive spatial awareness scheme that captures multi-level location-based information.\\n2. The introduction of two novel tasks and a 3D instruction dataset is a significant contribution to the field.\\n3. The experimental results demonstrate state-of-the-art performance across a wide range of 3D vision-language tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the progressive spatial awareness scheme is the key to improving performance, but it's unclear how this scheme is more effective than other methods.\\n2. The paper does not provide a thorough comparison with other state-of-the-art models on the proposed tasks.\\n3. The dataset MODEL is not publicly available, which may limit the reproducibility of the results.\",\n  \"Questions\": \"1. How does the progressive spatial awareness scheme compare to other methods for capturing spatial information in 3D scenes?\\n2. Can the authors provide more details on the design of the dataset MODEL and"}
{"paper_id": "hXJrQWIoR3", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in the field of explainable graph learning by focusing on representation-level explainability. The proposed framework is well-motivated and provides a clear direction for future research.\\n2. The theoretical analyses of the method's robustness and generalization are thorough and provide a solid foundation for the proposed approach.\\n3. The experiments are comprehensive and demonstrate the effectiveness of the method in both supervised and unsupervised learning tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the graph patterns are known and can be used as features for the weighted sum, which might limit the applicability of the method in real-world scenarios where the graph patterns are unknown or complex.\\n2. The method relies heavily on the quality of the graph pattern sampling, which can be a challenging task, especially for large graphs.\",\n  \"Questions\": \"1. How does the method handle the case where the graph patterns are unknown or complex, and how can it be adapted to handle such scenarios?\\n2. Can the method"}
{"paper_id": "67sSPPAZiG", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper contributes significantly to the field of egocentric video understanding by generating a large-scale QA dataset, proposing a new benchmark, and introducing a novel multimodal architecture. \\n2. The paper is well-organized, clearly presented, and the writing is concise.\\n3. The authors demonstrate the effectiveness of their approach through comprehensive experiments and comparisons with state-of-the-art models.\\n4. The Memory Pointer Prompting mechanism is an interesting and innovative design that enables the model to comprehend extended video content.\",\n  \"Weaknesses\": \"1. The paper assumes that the generated QA samples are of high quality, but it would be beneficial to provide more information about the quality control process.\\n2. The de-biasing evaluation method is not thoroughly explained, and more details about its implementation would be helpful.\\n3. The paper does not provide a clear comparison with other multimodal architectures for egocentric video understanding.\",\n  \"Questions\": \"1. How does the Memory Pointer Prompting mechanism handle cases where the video content is"}
{"paper_id": "kjmLabjSE2", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper provides a significant contribution to the field of differential privacy by extending the analysis to non-convex non-smooth losses.\\n2. The results are well-organized and clearly presented.\\n3. The use of H\\\"older reduction lemma is innovative and insightful.\",\n  \"Weaknesses\": \"1. The paper assumes that the loss function has H\\\"older continuous gradient, which might be restrictive in practice.\\n2. The improvement of shifted divergence analysis is not fully explained, and the optimal shifts allocation is not clearly justified.\\n3. The applicability of the results is not thoroughly discussed.\",\n  \"Questions\": \"1. Can the H\\\"older reduction lemma be applied to other types of losses or domains?\\n2. How does the choice of H\\\"older exponent affect the privacy bound?\"\n}"}
{"paper_id": "I18MA5DjoP", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel analytical framework, Neuron Predictability Lens (NPL), which provides insights into the behavior of internal neurons in transformer-based LLMs.\\n2. The framework is applied to both global and local analysis, shedding light on the connection between neuron predictability and interpretability.\\n3. The paper presents a comprehensive and systematic evaluation of LLaMA-2 and GPT-J, demonstrating the value of NPL as a tool for model analysis.\",\n  \"Weaknesses\": \"1. The paper assumes that the reader is familiar with transformer-based LLMs and their internal workings, which may limit its accessibility to a broader audience.\\n2. The concept of neuron predictability is not fully explored, and more in-depth analysis is needed to understand its implications.\\n3. The paper could benefit from a more detailed discussion of the limitations of NPL and potential future directions for improvement.\",\n  \"Questions\": \"1. How does NPL compare to existing methods for analyzing transformer-based LLMs?\\n2"}
{"paper_id": "qpDqO7qa3R", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed method achieves top performance in zero-shot video restoration and generalizes well across various datasets and extreme degradations.\\n2. The hierarchical latent warping strategy and token merging mechanism are well-designed and effectively integrate spatial information, optical flow, and feature-based matching.\\n3. The paper presents clear and concise visual comparisons and quantitative metrics on challenging datasets.\\n4. The technique is versatile and can work with any 2D restoration diffusion model.\",\n  \"Weaknesses\": \"1. The paper does not provide a clear explanation of the choice of hyperparameters for the hybrid correspondence mechanism.\\n2. The evaluation on extreme degradations (8$\\times$ super-resolution and high-standard deviation video denoising) is impressive, but it would be beneficial to see more detailed analysis of the method's performance under these conditions.\\n3. The paper assumes that the pre-trained image restoration diffusion model is available, but it would be more impactful if the model could be trained from scratch.\",\n  \"Questions\": \"1. How does"}
{"paper_id": "dSQtMx6dPE", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper is well-written and easy to follow, with a clear introduction and a concise description of the problem and the proposed solution.\\n2. The authors have made a significant contribution to the field by investigating the risks of graph prompts and proposing two new algorithms for differentially private graph prompt learning.\\n3. The evaluation is comprehensive and systematic, with a good balance between utility and privacy.\",\n  \"Weaknesses\": \"1. The paper assumes that the sensitive data is public, which might not be the case in many real-world applications.\\n2. The authors do not provide a detailed comparison with other existing methods for differentially private graph prompt learning.\\n3. The paper could benefit from a more detailed discussion on the trade-offs between utility and privacy.\",\n  \"Questions\": \"1. How do the authors plan to extend their work to handle private data?\\n2. Can the authors provide more insights on the trade-offs between utility and privacy?\\n3. How do the proposed algorithms compare with other existing methods for differentially private"}
{"paper_id": "GbgCRJedQ7", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel method, Sparse Matrix Tuning (SMT), that effectively minimizes the performance gap between parameter-efficient fine-tuning (PEFT) and full fine-tuning (FT) while reducing computational cost and memory footprint.\\n2. The experimental results demonstrate the superiority of SMT over other PEFT baselines (e.g. LoRA and DoRA) on various large language models and tasks.\\n3. The paper highlights a significant issue with LoRA and DoRA, where their performance tends to plateau and decline as the number of trainable parameters increases.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The authors claim that SMT reduces the GPU memory footprint by 67% compared to FT, but it would be more convincing if they provided a more detailed analysis of the memory usage.\\n2. The paper assumes that the most significant sub-matrices in the gradient update are the ones that should be updated, but it is not clear why this assumption"}
{"paper_id": "ZZVOrId3yN", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a comprehensive mathematical analysis of CrossModalNet, proving its universal approximation capabilities and deriving tight generalization bounds. This is a significant contribution to the field of multimodal learning.\\n2. The introduction of the Cross-Modal Information Flow (CMIF) metric is a valuable addition to the research community, providing theoretical justification for the progressive integration of multimodal information through the network layers.\\n3. The Joint Adversarial Domain Adaptation (JADA) framework addresses the critical issue of domain shift, simultaneously aligning marginal and conditional distributions while preserving topological structures.\\n4. The experimental results on the MM-WHS dataset demonstrate CrossModalNet's superior performance, advancing the field of medical image segmentation.\",\n  \"Weaknesses\": \"1. The paper assumes that the multimodal data streams are aligned, which may not always be the case in real-world applications.\\n2. The JADA framework may not be applicable to all types of domain shifts, and further research is needed to explore its limitations and extensions.\\n3"}
{"paper_id": "gLHuAYGs6a", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel structural multi-view clustering network that incorporates heterogeneous random walks to enhance clustering performance, which is a significant contribution to the field.\\n2. The method is well-designed and effective, as demonstrated by the extensive experiments on five real-world datasets.\\n3. The paper is well-organized and clearly presented, with a clear and concise writing style.\",\n  \"Weaknesses\": \"1. The paper assumes that the views are already pre-processed and aligned, which might not be the case in real-world scenarios.\\n2. The method might not be scalable to very large datasets due to the complexity of the heterogeneous random walks.\\n3. The paper lacks a clear comparison with other state-of-the-art methods in terms of computational efficiency.\",\n  \"Questions\": \"1. How does the proposed method handle noisy or missing data in the views?\\n2. Can the method be extended to handle more than two views?\\n3. How does the method perform on datasets with a large number of clusters?\"\n}"}
{"paper_id": "x5l5PRtvul", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a well-developed theoretical framework for h-SVGD, including a descent lemma and a large particle limit result. The connection to kernelised Wasserstein gradient flow is also insightful.\\n2. The experiments demonstrate the effectiveness of h-SVGD in alleviating variance collapse, and its competitiveness on high-dimensional inference tasks.\\n3. The paper is well-organized and clearly presented, with a good balance of theory and experiments.\",\n  \"Weaknesses\": \"1. The paper assumes that the target density is unknown, but does not provide any discussion on how to handle cases where the target density is known but not factorizable.\\n2. The mean field limiting distribution result shows that h-SVGD is biased, which may have implications for its use in certain applications.\\n3. The experiments are limited to a single dataset and a single type of neural network architecture.\",\n  \"Questions\": \"1. How does the bias in the mean field limiting distribution affect the performance of h-SVGD in practice?\\n2"}
{"paper_id": "pOUAVXnOQP", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes an innovative solution to the spectral bias problem in ReLU networks, which is a significant contribution to the field of neural representations.\\n2. The proposed Sinusoidal Trainable Activation Functions (STAF) is a well-designed and well-implemented solution that demonstrates superiority over state-of-the-art networks.\\n3. The experimental evaluation is comprehensive and systematic, showcasing the effectiveness of STAF in improving reconstruction quality and training efficiency.\\n4. The paper is well-organized and clearly presented, with a clear motivation for the proposed solution.\",\n  \"Weaknesses\": \"1. The paper assumes that the target signals are periodic, which might not be the case in all applications.\\n2. The extension of STAF to more general signal types, such as non-periodic signals, is not explored in this paper.\\n3. The paper does not provide a clear comparison with other state-of-the-art methods in terms of computational complexity.\",\n  \"Questions\": \"1. How does STAF perform on non-periodic signals,"}
{"paper_id": "iN64nSYt0z", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents a clear and well-structured method for improving the accuracy of following instructions, which is a significant contribution to the field of Large Language Models. \\n2. The introduction of Influence, a novel metric, is a valuable addition to the research and helps to understand how user instructions propagate through transformer layers. \\n3. The results show a significant improvement in accuracy, outperforming natural prompting alternatives.\",\n  \"Weaknesses\": \"1. The paper does not provide a thorough analysis of the limitations of the GUIDE method and its potential applications. \\n2. The comparison with natural prompting alternatives is not comprehensive, and more baselines should be included to support the claim of outperforming them. \\n3. The paper does not discuss the potential risks or challenges of using the GUIDE method in real-world applications.\",\n  \"Questions\": \"1. How does the GUIDE method handle out-of-distribution instructions or user input?\\n2. Can the Influence metric be applied to other types of models or tasks beyond Large Language Models"}
{"paper_id": "gRuZkEy49k", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a clear and concise connection between GFlowNets and maximum-entropy RL, which is well-motivated and well-executed.\\n2. The proposed method of adapting MCTS for GFlowNet training is innovative and well-implemented.\\n3. The paper provides extensive experiments and analysis, showcasing the effectiveness of the proposed method in various discrete domains.\\n4. The writing is clear and well-organized.\",\n  \"Weaknesses\": \"1. The paper assumes a good understanding of GFlowNets and RL, which might limit its accessibility to a broader audience.\\n2. The discussion on the practical strategies for employing MCTS as a sampling tool is somewhat limited.\\n3. The paper does not provide a clear comparison with other existing methods for GFlowNet training.\",\n  \"Questions\": \"1. How does the proposed method perform in continuous action spaces, where MCTS is not directly applicable?\\n2. Can the method be extended to other types of generative models beyond GFlowNets?\\"}
{"paper_id": "d23EVDRJ6g", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed localized masked modeling paradigm, MotionDreamer, effectively addresses the challenge of overfitting in the animation domain by learning motion internal patterns from a given motion with arbitrary topology and duration.\\n2. The novel distribution regularization method and sliding window local attention mechanism are well-designed and enable the generation of natural yet diverse animations.\\n3. The comprehensive experiments demonstrate the superiority of MotionDreamer over state-of-the-art methods in both faithfulness and diversity.\\n4. The proposed approach can also effectively perform downstream tasks such as temporal motion editing, crowd motion synthesis, and beat-aligned dance generation.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of a single MoCap reference, which may not be the case in all scenarios.\\n2. The evaluation is mostly based on quantitative metrics, and it would be beneficial to include more qualitative analysis to better understand the generated animations.\\n3. The paper does not provide a clear comparison with other existing methods in the animation domain, making it difficult to fully assess the novelty of the"}
{"paper_id": "kQ5s9Yh0WI", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant limitation of current long context LLMs, and the proposed AgentWrite pipeline is a creative solution to this problem. The work has the potential to greatly impact the field of language generation.\\n2. The paper is well-organized and clearly presented, with a clear structure and concise language.\\n3. The LongBench-Write benchmark is a valuable contribution to the field, providing a comprehensive evaluation framework for ultra-long generation capabilities.\",\n  \"Weaknesses\": \"1. The paper assumes that the scarcity of long-output examples in existing SFT datasets is the primary reason for the model's output limitation. However, it is unclear whether this is the only factor contributing to this limitation.\\n2. The AgentWrite pipeline relies heavily on off-the-shelf LLMs, which may not be suitable for all tasks or domains.\\n3. The paper does not provide a thorough analysis of the trade-offs between model size, training data, and output length.\",\n  \"Questions\": \"1. How does the Agent"}
{"paper_id": "9CqkpQExe2", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Ada-K routing strategy offers a novel and effective approach to managing computational costs in MoE-based LLMs.\\n2. The use of learnable and lightweight allocator modules to dynamically adjust the number of activated experts for each token is a significant contribution.\\n3. The experimental results demonstrate a substantial reduction in FLOPs and inference speedup while improving performance across various benchmarks.\\n4. The training of Ada-K is highly efficient, and the model is broadly applicable across mainstream MoE-based LLMs.\",\n  \"Weaknesses\": \"1. The paper assumes that the allocator modules can be learned effectively using PPO, but it is unclear whether this approach can be generalized to other allocation strategies.\\n2. The evaluation is limited to four popular baseline models, and it would be beneficial to include more comprehensive comparisons with other MoE-based LLMs.\\n3. The paper does not provide a clear explanation of how the allocator modules are integrated into the MoE architecture.\",\n  \"Questions\": \"1. How does the"}
{"paper_id": "PpYy0dR3Qw", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel and effective algorithm, LoCoDL, that leverages local training and compression to reduce communication complexity in distributed optimization and federated learning.\\n2. The theoretical analysis of LoCoDL's communication complexity is rigorous and well-motivated.\\n3. The experimental results demonstrate the superiority of LoCoDL over existing algorithms.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the compressor is unbiased, which might not be the case in practice.\\n2. The experimental evaluation is limited to a small number of datasets and baselines.\\n3. The paper does not discuss the potential drawbacks of using local training and compression.\",\n  \"Questions\": \"1. How does LoCoDL perform on non-strongly convex functions?\\n2. Can LoCoDL be extended to handle non-heterogeneous regimes?\\n3. What are the potential applications of LoCoDL in real-world federated learning scenarios?\"\n}"}
{"paper_id": "UatDdAlr2x", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a detailed and insightful analysis of how different architectural design choices influence the space of solutions that a transformer can implement and learn.\\n2. The histogram task is a well-chosen problem to study this phenomenon, and the findings have implications for the design of transformer models.\\n3. The paper is well-written and easy to follow, with clear explanations of the theoretical results and empirical evaluation.\\n4. The authors provide a clear and concise summary of the key contributions and implications of the work.\\n5. The paper's focus on the interplay between different components of the transformer architecture is a significant contribution to the field.\",\n  \"Weaknesses\": \"1. The paper's scope is relatively narrow, focusing on a specific task and a specific type of model.\\n2. The experimental evaluation is limited to a small set of hyperparameters and architectures.\\n3. The paper could benefit from a more detailed discussion of the implications of the findings for the design of transformer models in more complex tasks.\",\n  \"Questions\": \"1"}
{"paper_id": "IwgmgidYPS", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a comprehensive and large-scale multimodal dataset for medicine, MedTrinity-25M, which is a significant contribution to the field.\\n2. The dataset is annotated with multigranular information, including global and local information, and is generated through an automated pipeline.\\n3. The paper proposes a novel approach to generating multigranular visual and textual annotations, which is scalable and efficient.\\n4. The LLaVA-Tri model achieves state-of-the-art performance on several multimodal tasks, demonstrating the effectiveness of the dataset and the approach.\\n5. The paper highlights the potential of MedTrinity-25M for supporting large-scale pre-training of multimodal medical AI models.\",\n  \"Weaknesses\": \"1. The paper assumes that the automated pipeline for generating annotations is reliable, but it is unclear how well it performs in edge cases or when faced with novel medical concepts.\\n2. The paper does not provide a thorough comparison with existing multimodal datasets, making it difficult to assess the novelty"}
{"paper_id": "WG7GzGx3G9", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective method for activation smoothing in quantization, addressing the issue of outliers in activations.\\n2. The proposed method, RRS, outperforms state-of-the-art methods in the LLaMA and Qwen families.\\n3. The paper provides a clear and concise explanation of the problem and the proposed solution.\",\n  \"Weaknesses\": \"1. The paper assumes that outliers can be classified into channel-wise and spike outliers, which might not be universally applicable.\\n2. The Rotation operation is not fully explained, and its effect on the performance is not thoroughly analyzed.\\n3. The paper does not provide a thorough comparison with other existing methods in terms of latency and accuracy.\",\n  \"Questions\": \"1. How does the Rotation operation specifically narrow the gap between spike outliers and normal values?\\n2. Can the proposed method be applied to other types of neural networks, or is it specific to large language models?\\n3. What is the computational cost of the Rotation operation, and how does"}
{"paper_id": "BhECSDSkAE", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper introduces a novel task and approach for one-shot medical video object segmentation using static image datasets.\\n2. The proposed framework leverages readily available labeled static images to segment objects in medical videos with minimal annotation.\\n3. The method comprises training a one-shot segmentation model exclusively on images, followed by adapting it to medical videos through a test-time training strategy.\\n4. The paper presents OS-I2V-Seg, a comprehensive dataset comprising 28 categories in images and 4 categories in videos.\",\n  \"Weaknesses\": \"1. The paper does not provide a detailed comparison with existing state-of-the-art methods for video object segmentation.\\n2. The evaluation metrics used are not clearly explained, making it difficult to understand the significance of the results.\\n3. The paper assumes that the static image dataset is readily available, which might not be the case in all medical imaging scenarios.\",\n  \"Questions\": \"1. How does the proposed method handle cases where the first frame of the video is not representative of the rest of"}
{"paper_id": "mnB4hDTIDr", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to diversity evaluation for LLM-generated datasets from a classification perspective, which is a timely and important contribution to the field.\\n2. The proposed method, DCScore, is theoretically verified and enjoys lower computational costs compared to existing methods.\\n3. The experimental results demonstrate the effectiveness of DCScore in evaluating diversity.\",\n  \"Weaknesses\": \"1. The paper assumes that the classification task is a good proxy for diversity evaluation, which might not always hold true. For example, in certain domains, diversity might be more nuanced and not solely dependent on classification accuracy.\\n2. The experimental results are limited to a few datasets and metrics, which might not be representative of all possible scenarios.\\n3. The paper does not discuss potential limitations or challenges in applying DCScore to real-world datasets.\",\n  \"Questions\": \"1. How does DCScore perform on datasets with varying levels of diversity, and how does it handle cases where the classification task is not a good proxy for diversity?\\n"}
{"paper_id": "Y0qmwm6tgy", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant problem in the field of model pruning, which is the instability of weight gradients under perturbations.\\n2. The proposed method, MoreauPruner, is well-motivated and provides a novel approach to structural pruning with provable robustness against weight perturbations.\\n3. The evaluation is comprehensive and shows the robustness of MoreauPruner against weight perturbation and its contribution to successful accuracy-based scores.\",\n  \"Weaknesses\": \"1. The paper assumes that the model weights are represented in float16 format, which might not be the case in all scenarios.\\n2. The method is limited to LLMs and it's unclear whether it can be extended to other types of neural networks.\\n3. The comparison with existing pruning methods is limited to a few baselines.\",\n  \"Questions\": \"1. How does MoreauPruner handle the case where the model weights are represented in a different format, such as float32?\\n2. Can MoreauPruner be"}
{"paper_id": "aAcOaJYbUg", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a well-designed benchmark, LAION-C, which is a significant improvement over ImageNet-C, as it is more representative of real-world OOD scenarios.\\n2. The paper conducts a comprehensive evaluation of state-of-the-art models on the proposed benchmark, providing a clear understanding of their performance.\\n3. The psychophysical experiment is a nice addition, providing a comparison of model performance to human robustness data.\\n4. The paper highlights a paradigm shift in OOD generalization, with models now matching or outperforming human observers.\",\n  \"Weaknesses\": \"1. The paper assumes that the proposed benchmark is more representative of real-world OOD scenarios, but it is unclear whether this is the case, as the dataset is still limited to a specific set of corruption types and severity levels.\\n2. The psychophysical experiment is not fully explained, making it difficult to understand the methodology and results.\",\n  \"Questions\": \"1. How does the proposed benchmark LAION-C compare to other existing benchmarks, such"}
{"paper_id": "duGygkA3QR", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper connects GNNs to Koopman theory and its numerical method, Dynamic Mode Decomposition (DMD), which is a novel and interesting approach.\\n2. The authors theoretically establish a connection between the DMD-estimated operator and the original dynamic operator between system states, providing a solid foundation for their approach.\\n3. The paper introduces a family of DMD-GNN models that effectively leverage the low-rank eigenfunctions provided by the DMD algorithm.\\n4. The authors validate their approach through extensive experiments on various learning tasks, including directed graphs, large-scale graphs, long-range interactions, and spatial-temporal graphs.\",\n  \"Weaknesses\": \"1. The paper assumes that the graph structure is known and does not address the case where the graph structure is unknown or changing.\\n2. The authors do not provide a thorough analysis of the computational complexity of their approach and its scalability to large graphs.\\n3. The paper does not discuss the interpretability of the DMD-GNN models and how they can"}
{"paper_id": "s6nYndMwG7", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors propose a practical approach to choosing hyperparameters for LiSSA, making it more feasible for large models.\\n2. The use of spectral properties of the Hessian matrix is innovative and insightful.\\n3. The comparison with PBRF is a good addition to the paper.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of the Hessian matrix, which might not be the case in all scenarios.\\n2. The authors could have explored more real-world applications of their approach.\",\n  \"Questions\": \"1. How do the authors plan to extend their approach to scenarios where the Hessian matrix is not available?\\n2. Are there any potential limitations of using random sketching for evaluating spectral properties?\"\n}"}
{"paper_id": "9BVMD3keG8", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses an interesting problem in online learning, specifically in the context of brokerage between traders. The authors provide a clear and well-structured presentation of their results.\\n2. The paper presents two main results: a regret bound for the case where traders' valuations are revealed after each interaction, and a regret bound for the case where only their willingness to sell or buy is revealed. These results are rigorously proven and provide a clear understanding of the problem's complexity.\\n3. The paper's contribution is significant, as it provides a better understanding of the role of contextual information in online learning and provides algorithms with provable regret bounds.\",\n  \"Weaknesses\": \"1. The paper assumes that the market value of traded assets is an unknown linear function of a d-dimensional vector representing the contextual information available to the broker. This assumption may be too restrictive, and it would be interesting to see how the results generalize to more complex relationships between the contextual information and the market value.\\n2. The paper focuses on the regret with respect"}
{"paper_id": "mnna9LUg7P", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective SSM quantization method that addresses the challenges of quantizing SSMs with sensitive feature maps and massive outliers. The use of Hadamard transform for outlier-free quantization is particularly innovative.\\n2. The experiments demonstrate the effectiveness and scalability of the proposed method for large language models, with only a small drop in accuracy.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the selective scan mechanism is the primary source of sensitivity in SSMs, but it would be beneficial to investigate other potential sources of sensitivity.\\n2. The experiments are limited to only two models (Mamba 2.8B and Jamba 52B), and it would be interesting to see the results on other SSM-based models.\\n3. The paper does not discuss the potential impact of quantization on the interpretability of the models.\",\n  \"Questions\": \"1. How does the proposed method compare to other quantization techniques"}
{"paper_id": "3X3LuwzZrl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant issue in multi-label node classification on graphs, specifically the intricate influences between labels in non-Euclidean graph data.\\n2. The proposed model, Label Influence Propagation (LIP), is novel and effective, consistently outperforming SOTA methods across various settings.\\n3. The paper is well-organized and clearly presented, with a comprehensive analysis and quantification of label influence correlations.\",\n  \"Weaknesses\": \"1. The paper assumes that the label influence graph can be accurately constructed based on integrated label correlations, which may not always be the case in real-world datasets.\\n2. The model's performance may be sensitive to the quality of the input graph and the choice of hyperparameters.\\n3. The paper does not provide a clear explanation of how the label influence graph is used to adjust the learning process.\",\n  \"Questions\": \"1. How does the label influence graph account for the direction of influence between labels?\\n2. Can the model be extended to handle graphs with cycles or other"}
{"paper_id": "IqaQZ1Jdky", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and well-motivated framework for KANs, leveraging the Weierstrass approximation theorem and Bernstein polynomials to enhance both accuracy and interpretability.\\n2. The experiments demonstrate the effectiveness of the proposed framework across multiple domains, including multivariate time series forecasting, computer vision, and function approximation.\\n3. The paper is well-written and easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes a good understanding of advanced mathematical concepts, such as the Weierstrass approximation theorem and Bernstein polynomials, which may be a barrier for some readers.\\n2. The experiments are limited to three domains, and it would be beneficial to explore the proposed framework in more diverse application areas.\\n3. The paper could benefit from a more detailed discussion on the computational complexity of the proposed framework and its potential scalability issues.\",\n  \"Questions\": \"1. How does the proposed framework handle cases where the input data has a complex structure or high dimensionality?\\n2. Can the Bernstein polynomial"}
{"paper_id": "OdMqKszKSd", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel method for generating articulated objects from a single image, addressing a significant limitation in prior work.\\n2. The method's ability to capture ambiguity in part shape and motion is a significant contribution.\\n3. The pipeline design is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the input image is of the object in a resting state, which might not always be the case in real-world scenarios.\\n2. The method's reliance on a diffusion model may limit its applicability to certain types of objects or scenes.\\n3. The paper could benefit from more extensive evaluation on a diverse range of objects and scenarios.\",\n  \"Questions\": \"1. How does the method handle cases where the input image is not of the object in a resting state?\\n2. Can the method be adapted to handle objects with complex kinematics or dynamic behavior?\\n3. What are the potential applications of this method beyond articulated object creation?\"\n}"}
{"paper_id": "LOBhVTtVnc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to dynamics simulation using Transformers, which is well-motivated and effectively addresses the limitations of existing GNN methods.\\n2. The introduction of the Temporal Difference Graph (TDG) is a significant contribution, as it captures global dynamic patterns and mitigates cumulative errors in long-term prediction tasks.\\n3. The paper achieves state-of-the-art performance across multiple challenging physical systems at various scales, demonstrating the robust dynamics simulation capabilities of GSTs.\",\n  \"Weaknesses\": \"1. The paper assumes that the input sequences are of arbitrary lengths, but it is unclear how GSTs perform with sequences that have varying lengths or missing data.\\n2. The evaluation is limited to a few physical systems, and it would be beneficial to see the method applied to a broader range of domains.\\n3. The authors could provide more insights into the TDG mechanism and its impact on the overall performance.\",\n  \"Questions\": \"1. How does GSTs perform with sequences that have varying lengths or missing data?\\"}
{"paper_id": "oa5UeyUVMm", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a clear and concise overview of the current state of diffusion probabilistic models in representation learning, and their potential for graph representation learning.\\n2. The theoretical foundations of applying diffusion models to representation learning are well-established and the authors provide a solid proof of the denoising objective's relation to conditional mutual information.\\n3. The empirical evaluation is comprehensive and shows competitive results on various real-world datasets.\\n4. The introduction of Graffe, a self-supervised diffusion model for graph representation learning, is well-motivated and shows promising results.\\n5. The authors provide a clear and concise explanation of the Graffe model and its components.\\n6. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes a strong background in diffusion probabilistic models and representation learning, which might make it difficult for non-experts to follow.\\n2. The evaluation of Graffe is limited to the linear probing setting, and it would be beneficial to explore other settings, such"}
{"paper_id": "5swfKRkCx7", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to augmenting LLMs with external knowledge attention for QA, which is well-motivated and effectively addressed.\\n2. The memory-based mechanism for dynamically controlling knowledge integration is innovative and well-implemented.\\n3. The experiments on both general and specific-domain QA tasks demonstrate the effectiveness of the approach.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The novelty of the approach may be somewhat limited, as it builds upon existing RAG methods.\\n2. The evaluation could be more comprehensive, including more baselines and metrics.\\n3. The paper could benefit from more detailed analysis of the memory-based mechanism and its impact on the LLM's performance.\",\n  \"Questions\": \"1. How does the extra head for external knowledge attention interact with the internal heads of the LLM, and how does it affect the overall performance?\\n2. Can the memory-based mechanism be applied to other types of tasks beyond QA, such as text classification"}
{"paper_id": "5s1qpjrNvZ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a novel and rigorous analysis of the sampling rate of the guide policy in guided RL, establishing a performance guarantee for the first time. This is a significant contribution to the field.\\n2. The proposed algorithm, GRL-RB, is simple to implement and robust to hyperparameter choices, making it a practical solution for real-world applications.\\n3. The paper is well-written and easy to follow, with a clear presentation of the problem, the proposed solution, and the results.\",\n  \"Weaknesses\": \"1. The assumptions made in the analysis are not explicitly stated, which might limit the applicability of the results.\\n2. The evaluation of the proposed algorithm is limited to a few experiments, and it would be beneficial to see more extensive comparisons with other methods.\\n3. The paper assumes a specific type of guide policy, which might not be generalizable to other types of guide policies.\",\n  \"Questions\": \"1. Can the performance guarantee be extended to other types of guide policies or learning environments?\\"}
{"paper_id": "WNb4P8aG66", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Diffusion on Diffusion (DoD) framework is innovative and well-motivated, addressing a significant limitation of class-guided diffusion models. The use of visual priors from previously generated samples is a clever approach.\\n2. The evaluation on the ImageNet-$256 \\times 256$ dataset demonstrates the effectiveness of DoD, achieving a 7x reduction in training cost with better performance in terms of the FID-50K score.\\n3. The paper is well-organized and clearly presented, with a clear description of the methodology and results.\",\n  \"Weaknesses\": \"1. The paper assumes that the generated images from the early stages of diffusion sampling are sufficient for providing rich guidance for the diffusion model. However, it is unclear whether this assumption holds for all types of images or datasets.\\n2. The paper does not provide a detailed analysis of the effect of the latent embedding module on the generated images.\",\n  \"Questions\": \"1. How does the DoD framework perform on other datasets,"}
{"paper_id": "UfczlMudN6", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The work presents a unified framework for in-distribution and out-of-distribution generalization, which is a significant contribution to the field of deep reinforcement learning.\\n2. The proposed algorithm GRAM achieves strong generalization performance across various scenarios, demonstrating its effectiveness.\\n3. The use of a robust adaptation module and a joint training pipeline is a well-designed approach.\",\n  \"Weaknesses\": \"1. The paper assumes that the environment dynamics can be fully captured by a single adaptation module, which might not be the case in more complex scenarios.\\n2. The evaluation is limited to simulated locomotion tasks, and it is unclear how the algorithm would perform in real-world scenarios.\\n3. The paper could benefit from a more detailed discussion on the trade-offs between in-distribution adaptation and out-of-distribution robustness.\",\n  \"Questions\": \"1. How does the algorithm handle the trade-off between in-distribution adaptation and out-of-distribution robustness? Are there any scenarios where the algorithm prioritizes one over the other?\\n"}
{"paper_id": "60Vd7QOXlM", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in the current state-of-the-art by developing more effective canaries for privacy auditing of large language models, which is a timely and relevant topic.\\n2. The experiments demonstrate the effectiveness of the proposed approach in detecting privacy leakage, with impressive results on multiple families of fine-tuned LLMs.\\n3. The paper provides a clear and concise presentation of the method and results, making it easy to follow and understand.\",\n  \"Weaknesses\": \"1. The paper assumes that the attacker cannot train shadow models, insert gradient canaries, or access the model at every iteration, which might not be a realistic threat model for all applications.\\n2. The evaluation is limited to a few specific LLMs and datasets, which may not generalize to other settings.\\n3. The paper does not provide a detailed analysis of the trade-offs between the proposed method and other existing approaches.\",\n  \"Questions\": \"1. How does the proposed method handle the case where the attacker has access to the model's"}
{"paper_id": "GqhvJ1o8m5", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel framework for transforming single-view videos into stereo videos, which is a significant contribution to the field. The use of a dual-branch architecture with spatial-temporal attention mechanisms is innovative and effective.\\n2. The introduction of the YouTube-SBS dataset is a major contribution to the field, providing a comprehensive collection of stereo videos for training and benchmarking stereo video generation models.\\n3. The experiments demonstrate the effectiveness of ImmersePro in producing high-quality stereo videos, with significant improvements over existing methods.\",\n  \"Weaknesses\": \"1. The paper assumes that the input video is of good quality, which may not be the case in real-world scenarios.\\n2. The evaluation metrics used are limited to L1, SSIM, and PSNR, which may not capture the full range of possible improvements in stereo video generation.\\n3. The paper does not provide a clear explanation of how the disparity branch and context branch interact with each other.\",\n  \"Questions\": \"1. How does the implicit disparity"}
{"paper_id": "ua5MHdsbck", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to protein design by leveraging triplet relations, which is a significant contribution to the field. The idea of distilling relevant triplet relations into the model is innovative and has the potential to improve the effectiveness of protein design.\\n2. The evaluation is well-structured and demonstrates the effectiveness of the proposed framework in designing AAV and GFP proteins.\\n3. The paper is well-written and easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes that noisy training pairs are not sufficiently informative to capture the fitness gradient, but it would be helpful to provide more evidence or analysis to support this claim.\\n2. The paper mentions that the proposed framework improves effectiveness in extrapolation tasks, but it would be beneficial to provide more details about the specific tasks and metrics used to evaluate the performance.\\n3. The paper could benefit from a more thorough comparison with existing methods, including their strengths and limitations.\",\n  \"Questions\": \"1. How does the proposed framework handle cases where the triplet relations are not well"}
{"paper_id": "56Zn3halhq", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes an innovative learnable data augmentation method, AutoTSAug, which improves forecasting performance with minimal additional computational cost.\\n2. The empirical analysis of marginal samples is well-motivated and effective in identifying which parts of the training data should be augmented.\\n3. The use of variational masked autoencoders as the augmentation model and the REINFORCE algorithm to transform marginal samples into new data is well-designed.\",\n  \"Weaknesses\": \"1. The paper relies heavily on the assumption that the marginal samples are representative of the challenging training samples, which may not always be the case.\\n2. The evaluation of AutoTSAug is limited to a single dataset, and it is unclear how well the method generalizes to other datasets.\\n3. The computational cost of training the variational masked autoencoder may be high, which could be a limitation for large-scale applications.\",\n  \"Questions\": \"1. How does AutoTSAug perform on other types of time series forecasting tasks, such as multivariate"}
{"paper_id": "aPTGvFqile", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant issue in CLIP, which is the modality gap in the embedding space. The proposed AlignCLIP method effectively reduces this gap and improves cross-modal alignment.\\n2. The paper provides a clear and concise explanation of the problem and the proposed solution.\\n3. The evaluation is comprehensive and includes both zero-shot and fine-tuning downstream evaluations.\\n4. The authors provide a semantically-regularized separation objective function to improve the alignment between text and image embeddings.\",\n  \"Weaknesses\": \"1. The paper assumes that the modality gap is the primary cause of the sparse and disconnected embedding space, which might not be the case.\\n2. The evaluation does not include a comparison with other state-of-the-art methods that address the modality gap.\\n3. The paper does not provide a clear explanation of how the semantically-regularized separation objective function works and how it improves the alignment between text and image embeddings.\",\n  \"Questions\": \"1. How does the semantically-regular"}
{"paper_id": "GOwNImvCWf", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a limitation of weight-space autoencoders (AEs) and proposes a novel behavioral loss to capture features essential for reconstructing high-performing models.\\n2. The evaluation on three different model zoos demonstrates the effectiveness of combining structural and behavioral losses in increasing performance across downstream tasks.\\n3. The paper explores representation learning in deep weight spaces and shows a strong synergy between structural and behavioral features.\",\n  \"Weaknesses\": \"1. The novelty of the behavioral loss is not clearly established, as the authors do not provide a thorough analysis of existing methods that could be used to capture the features critical for reconstructing high-performing models.\\n2. The paper assumes that the reader is familiar with the concept of weight-space AEs and their limitations, which may not be the case for all readers.\\n3. The evaluation is limited to three model zoos, and it would be beneficial to see more comprehensive evaluation on a wider range of models and tasks.\",\n  \"Questions\": \"1. How does the behavioral loss"}
{"paper_id": "C9BA0T3xhq", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel algorithm, Extended Implicit Q-Learning (EIQL), which addresses the exploration-exploitation trade-off in offline reinforcement learning. The approach is well-motivated and has the potential to improve the performance of offline RL algorithms.\\n2. The experimental results demonstrate the efficacy of EIQL, particularly in environments with sparse rewards or suboptimal and incomplete trajectories.\\n3. The paper is well-written and easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes that the Bellman update can be extended to actions not explicitly present in the dataset, which might not always be the case. The theoretical justification for this assumption is not fully explored.\\n2. The evaluation of EIQL is limited to a few environments, and it is unclear whether the results generalize to other domains.\\n3. The comparison with other offline RL algorithms is not comprehensive, and it would be beneficial to include more baselines in the experiments.\",\n  \"Questions\": \"1. How does EIQL handle the case where the"}
{"paper_id": "EeqlkPpaV8", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a rigorous analysis of the adaptive complexity of sampling, which is a fundamental problem in large-data applications. The results are well-motivated and the proof techniques are novel.\\n2. The paper is well-organized and clearly presented, with a good balance between technical details and intuition.\\n3. The authors provide a clear and concise summary of the related work and the contributions of the paper.\",\n  \"Weaknesses\": \"1. The paper assumes a high degree of parallelization, which might not be realistic in all scenarios.\\n2. The proof techniques are complex and might be difficult to follow for readers without a strong background in theoretical computer science.\\n3. The paper does not provide any empirical evaluation of the proposed algorithms.\",\n  \"Questions\": \"1. Can the results be extended to more general distributions or sampling algorithms?\\n2. How do the authors plan to address the issue of parallelization in practice?\\n3. Are there any potential applications of the proposed algorithms beyond large-data inference processes?\"\n}"}
{"paper_id": "oK1zJCWBqf", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and elegant approach to aligning generative models with human preferences without the need for a reward model.\\n2. The theoretical foundation of SPO under the Bradley-Terry model assumption is well-motivated and provides a clear understanding of the algorithm's behavior.\\n3. The paper's comparative advantages in simplicity and alignment precision are well-highlighted, making it a strong contribution to the field.\",\n  \"Weaknesses\": \"1. The paper assumes the Bradley-Terry model assumption, which might not hold in all cases.\\n2. The algorithm's performance might be sensitive to the choice of the softmax exponent, which could be a limitation.\\n3. The paper could benefit from more extensive experiments to demonstrate the robustness of SPO in various scenarios.\",\n  \"Questions\": \"1. How does SPO perform in cases where the Bradley-Terry model assumption does not hold?\\n2. Can the softmax exponent be learned automatically or does it require manual tuning?\\n3. Are there any potential applications of"}
{"paper_id": "Dq9VrVuLzV", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective method for generating photorealistic and geometric-controlled images for 3D occupancy prediction, which can provide an unlimited amount of diverse, annotated, and controllable datasets.\\n2. The approach innovatively incorporates 3D semantic multi-plane images (MPIs) to provide comprehensive and spatially aligned 3D scene descriptions for conditioning.\\n3. The paper provides extensive qualitative and quantitative evaluations of SyntheOcc on the nuScenes dataset, demonstrating its effectiveness in generating controllable occupancy datasets that serve as an effective data augmentation to perception models.\\n4. The paper has the potential to significantly impact the field of autonomous driving and 3D occupancy prediction.\",\n  \"Weaknesses\": \"1. The paper assumes that the availability of high-quality 3D annotations is a significant bottleneck in the development of autonomous driving systems. However, this assumption may not hold for all applications or datasets.\\n2. The paper does not provide a clear explanation of how the proposed method can be scaled to handle large and"}
{"paper_id": "73Q9U0vcja", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective approach to adaptively acquire data for solving inverse problems in imaging using a generative diffusion model and sequential experimental design.\\n2. The method is well-motivated and has the potential to significantly reduce data acquisition requirements and improve image reconstruction quality.\\n3. The experimental results on real-world tomography datasets are impressive and demonstrate the effectiveness of the proposed approach.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of a pre-trained unconditional diffusion model, which might not always be the case in practice.\\n2. The method relies on the forward model of the inverse problem, which might not always be available or accurate.\\n3. The paper could benefit from a more detailed discussion on the computational cost and scalability of the proposed approach.\",\n  \"Questions\": \"1. How does the proposed approach perform on other types of inverse problems, such as those involving different imaging modalities or more complex geometries?\\n2. Can the diffusion model be pre-trained on a smaller dataset and still achieve"}
{"paper_id": "UiEjzBRYeI", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel and generalized methodology for equipping vision foundation models with multi-grained semantic perception abilities, which is a significant contribution to the field.\\n2. The approach of establishing two types of composable prompts (Type-I and Type-II) is innovative and effective in achieving state-of-the-art performance in open-vocabulary segmentation.\\n3. The unified framework for calculating affinity between queries and SAM patches is well-designed and efficient.\\n4. The experiments demonstrate the versatility of SAM-CP in both open and closed domains, showcasing its potential for real-world applications.\",\n  \"Weaknesses\": \"1. The paper assumes that the text labels are available for all classes, which might not be the case in all scenarios.\\n2. The approach may not generalize well to other vision foundation models if they have different patching mechanisms.\\n3. The paper does not provide a thorough analysis of the computational complexity of the proposed method.\",\n  \"Questions\": \"1. How does the proposed method handle the case where the text labels are not"}
{"paper_id": "lessla98Wp", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a well-structured and well-organized approach to address the challenges of automatic video colorization. The use of language descriptions to guide the colorization process is innovative and effective. The proposed L-C4 model is well-designed and leverages the strengths of cross-modality generative models. \\n2. The experimental results are comprehensive and demonstrate the superiority of L-C4 over relevant methods. The paper also provides a clear and concise comparison with existing approaches. \\n3. The paper is well-written and easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes that the user-provided language descriptions are accurate and relevant, which might not always be the case. \\n2. The model's performance may degrade if the language descriptions are ambiguous or incomplete. \\n3. The paper does not provide a clear explanation of how the model handles out-of-vocabulary words or phrases.\",\n  \"Questions\": \"1. How does the model handle cases where the language descriptions are not accurate or relevant? \\n"}
{"paper_id": "UstOpZCESc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a critical challenge in the field of lifelong learning and machine unlearning, and presents a novel solution that integrates both objectives. The proposed method, PALL, is well-motivated and has the potential to significantly impact the development of responsible AI applications.\\n2. The paper is well-organized, and the authors provide a clear and concise explanation of their approach, including the optimization of task-specific sparse subnetworks and the episodic memory rehearsal mechanism.\\n3. The experimental results demonstrate the scalability and effectiveness of PALL across various architectures and image classification tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the task-specific sparse subnetworks can be learned efficiently, which might not always be the case, especially for complex tasks.\\n2. The authors do not provide a thorough analysis of the memory requirements of PALL, which is a critical aspect of the proposed method.\\n3. The paper could benefit from a more detailed discussion of the potential applications of PALL in real-world scenarios.\",\n  \""}
{"paper_id": "LnRegTxsa4", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Cross-view and Cross-attention Module (CVCAM) and Multi-head Spatial Attention Module (MHSAM) are novel and effective approaches to improve cross-view object geo-localization.\\n2. The creation of the G2D dataset is a valuable contribution to the field, filling a gap in existing datasets.\\n3. The method's ability to suppress edge noise and enhance feature representation is a significant improvement over existing approaches.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of aligned views, which might not be the case in real-world scenarios.\\n2. The evaluation on the CVOGL dataset is limited to a single view setup, and it is unclear how the method would perform in a multi-view setting.\\n3. The paper could benefit from a more detailed analysis of the impact of the MHSAM on the overall performance.\",\n  \"Questions\": \"1. How does the CVCAM module handle cases where the two views"}
{"paper_id": "2ErS9Bkc3O", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper provides a novel matrix-theoretic explanation of the adversarial fragility of deep neural networks.\\n2. The theoretical results show that neural network's adversarial robustness can degrade as the input dimension increases, which is consistent with an earlier information-theoretic explanation.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper's focus is mainly theoretical, and it would be interesting to see more experimental validation of the results.\\n2. The connection between the matrix-theoretic explanation and the information-theoretic explanation could be explored further.\\n3. The paper assumes a specific type of adversarial attack, and it would be interesting to see how the results generalize to other types of attacks.\",\n  \"Questions\": \"1. How do the results generalize to other types of neural networks, such as recurrent neural networks or transformers?\\n2. Can the matrix-theoretic explanation be used to improve the adversarial robustness of neural networks?\\n3. Are"}
{"paper_id": "pK3oe2bubc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors address a relevant problem in the field of neural networks, providing a solution that enables robustness to pruning, replacing, or shuffling layers at test time. This is a valuable contribution to the field.\\n2. The proposed approaches for randomizing the execution order of attention modules at training time are well-explained and the results are convincing.\\n3. The analysis of feature representations and layer contributions is thorough and provides valuable insights.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The reduction in accuracy (about 20\\%) might be a significant drawback for some applications.\\n2. The paper could benefit from a more detailed discussion of the implications of the proposed approaches on the interpretability of the models.\\n3. It is not entirely clear how the proposed approaches can be generalized to other types of neural networks beyond vision transformers.\",\n  \"Questions\": \"1. How do the proposed approaches affect the computational efficiency of the models?\\n2. Can the proposed approaches"}
{"paper_id": "sec09tLQUl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors propose a novel method, FairDropout, that effectively addresses the issue of spurious correlations in deep learning models.\\n2. The method is well-motivated and the empirical evaluation is thorough, demonstrating significant improvements on various tasks and datasets.\\n3. The paper is well-written and easy to follow.\",\n  \"Weaknesses\": \"1. The authors assume that memorization can be localized to a limited number of neurons, which might not always be the case.\\n2. The FairDropout method is specific to the task of reducing reliance on spurious correlations and might not be applicable to other problems.\\n3. The paper does not provide a clear explanation of how FairDropout can be extended to more complex models or tasks.\",\n  \"Questions\": \"1. How does FairDropout compare to other methods for reducing spurious correlations, such as data augmentation or regularization techniques?\\n2. Can FairDropout be applied to other types of neural networks, such as recurrent neural networks or transformers?\\n3."}
{"paper_id": "96jZFqM5E0", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors present a well-designed and comprehensive framework for pre-training 3D hand pose estimation from in-the-wild hand images, which is a challenging task.\\n2. The extensive collection of hand images from recent human-centric videos is impressive and provides a rich source of data for pre-training.\\n3. The proposed contrastive learning method is innovative and effective, and the adaptive weighting of contrastive learning loss based on inter-sample distance is a nice touch.\\n4. The experimental results demonstrate significant improvements over the state-of-the-art method, with gains of 15% on FreiHand, 10% on DexYCB, and 4% on AssemblyHands.\",\n  \"Weaknesses\": \"1. The paper assumes that the hand images are accessible from in-the-wild videos, which might not be the case in all scenarios.\\n2. The method relies heavily on the quality of the collected hand images, and poor-quality images might affect the performance.\\n3. The paper does not discuss the potential issues with over"}
{"paper_id": "uNd289HjLi", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel self-supervised framework, Corruption2Self (C2S), which effectively learns denoising across multiple noise levels directly from noisy data.\\n2. The GADSM loss is a significant contribution, extending denoising score matching to the ambient noise setting.\\n3. The incorporation of a reparameterization of noise levels and detail refinement extension is a good idea.\\n4. The method can be extended to multi-contrast denoising, leveraging complementary information across different MRI contrasts.\\n5. The paper achieves state-of-the-art performance among self-supervised methods and competitive results compared to supervised counterparts.\",\n  \"Weaknesses\": \"1. The paper does not provide a clear explanation of how the GADSM loss is derived and why it is effective.\\n2. The evaluation is limited to two datasets, M4Raw and fastMRI, and it would be beneficial to see the method's performance on other datasets.\\n3. The paper does not discuss the computational cost of the method and how"}
{"paper_id": "e2ONKX6qzJ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel and effective approach to address the issue of oversaturation in classifier-free guidance, which is a significant problem in diffusion models.\\n2. The proposed adaptive projected guidance (APG) method is easy to implement and introduces minimal additional computational overhead.\\n3. The paper provides extensive experiments demonstrating the effectiveness of APG in improving FID, recall, and saturation scores while maintaining precision comparable to CFG.\\n4. The connection between CFG and gradient ascent is an interesting insight that adds depth to the understanding of the problem.\",\n  \"Weaknesses\": \"1. The paper assumes that the parallel component primarily causes oversaturation, which might not be universally true.\\n2. The method may not generalize to other types of diffusion models or applications.\\n3. The paper does not provide a thorough analysis of the computational cost of the proposed method.\",\n  \"Questions\": \"1. How does the proposed method handle the trade-off between quality and oversaturation in practice?\\n2. Can the method be extended to"}
{"paper_id": "a2eBgp4sjH", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a systematic study of MultiFilterANN, covering both theoretical and empirical aspects. The theoretical results provide provable algorithms with the best known space-time tradeoffs and lower bounds for popular algorithms, which is a significant contribution to the field.\\n2. The empirical approach extends practical graph indices for standard nearest neighbor search to MultiFilterANN, and the algorithm is competitive with existing state-of-the-art solutions.\\n3. The paper fills a noticeable gap in literature by releasing multiple novel datasets for MultiFilterANN.\\n4. The work has strong practical motivation from search and recommendation applications.\\n5. The authors provide a clear and well-organized presentation of the theoretical and empirical results.\",\n  \"Weaknesses\": \"1. The paper is dense and may be challenging for readers without a strong background in algorithms and graph theory.\\n2. The empirical results are mostly based on a single dataset, and it would be beneficial to see more extensive experiments on other datasets.\\n3. The authors do not provide a clear comparison with other state"}
{"paper_id": "EIXZXPz7jU", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed method addresses a significant challenge in PINNs by introducing a novel sampling point selection method, leveraging diffusion models and optimal transport coupling flow-matching technique to generate more sampling points in regions with higher PDE residuals.\\n2. The approach avoids explicit modeling of probability density, which is a significant advantage over existing methods.\\n3. The paper demonstrates effectiveness in improving solution quality for the linear elasticity equation with complex geometry of inclusion.\\n4. The comparison with existing techniques, including normalizing flow-based sampling PINN, is comprehensive and provides valuable insights.\\n5. The method's ability to outperform existing techniques in certain scenarios is impressive.\",\n  \"Weaknesses\": \"1. The paper assumes a specific type of PDE (linear elasticity equation), and it is unclear whether the method generalizes to other types of PDEs.\\n2. The method relies on the optimal transport coupling flow-matching technique, which may not be widely applicable or easy to implement.\\n3. The paper does not provide a detailed analysis of the"}
{"paper_id": "QO4bF6MHza", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in the evaluation of large language models, specifically their mathematical reasoning abilities over long contexts.\\n2. The proposed benchmark, MathHay, is well-designed and comprehensive, covering various aspects of mathematical reasoning.\\n3. The experiments are thorough and provide valuable insights into the limitations of current LLMs.\",\n  \"Weaknesses\": \"1. The paper assumes that the reader is familiar with the context of large language models and their applications, which might limit its accessibility to a broader audience.\\n2. The paper does not provide a detailed analysis of the results, making it difficult to understand the implications of the findings.\\n3. The authors could have explored more advanced mathematical reasoning tasks to further evaluate the capabilities of LLMs.\",\n  \"Questions\": \"1. How does the authors' definition of mathematical reasoning abilities align with the actual requirements of real-world applications?\\n2. Can the MathHay benchmark be adapted to evaluate other aspects of LLMs, such as their ability to reason about natural language?\\"}
{"paper_id": "GULx8rzzjC", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a practical and effective solution to the challenge of data acquisition in machine learning, which is a significant problem in the field. The method, Mycroft, is well-designed and well-implemented, and the results are impressive. 2. The paper is well-organized and clearly presented, with a clear introduction, a well-defined problem, and a well-executed solution. 3. The paper has a strong contribution to the field, as it addresses a significant challenge in machine learning and provides a practical solution. 4. The experimental results are thorough and convincing, with four tasks in two domains showing the effectiveness of Mycroft.\",\n  \"Weaknesses\": \"1. The paper assumes that the data owners are willing to share their data, which may not always be the case. 2. The paper does not discuss the potential risks and challenges of using Mycroft, such as the potential for data leakage or the impact on data owners. 3. The paper could benefit from more discussion on the scalability of Mycroft,"}
{"paper_id": "PnZ2lbQaao", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an interesting approach to address the cold-start item problem in cross-domain recommendation systems, using an adversarial Bayesian framework. \\n2. The framework, DICF, is able to infer domain indices during cross-domain recommendation, improving performance and providing interpretability. \\n3. The empirical results on both synthetic and real-world datasets are comprehensive and verify the effectiveness of the proposed method.\",\n  \"Weaknesses\": \"1. The novelty of the approach is not entirely clear, as the concept of domain indexing is mentioned as a recent development. \\n2. The paper could benefit from a more in-depth analysis of the trade-offs between performance and interpretability. \\n3. The generalizability of the proposed method to other domains or scenarios is not extensively explored.\",\n  \"Questions\": \"1. How does the adversarial Bayesian framework, DICF, compare to other state-of-the-art methods in terms of performance and interpretability? \\n2. Are there any potential limitations or challenges in applying DICF to real-world"}
{"paper_id": "AT64R0ivUO", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel method, SteerPrompt, that effectively improves model reading comprehension by explicitly highlighting key contextual information and steering the model's attention scores.\\n2. The evaluation on open-book QA demonstrates significant improvement in problem-solving performance, with an average improvement of 7.95% for LLAMA3-70B-Instruct.\\n3. The paper is well-organized and clearly presented, with a concise abstract and introduction.\\n4. The code will be publicly available, making it easier for the community to replicate and build upon the research.\",\n  \"Weaknesses\": \"1. The paper assumes that the model's attention scores can be steered to highlight key contextual information, which might not be the case for all models or contexts.\\n2. The method relies on the quality of the input prompts, which can be challenging to craft for certain tasks or domains.\\n3. The paper does not provide a detailed analysis of the computational cost of SteerPrompt, which could be a concern for large-scale applications.\","}
{"paper_id": "nGiGXLnKhl", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an efficient architecture for vision tasks, Vision-RWKV, which demonstrates robust global processing capabilities and reduced spatial aggregation complexity.\\n2. The model's ability to process high-resolution images without window operations is a significant advantage.\\n3. The evaluation shows that VRWKV surpasses ViT's performance in image classification and has faster speeds and lower memory usage.\\n4. The code and models are available for further research and development.\",\n  \"Weaknesses\": \"1. The paper assumes that the RWKV architecture from the NLP field can be directly applied to vision tasks without significant modifications, which might not be the case.\\n2. The comparison with ViT is limited to image classification tasks, and it is unclear how VRWKV performs in other vision tasks.\\n3. The paper does not provide a clear explanation of how the reduced spatial aggregation complexity is achieved.\",\n  \"Questions\": \"1. How does VRWKV handle edge cases where the input image resolution is not a multiple of the window size?\\"}
{"paper_id": "TBJCtWTvXJ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a thorough analysis of Adam's effectiveness and ineffectiveness, revealing the importance of similarity to SignSGD in managing gradient variations. \\n2. The introduction of SignSoftSGD (S3) is well-motivated and provides a clear explanation of its advantages over Adam. \\n3. The theoretical analysis of S3 on a general nonconvex stochastic problem demonstrates its optimal convergence rate under weak assumptions. \\n4. The experimental results show that S3 achieves rapid convergence and improved performance, with rare loss spikes even at a 10x larger learning rate.\",\n  \"Weaknesses\": \"1. The paper assumes a good understanding of optimization algorithms and their convergence properties, which may limit its accessibility to a broader audience. \\n2. The authors could have provided more insights into the practical implications of using S3 in real-world scenarios, such as training large-scale models or handling non-stationary data.\",\n  \"Questions\": \"1. How does the choice of p in S3 affect its performance"}
{"paper_id": "8gSrJOL2oc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses three significant limitations of existing CZSL approaches, providing a comprehensive solution. \\n2. The proposed TRIDENT framework is well-organized and clearly presented, with a clear explanation of each component's contribution. \\n3. The use of MLLM embeddings and attribute smoothing through LLM-generated auxiliary attributes is innovative and effective.\\n4. The extensive experiments demonstrate the superiority of TRIDENT over existing methods on three challenging datasets.\",\n  \"Weaknesses\": \"1. The paper assumes that the background can be mitigated using FAA modules, which might not always be the case, especially in scenarios with complex or dynamic backgrounds.\\n2. The reliance on LLM-generated auxiliary attributes might limit the generalizability of TRIDENT to domains with limited or no text data.\\n3. The paper could benefit from a more in-depth analysis of the impact of each component of the TRIDENT framework on the overall performance.\",\n  \"Questions\": \"1. How does TRIDENT perform on scenarios with complex or dynamic backgrounds, and are"}
{"paper_id": "yheQRc5xWB", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective approach to tackle the TCP task by introducing a counterfactual Mamba model with Covariate-based Decorrelation towards Selective Parameters (Mamba-CDSP), which outperforms baselines by a large margin and exhibits prominent running efficiency.\\n2. The method is well-motivated and theoretically sound, addressing the over-balancing problem in TCP of the direct covariate balancing methods.\\n3. The paper is well-organized and clearly presented, with a clear and concise writing style.\",\n  \"Weaknesses\": \"1. The paper assumes that the SSMs can capture interactions in long sequences effectively, but the performance of SSMs may degrade when dealing with very long sequences or complex interactions.\\n2. The approach may not be applicable to all types of TCP tasks, as it relies on the assumption that the covariates are correlated with the treatment and outcome.\\n3. The paper does not provide a detailed comparison with other state-of-the-art methods, which may limit the general"}
{"paper_id": "HxKSzulSD1", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses an important issue in superalignment, which is the potential for weak-to-strong deception. This is a significant contribution to the field, and the authors provide a clear and concise explanation of the problem and its implications.\\n2. The experiments are thorough and well-designed, and the results provide strong evidence for the existence of the weak-to-strong deception phenomenon.\\n3. The paper highlights the need for more attention to the true reliability of superalignment, which is a crucial aspect of this area of research.\",\n  \"Weaknesses\": \"1. The paper is somewhat narrow in scope, focusing on a specific case of multi-objective alignment with conflicting targets. It would be beneficial to explore other scenarios to further generalize the findings.\\n2. The bootstrapping with an intermediate model is a useful mitigation strategy, but its effectiveness is limited. It would be interesting to explore other methods to address the deception phenomenon.\\n3. The paper could benefit from a more detailed discussion of the implications of the weak-to-strong deception phenomenon for the"}
{"paper_id": "wH8XXUOUZU", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to accelerate high-resolution diffusion models by introducing Residual Autoencoding and Decoupled High-Resolution Adaptation, which effectively improves the spatial compression ratio while maintaining reconstruction quality.\\n2. The proposed method is well-motivated, and the experimental results demonstrate its effectiveness in accelerating inference and training of UViT-H on ImageNet 512x512.\\n3. The paper is well-organized and clearly presented, with a concise introduction to the problem and a clear explanation of the proposed method.\",\n  \"Weaknesses\": \"1. The paper assumes that the reader is familiar with the basics of autoencoders and diffusion models, which might limit its accessibility to a broader audience.\\n2. The experimental results are mostly focused on a single application (UViT-H on ImageNet 512x512), and it would be beneficial to provide more comprehensive evaluation on a wider range of models and datasets.\\n3. The paper does not provide a detailed analysis of the computational resources required for the proposed method, which"}
{"paper_id": "QWIg5e6mtT", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a clear and well-structured introduction to the problem of heterogeneous team games and the limitations of existing PSRO frameworks.\\n2. The proposed H-PSRO framework is well-motivated and effectively addresses the issue of insufficient policy expressiveness in Team PSRO.\\n3. The paper presents thorough empirical results that demonstrate the effectiveness of H-PSRO in achieving lower exploitability and convergence in heterogeneous team games.\\n4. The authors provide a clear and concise explanation of their approach and its advantages over existing methods.\\n5. The paper is well-organized and easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes that the heterogeneous policies can be parameterized, which may not always be the case in real-world scenarios.\\n2. The sequential optimization approach may not be scalable for very large team games.\\n3. The paper does not provide a clear comparison with other state-of-the-art methods for heterogeneous team games.\",\n  \"Questions\": \"1. How does H-PSRO perform in"}
{"paper_id": "kbSU5bwoRv", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to singing voice conversion (SVC) that achieves zero-shot performance, which is a significant contribution to the field. The use of multiple ASR models and speaker embedding is innovative and effective.\\n2. The establishment of a large-scale dataset is crucial for zero-shot SVC tasks and will benefit the research community.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the ASR models are accurate, which might not always be the case. How does the paper address the potential errors in ASR models?\\n2. The paper does not discuss the computational cost of the proposed method, which might be a concern for practical applications.\",\n  \"Questions\": \"1. Can the proposed method be applied to other types of audio conversion tasks, such as speech-to-singing or singing-to-speech?\\n2. How does the paper handle cases where the speaker embedding is not available or is not accurate?\"\n}"}
{"paper_id": "KyqtKhv6q1", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective framework for learning spatial priors from historic traversals, which can be easily integrated into leading 3D perception systems at little to no extra computational costs.\\n2. The evaluation is comprehensive and systematic, showcasing significant and consistent improvement in 3D object detection and semantic map segmentation tasks on the nuScenes dataset across several architectures.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The novelty of the approach is somewhat diminished by the fact that it relies on historic traversals, which may not be available in all scenarios.\\n2. The paper does not provide a thorough discussion on how to handle cases where the historic traversals are limited or biased.\\n3. The impact of the approach on other tasks, such as motion forecasting or motion planning, is not explored.\",\n  \"Questions\": \"1. How does the approach handle cases where the historic traversals are limited or biased?\\n2. Can the approach be extended to other types of"}
{"paper_id": "lTL4t68BNc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a novel connection between the Information Bottleneck (IB) principle and the robustness of Graph Neural Networks (GNNs), which is a significant contribution to the field. The observation that lower IB loss correlates with better adherence to the IB principle and stronger robustness against graph adversarial attacks is insightful and well-supported by experiments.\\n2. The proposed Robust Graph Attention inspired by Information Bottleneck (RGA-IB) method is well-designed and effectively minimizes the IB loss, leading to improved node classification accuracy under graph adversarial attacks.\\n3. The experimental results are comprehensive and demonstrate the effectiveness of RGA-IB on semi-supervised node classification tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the graph structure is available during training, which might not be the case in real-world scenarios where graph structures are unknown or changing.\\n2. The evaluation of RGA-IB is limited to semi-supervised node classification tasks and does not consider other types of graph tasks, such as link prediction"}
{"paper_id": "hWmwL9gizZ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant challenge in reverse vaccinology with a novel deep learning solution, ProVaccine, that outperforms existing methods.\\n2. The comprehensive immunogenicity dataset is a valuable resource for the field.\\n3. The post-hoc validation protocol is a useful tool for assessing the practical significance of deep learning models in vaccine design.\\n4. The work sets valuable benchmarks for future research.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of pre-trained latent vector representations, which might not be feasible for all research groups.\\n2. The evaluation metrics used are not explicitly explained, making it difficult to understand the comparison with existing methods.\\n3. The post-hoc validation protocol is not clearly explained, and its practical significance is not fully explored.\",\n  \"Questions\": \"1. How does ProVaccine handle cases where the pre-trained latent vector representations are not available or are of poor quality?\\n2. Can the authors provide more details on the evaluation metrics used and their choice of"}
{"paper_id": "IL85Ebjg9j", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to resolving conflicts in multi-view classification, which is an essential problem in real-world applications.\\n2. The computational trust-based discounting method is an interesting and innovative extension to the Evidential Multi-view framework.\\n3. The experimental results are comprehensive and demonstrate the effectiveness of the proposed method.\",\n  \"Weaknesses\": \"1. The paper assumes that the reliability of predictions made by individual views can be measured using an instance-wise probability-sensitive trust discounting mechanism, which might not be applicable to all real-world scenarios.\\n2. The evaluation metrics used, such as Top-1 Accuracy, Fleiss\u2019 Kappa, and Multi-View Agreement with Ground Truth, might not capture all aspects of the proposed method\u2019s performance.\\n3. The paper could benefit from a more in-depth analysis of the AUROC results and their implications for uncertainty measures indicating prediction correctness.\",\n  \"Questions\": \"1. Can the computational trust-based discounting method be applied to other multi-view classification problems beyond the ones considered"}
{"paper_id": "cnKhHxN3xj", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel measure for estimating neuronal entanglement using the Wasserstein distance, which is a significant contribution to the field of interpretability of large language models.\\n2. The experimental framework for disentangling polysemantic neurons is well-designed and provides strong evidence for the effectiveness of the approach.\\n3. The paper is well-organized and clearly presented, with a clear explanation of the methodology and results.\",\n  \"Weaknesses\": \"1. The paper assumes that the Wasserstein distance is a good measure of entanglement, but it is not clear if this is always the case.\\n2. The paper only considers a limited number of models and tasks, which may not be representative of the broader field.\\n3. The experimental framework is complex and may be difficult to reproduce.\",\n  \"Questions\": \"1. How does the Wasserstein distance measure relate to other measures of entanglement, and are there any limitations to its use?\\n2. Can the approach be applied to other types of neural networks,"}
{"paper_id": "dgR6i4TSng", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel quantum parameterization that achieves a significant reduction in the number of trainable parameters compared to LoRA-based methods.\\n2. The authors demonstrate the effectiveness of Quantum-PEFT on several transfer learning benchmarks in language and vision, showcasing its competitive performance and parameter efficiency.\\n3. The paper is well-written and easy to follow, with clear explanations of the methodology and results.\",\n  \"Weaknesses\": \"1. The paper assumes a strong background in quantum computing and linear algebra, which may limit its accessibility to a broader audience.\\n2. The evaluation is limited to a few transfer learning benchmarks, and it is unclear whether the results would generalize to other domains or tasks.\\n3. The paper could benefit from a more detailed discussion on the potential applications and limitations of Quantum-PEFT in real-world scenarios.\",\n  \"Questions\": \"1. How does the quantum unitary parameterization compare to other low-rank approximations, such as LoRA, in terms of accuracy and computational efficiency?\\n2. Can"}
{"paper_id": "ye1mxb79lw", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel algorithm for Bilevel Bayesian Optimization (BILBO) that optimizes both upper- and lower-level problems jointly in a sample-efficient manner.\\n2. The use of confidence bounds to construct trusted sets of feasible and lower-level optimal solutions is an innovative approach.\\n3. Theoretical guarantees of sublinear regret bound and instantaneous regret bounds for the query point are significant contributions.\\n4. The empirical evaluation on synthetic and real-world problems demonstrates the effectiveness of BILBO.\\n5. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of derivative-free and noisy evaluations, which might limit its applicability to certain real-world problems.\\n2. The extension of BILBO to more complex bilevel optimization problems with multiple upper-level objectives is not discussed.\\n3. The choice of the confidence bound used to construct trusted sets might be problem-dependent and requires further investigation.\",\n  \"Questions\": \"1. How does BILBO handle cases"}
{"paper_id": "1fwZJzGdKj", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper tackles an important problem in large language model pretraining, addressing the inherent conflicts between data selection methods. This is a significant contribution to the field.\\n2. The proposed multi-agent collaborative data selection mechanism is novel and well-designed, with a clear explanation of its components and benefits.\\n3. The experimental results are thorough and demonstrate the effectiveness of the approach, with significant improvements in data efficiency and model performance.\\n4. The paper is well-organized and clearly presented, with a logical flow of ideas and concise writing.\",\n  \"Weaknesses\": \"1. The paper assumes that the agents' prioritization rules can be updated based on the current state of the model, which might not always be the case, especially in the early stages of training.\\n2. The experimental results are based on a limited set of language model benchmarks, and it would be beneficial to evaluate the approach on a broader range of tasks and models.\\n3. The paper does not provide a detailed analysis of the computational cost of the multi-agent framework"}
{"paper_id": "pISLZG7ktL", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a comprehensive and systematic study on data scaling in imitation learning for robotic manipulation, which is a significant contribution to the field.\\n2. The authors collect a large-scale dataset with over 40,000 demonstrations and execute 15,000 real-world robot rollouts, demonstrating the feasibility of their approach.\\n3. The findings on the power-law relationship between generalization performance and the number of environments and objects are intriguing and provide valuable insights for future research.\\n4. The proposed data collection strategy is efficient and can be applied to other tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the policy can be deployed zero-shot for any object within the same category in any environment, which might be overly optimistic.\\n2. The study only considers a specific type of robotic manipulation and does not explore other tasks or environments.\\n3. The authors do not provide a clear explanation of how the power-law relationship was derived and validated.\",\n  \"Questions\": \"1. How can the findings on the power-law relationship"}
{"paper_id": "dML3XGvWmy", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and innovative approach to self-improvement in agents, leveraging large language models to dynamically modify their own logic and behavior.\\n2. The experimental results demonstrate the effectiveness of G\u00f6del Agent in achieving continuous self-improvement and surpassing manually crafted agents in performance, efficiency, and generalizability.\\n3. The paper is well-organized and clearly presented, with a clear and concise writing style.\",\n  \"Weaknesses\": \"1. The paper assumes that high-level objectives can be effectively used to guide the self-improvement process, which might not always be the case in complex and dynamic environments.\\n2. The reliance on large language models might limit the applicability of G\u00f6del Agent to specific domains or tasks where such models are not effective.\\n3. The paper could benefit from a more detailed analysis of the trade-offs between self-improvement and other factors, such as computational resources and interpretability.\",\n  \"Questions\": \"1. How does G\u00f6del Agent handle the potential risks of self"}
{"paper_id": "xlxGsX1pc7", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant gap in the evaluation of mathematical skills in LLMs, and proposes a novel benchmark (U-MATH) and dataset ($\\mu$-MATH) to evaluate the capabilities of LLMs in judging solutions to open-ended university-level math problems.\\n2. The paper is well-organized and clearly presented, with a clear structure and concise writing.\\n3. The evaluation of LLMs on U-MATH and $\\mu$-MATH provides valuable insights into the challenges presented by these tasks.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed discussion of the limitations of the current benchmarks and the motivation for creating U-MATH and $\\mu$-MATH.\\n2. The evaluation of LLMs on U-MATH and $\\mu$-MATH is primarily focused on accuracy, and it would be interesting to explore other evaluation metrics, such as the quality of the solutions generated by the LLMs.\\n3. The paper assumes that the L"}
{"paper_id": "AjXkRZIvjB", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant concern in the field of LLMs by investigating the reliability of GSM8K benchmark and proposing an improved benchmark, GSM-Symbolic. This work is timely and relevant to the current research landscape.\\n2. The study provides a comprehensive analysis of the limitations of LLMs in mathematical reasoning, including the variance in responses to different instantiations of the same question and the decline in performance with increasing number of clauses in a question.\\n3. The paper is well-organized and clearly presented, with a logical flow of ideas and a clear explanation of the methodology and results.\",\n  \"Weaknesses\": \"1. The paper's conclusion that current LLMs are not capable of genuine logical reasoning may be too broad, as it is based on a specific experiment with a particular benchmark.\\n2. The study's focus on the GSM-Symbolic benchmark may limit the generalizability of the findings to other types of mathematical reasoning tasks.\\n3. The paper could benefit from a more detailed discussion of the"}
{"paper_id": "IJiTI0fB0e", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to quantify the prompt-induced and model-induced diversity in samples generated by prompt-based models.\\n2. The information-theoretic approach provides a clear and interpretable way to decompose the existing Vendi diversity score.\\n3. The numerical experiments demonstrate a correlation between the Conditional-Vendi score and the internal diversity of text-conditioned generative models.\",\n  \"Weaknesses\": \"1. The paper assumes a fixed prompt distribution and does not consider the effect of varying the prompt distribution on the Conditional-Vendi score.\\n2. The authors could provide more detailed analysis of the Information-Vendi score and its relationship with the Conditional-Vendi score.\\n3. The paper could benefit from more extensive experiments to demonstrate the robustness of the proposed approach.\",\n  \"Questions\": \"1. How does the Conditional-Vendi score behave when the prompt distribution is not fixed, but rather varies across different tasks or domains?\\n2. Can the Information-Vendi score be used to evaluate the diversity of generated samples in other"}
{"paper_id": "fs2Z2z3GRx", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed algorithm, FIG, efficiently guides the reverse-time sampling process with measurement interpolants, which is a novel and theoretically justified approach.\\n2. The experimental results demonstrate that FIG produces highly competitive results on various linear image reconstruction tasks, especially for challenging scenarios.\\n3. The paper is well-organized and clearly presented, with a clear introduction to the problem, a concise explanation of the proposed method, and a thorough evaluation of the results.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more in-depth discussion of the theoretical justifications for the proposed method.\\n2. While the results are impressive, it would be helpful to see more detailed analysis of the performance of FIG in comparison to other state-of-the-art methods, especially for specific types of measurement noise or ill-posedness.\\n3. The paper mentions that code will be released, but it would be better to provide the code alongside the paper.\",\n  \"Questions\": \"1. Can FIG be adapted for non-linear inverse problems, or is it"}
{"paper_id": "H4FSx06FCZ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective solution to address the challenges of 3D steganography, providing a secure and efficient framework for protecting 3D assets.\\n2. The proposed SecureGS framework utilizes a hybrid decoupled Gaussian encryption mechanism and a density region-aware anchor growing and pruning strategy, demonstrating significant improvements in rendering fidelity, speed, and security.\\n3. The paper's contributions are well-organized and clearly presented, with a comprehensive evaluation of the proposed method against existing GS steganography methods.\",\n  \"Weaknesses\": \"1. The paper assumes that the anchor point features are publicly accessible, which may not be the case in all scenarios. This could impact the security of the proposed framework.\\n2. The evaluation of the proposed method is mostly focused on rendering fidelity, speed, and security, but the paper could have provided more insights into the potential applications and limitations of SecureGS.\",\n  \"Questions\": \"1. How does the proposed framework handle cases where the anchor point features are not publicly accessible?\\n"}
{"paper_id": "OGtUfA6Amo", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed hierarchical patch graph network (Hi-Patch) is well-suited for modeling Irregular Multivariate Time Series (IMTS) and can effectively capture both local and global temporal and inter-variable dependencies.\\n2. The paper provides a comprehensive experimental evaluation on 8 datasets, demonstrating the superiority of Hi-Patch over state-of-the-art models in both forecasting and classification tasks.\\n3. The authors provide a clear and well-organized presentation of the method and its application.\",\n  \"Weaknesses\": \"1. The paper assumes that the variables in the IMTS have distinct original scales/sampling rates, but it is unclear how the method would perform when this assumption is violated.\\n2. The paper does not provide a detailed analysis of the computational complexity of the proposed method.\\n3. The authors do not discuss the potential limitations and challenges of applying Hi-Patch to real-world datasets with complex temporal and inter-variable dependencies.\",\n  \"Questions\": \"1. How does the method handle missing values or noisy data in the IMTS"}
{"paper_id": "ujpAYpFDEA", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a crucial issue in LLM watermarking, namely the imperceptibility of watermarks, which is essential for real-world applications.\\n2. The proposed Water-Probe algorithm is well-designed and effectively detects watermarks in LLMs.\\n3. The introduction of the Water-Bag strategy is a significant contribution to improving watermark imperceptibility.\\n4. The experiments demonstrate the effectiveness of Water-Probe and Water-Bag in various scenarios.\",\n  \"Weaknesses\": \"1. The paper assumes that the watermark key is consistent across all watermarked LLMs, which might not always be the case in real-world scenarios.\\n2. The evaluation of Water-Bag's imperceptibility is limited to a single experiment, and more comprehensive evaluation is needed.\\n3. The paper does not discuss the potential attacks that could be used to compromise the watermarking system.\",\n  \"Questions\": \"1. How do you plan to address the issue of inconsistent watermark keys in real-world scenarios?\\n2. Can you"}
{"paper_id": "7UKHNQIErp", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a clear and well-structured framework for understanding and characterizing DPA losses, making it easier to reason about the semantics of these algorithms.\\n2. The proposed formalism is novel and provides a systematic way to derive symbolic expressions for DPA losses, enabling the exploration of the DPA loss landscape.\\n3. The paper sheds new light on the relationships between recent loss proposals and provides a foundation for future research in human-AI alignment.\",\n  \"Weaknesses\": \"1. The paper assumes a strong background in formal methods and discrete reasoning, which may limit its accessibility to a broader audience.\\n2. The scope of the paper is somewhat narrow, focusing on a specific aspect of DPA losses, and it may not fully capture the complexity of the broader field of human-AI alignment.\\n3. Some of the notation and terminology used in the paper may be unclear to readers without a strong background in formal methods.\",\n  \"Questions\": \"1. How does the proposed formalism extend to more complex DPA"}
{"paper_id": "CpgWRFqxhD", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a comprehensive approach to address the challenges of audio-lip synchronization, long-term identity consistency, and natural expressions in generated talking videos. The proposed Memory-guided EMOtion-aware diffusion (MEMO) model is well-designed and effectively addresses these challenges.\\n2. The paper provides extensive experiments and comparisons with state-of-the-art methods, demonstrating the superiority of MEMO in generating realistic talking videos.\\n3. The model is trained on a large-scale dataset without relying on facial inductive biases, making it a significant contribution to the field.\\n4. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the audio and video are synchronized, but it does not address how to handle cases where the audio and video are not synchronized.\\n2. The model is complex and may require significant computational resources to train and generate videos.\\n3. The paper does not provide a clear explanation of how the memory-guided temporal module and emotion-aware audio module interact and affect each"}
