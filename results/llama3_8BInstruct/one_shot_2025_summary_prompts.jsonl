{"paper_id": "u3xwwfHmBC", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective approach to capturing spatio-temporal dependencies in traffic forecasting using Tri-Tense Former (TTformer), which outperforms existing models. This work has the potential to significantly impact the field of traffic forecasting.\\n2. The use of contrastive learning with negative filtering is an interesting technique to improve robustness against missing data, and the absence of predefined adjacency matrices is a significant advantage.\\n3. The paper is well-organized and clearly presented, with a clear hypothesis, method, and conclusion.\",\n  \"Weaknesses\": \"1. The paper's reliance on Graph Attention Networks (GAT) as the base architecture might limit its generalizability to other domains or applications beyond traffic forecasting.\\n2. The evaluation of the TTformer model is primarily conducted on two real-world traffic datasets, METR-LA and PEMS-BAY, and it would be beneficial to test its performance on a broader range of datasets to ensure its robustness.\\n3. The paper does not provide a detailed analysis"}
{"paper_id": "YKvBiRWdQC", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a challenging and well-structured benchmark for evaluating cooperative multi-agent RL agents in generalisation scenarios, addressing a significant gap in current research.\\n2. The proposed Overcooked Generalisation Challenge (OGC) is a comprehensive and realistic testbed for evaluating agents' abilities to perform zero-shot cooperation with new partners and in new environments.\\n3. The use of unsupervised environment design (UED) and dual curriculum design (DCD) algorithms, along with novel neural network architectures, is a significant contribution to the field.\",\n  \"Weaknesses\": \"1. The paper assumes a high level of background knowledge in multi-agent RL and cooperative settings, which might limit its accessibility to a broader audience.\\n2. The evaluation of the proposed OGC is mostly based on state-of-the-art DCD algorithms, which struggle with the challenge, making it challenging to draw conclusions about the effectiveness of the OGC itself.\\n3. The paper could benefit from more detailed discussions on the limitations and potential biases of the OGC,"}
{"paper_id": "tePFpDgyqg", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant challenge in the field of large language models, providing a scalable solution for constructing high-quality long documents. \\n2. The method of leveraging referral relationships from web pages to construct long documents is innovative and practical. \\n3. The experimental results demonstrate a significant improvement in model performance using the proposed LongPack data pipeline.\\n4. The paper highlights the importance of long-distance referrals in long-context training, providing valuable insights into the nature of effective training data.\",\n  \"Weaknesses\": \"1. The paper assumes that web pages are a reliable source of high-quality long documents, which might not always be the case. \\n2. The scalability of LongPack may be limited by the availability of web pages with rich referral relationships.\\n3. The paper does not extensively explore the impact of different types of referral signals on the quality of constructed documents.\",\n  \"Questions\": \"1. How does the choice of web page source affect the quality and diversity of the constructed long documents?\\n2. Can the Long"}
{"paper_id": "gx3LMRB15C", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors present a novel augmentation-free self-supervised learning method for tabular data, which is a significant contribution to the field.\\n2. The proposed method, T-JEPA, effectively learns rich representations of tabular data without relying on data augmentations.\\n3. The method's ability to identify relevant features without access to labels and avoid representation collapse during training is impressive.\",\n  \"Weaknesses\": \"1. The paper assumes that the tabular data has a fixed structure, which might not hold for all real-world datasets.\\n2. The authors do not provide a clear comparison with other augmentation-free self-supervised learning methods for tabular data.\\n3. The experiments seem to be limited to a few datasets, and more comprehensive evaluation is necessary to fully assess the method's performance.\",\n  \"Questions\": \"1. Can T-JEPA be applied to tabular data with varying structures or missing values?\\n2. How does T-JEPA handle concept drift or evolving data distributions?\\n3. Are there"}
{"paper_id": "kTH3bEH6hW", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed range-limited augmentation strategy is well-motivated and effectively addresses the challenge of preserving task-relevant information in tabular data.\\n2. The method is simple yet effective, and the results on the FeSTa benchmark demonstrate its robustness in few-shot classification tasks.\\n3. The evaluation is comprehensive, comparing the proposed method with 31 algorithms across different few-shot scenarios.\",\n  \"Weaknesses\": \"1. The idea of limiting augmentations to predefined feature-specific ranges is not entirely novel, and similar approaches have been explored in other domains.\\n2. The method's effectiveness is largely dependent on the selection of the augmentation's selection ratio, which may require further investigation to determine the optimal value.\\n3. The paper could benefit from a more in-depth analysis of the method's limitations and potential edge cases.\",\n  \"Questions\": \"1. How does the proposed range-limited augmentation strategy compare to other approaches that utilize distributional proximity, such as k-nearest neighbors or density-based methods?\\n2. Can"}
{"paper_id": "EqcLAU6gyU", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed framework for agent-oriented planning in multi-agent systems effectively addresses the issues of solvability, completeness, and non-redundancy in task decomposition and allocation. This is a significant contribution to the field.\\n2. The integration of a reward model, detector, and feedback loop for continuous improvement of the meta-agent's performance is a well-designed approach.\\n3. The framework demonstrates notable advancements in problem-solving over existing strategies, showcasing its effectiveness in real-world applications.\",\n  \"Weaknesses\": \"1. The framework relies heavily on LLMs, which can be biased and may not generalize well to all domains.\\n2. The evaluation of the framework's performance is primarily based on empirical results, and further theoretical analysis would strengthen the argument.\\n3. The framework's scalability and adaptability to complex, large-scale systems are not thoroughly discussed.\",\n  \"Questions\": \"1. How does the reward model assess the solvability of sub-tasks without actual agent calls, and what are the implications for task decomposition and"}
{"paper_id": "qrTrnrEi9d", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an innovative approach to address the challenge of low-resource languages in information extraction tasks.\\n2. The method, TransFusion, is well-designed and shows promising results on multilingual IE datasets.\\n3. The use of English translations of low-resource language data and annotation fusion is a clever idea.\",\n  \"Weaknesses\": \"1. The authors primarily focus on the effectiveness of TransFusion in low-resource languages, but the evaluation on high-resource languages is limited.\\n2. The method relies on the availability of high-quality English translations, which might not always be feasible.\\n3. The paper does not explore the potential of using other languages for translation.\",\n  \"Questions\": \"1. How does the performance of TransFusion degrade when the quality of English translations is poor?\\n2. Can the method be adapted for other NLP tasks beyond information extraction?\\n3. How does the proposed method compare to other approaches that leverage multilingual pre-training?\"\n}"}
{"paper_id": "Bp0HBaMNRl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a comprehensive solution to the limitations of existing causal discovery methods by proposing a differentiable causal discovery method that relaxes previous assumptions about latent variables and exogenous noise.\\n2. The theoretical identifiability results and continuous optimization technique using variational autoencoders (VAEs) with Gumbel-softmax are innovative and well-executed.\\n3. The paper demonstrates the method's scalability and accuracy on both synthetic and real-world high-dimensional image data.\",\n  \"Weaknesses\": \"1. The method assumes a specific form for the VAE, which might limit its applicability to other problem settings.\\n2. The paper does not discuss potential issues with overfitting or the impact of the Gumbel-softmax on the optimization process.\\n3. The transfer learning tasks on MNIST might not be representative of all real-world scenarios.\",\n  \"Questions\": \"1. How would the method perform on more complex, high-dimensional datasets with non-linear relationships?\\n2. Can the method be applied to other domains"}
{"paper_id": "JzLcKWtGnl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a crucial gap in 3D vision-language models by effectively capturing multi-level spatial information for detailed 3D reasoning and generation tasks.\\n2. The proposed Spatial 3D-LLM model exhibits superior capabilities in spatial perception and reasoning for 3D vision-language tasks.\\n3. The novel dataset MODLE provides a comprehensive benchmark for 3D instruction tasks, enabling the evaluation of the model's performance.\\n4. The paper's progressive spatial awareness scheme is an innovative approach to enhancing spatial embeddings of 3D scenes.\",\n  \"Weaknesses\": \"1. The paper's focus on 3D spatial intelligence might be too narrow, and the authors could have explored more general applications of their method.\\n2. The model's performance gains are impressive, but the analysis of the results could be more comprehensive.\\n3. The paper does not discuss potential challenges in extending the model to more complex 3D scenes or real-world applications.\",\n  \"Questions\": \"1. How does the progressive spatial awareness"}
{"paper_id": "hXJrQWIoR3", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors address a significant gap in explainable graph representation learning, proposing a framework that effectively learns and explains graph representations using graph pattern analysis.\\n2. The proposed methods outperform baseline models in both accuracy and interpretability, demonstrating substantial contributions to the field.\\n3. The framework's ability to incorporate multiple graph patterns and provide theoretical analyses on robustness and generalization ability is a notable strength.\\n4. The experiments conducted on real-world datasets provide a comprehensive evaluation of the proposed methods.\",\n  \"Weaknesses\": \"1. The paper assumes that graph patterns can provide a clear understanding of graph representations, but it is unclear whether this assumption holds true for all types of graph-structured data.\\n2. The framework's reliance on graph pattern analysis may limit its applicability to other types of data or domains.\\n3. The authors do not provide a detailed discussion on the potential limitations and challenges of their proposed methods.\",\n  \"Questions\": \"1. How does the framework's performance change when applied to graph-structured data with"}
{"paper_id": "67sSPPAZiG", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in the field by introducing a large-scale egocentric video dataset and a novel model architecture, significantly advancing the area of research. \\n2. The proposed approach of creating a multimodal foundation model specifically designed for egocentric video understanding is innovative and effective. \\n3. The introduction of a de-biasing mechanism in the evaluation benchmark EgoMemoria is a valuable contribution to the field.\",\n  \"Weaknesses\": \"1. While the dataset creation strategy is novel, it may be challenging to scale to other domains or modalities. \\n2. The Memory Pointer Prompting mechanism in the MM-Ego model may not generalize well to videos with significantly different characteristics or formats. \\n3. The computational efficiency of the MM-Ego model may be compromised for very long videos or those with high visual complexity.\",\n  \"Questions\": \"1. How does the MM-Ego model handle scenarios where the video content is significantly different from the training data, such as videos with different lighting conditions"}
{"paper_id": "kjmLabjSE2", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses an important open question in differential privacy and provides a convergent privacy loss bound for Noisy-SGD without the need for convexity or smoothness. This is a significant improvement over existing methods.\\n2. The analysis is technically sound and well-motivated, with clear explanations of the H\\\"older reduction lemma and forward Wasserstein distance tracking.\\n3. The paper provides a more general and applicable result, allowing for a wider class of problems to benefit from the proposed method.\",\n  \"Weaknesses\": \"1. The paper assumes H\\\"older continuous gradients, which might not be easily verifiable in practice, especially for non-convex losses.\\n2. The analysis relies on a specific mini-batch strategy, which might not be the most common or practical choice in real-world applications.\",\n  \"Questions\": \"1. Can the proposed method be extended to accommodate other types of gradient discontinuities, such as those caused by adversarial examples?\\n2. How does the H\\\"older reduction lemma relate"}
{"paper_id": "I18MA5DjoP", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors propose a novel framework, Neuron Predictability Lens (NPL), to analyze and understand the internal workings of transformer-based LLMs, which is a significant contribution to the field.\\n2. The study provides a comprehensive analysis of neuron predictability, shedding light on the role of neurons within FFNs and their contribution to model behavior.\\n3. The NPL framework has the potential to enhance model efficiency and effectiveness in language processing tasks.\\n4. The study uses LLaMA-2 and GPT-J models to evaluate neuron predictability, providing a clear and systematic evaluation.\",\n  \"Weaknesses\": \"1. The paper focuses primarily on the predictability of neuron activations within transformer-based LLMs, which might be seen as a narrow scope, given the complexity of the models.\\n2. The study relies on the assumption that neuron predictability is a useful proxy for understanding model behavior, which might not always hold true.\\n3. The application of the NPL framework is still in its infancy, and"}
{"paper_id": "qpDqO7qa3R", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel and effective approach to video restoration using pre-trained image restoration diffusion models, achieving impressive results without retraining or fine-tuning.\\n2. The method is versatile and can work with any pre-trained 2D image restoration diffusion model, making it a powerful tool for various video enhancement tasks.\\n3. The evaluation is thorough and demonstrates the method's superiority over existing state-of-the-art models in terms of quality and consistency.\",\n  \"Weaknesses\": \"1. The paper assumes a high level of prior knowledge in the field, which may make it challenging for non-experts to understand the technical details of the method.\\n2. The evaluation only focuses on a few specific datasets and tasks, and it would be beneficial to see more comprehensive evaluations on various datasets and tasks.\\n3. The paper does not discuss potential limitations or potential pitfalls of the proposed method.\",\n  \"Questions\": \"1. How does the method handle different types of degradation in the input video, such as different types of noise or different levels"}
{"paper_id": "dSQtMx6dPE", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant concern in graph prompt learning, providing a practical solution to mitigate privacy risks. The use of the PATE framework is a good approach. \\n2. The evaluation on various graph prompt methods, GNN architectures, and pre-training strategies is comprehensive and systematic. \\n3. The paper highlights substantial privacy risks in conventional methods, providing a clear call to action for the community.\",\n  \"Weaknesses\": \"1. The authors claim to provide strong privacy guarantees, but it is unclear how these guarantees are quantified, and how they compare to other existing methods. \\n2. The paper assumes that the pre-trained GNNs are available, which may not be the case in many real-world scenarios. \\n3. The experiments only evaluate the proposed methods on a limited set of datasets, and more comprehensive evaluation is needed to assess their generalizability.\",\n  \"Questions\": \"1. How do the proposed methods compare to other differential privacy methods, such as DP-SGD, in terms of privacy-"}
{"paper_id": "GbgCRJedQ7", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Sparse Matrix Tuning (SMT) method addresses a significant performance gap between parameter-efficient fine-tuning (PEFT) and full fine-tuning (FT) methods, making it a valuable contribution to the field.\\n2. The approach successfully overcomes the performance plateau issues associated with low-rank adaptation methods, such as LoRA.\\n3. The evaluation is comprehensive, comparing SMT with state-of-the-art PEFT methods and demonstrating its superiority in accuracy across various tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the performance gap between PEFT and FT methods is due to the low-rank adaptation methods, but it would be beneficial to provide more theoretical justification or empirical evidence to support this claim.\\n2. The impact of SMT on other types of models or tasks is not thoroughly explored, which could be a limitation of the proposed method.\",\n  \"Questions\": \"1. How does the proposed SMT method handle the potential overfitting issue when selecting sparse sub-matrices during the"}
{"paper_id": "ZZVOrId3yN", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel architecture for multimodal medical image segmentation, addressing domain shift issues and ensuring effective cross-modal information flow.\\n2. The use of a Joint Adversarial Domain Adaptation framework is innovative and ensures alignment of marginal and conditional distributions while preserving topological structures.\\n3. The extensive experiments on the MM-WHS dataset demonstrate superior performance and generalization.\\n4. The paper provides a robust theoretical foundation for future research in multimodal medical image segmentation.\",\n  \"Weaknesses\": \"1. The paper assumes that the reader is familiar with the MM-WHS dataset and the specific challenges of multimodal medical image segmentation.\\n2. The novelty of the Joint Adversarial Domain Adaptation framework could be further emphasized and discussed in more detail.\\n3. The paper does not provide a clear comparison with state-of-the-art methods in terms of computational complexity and efficiency.\",\n  \"Questions\": \"1. How does the Joint Adversarial Domain Adaptation framework handle cases where the marginal and conditional distributions are not aligned?\\"}
{"paper_id": "gLHuAYGs6a", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents a novel approach to multi-view clustering by constructing a heterogeneous graph with sample and view nodes, which effectively captures high-order sample structures across views.\\n2. The multi-step random walk strategy enables the discovery of these high-order structures, and the lightweight network learns from both within-view and cross-view structures.\\n3. The experiments demonstrate the model's effectiveness across five datasets with various metrics.\",\n  \"Weaknesses\": \"1. The method relies heavily on the quality of the graph construction, and the paper does not provide a clear explanation of how to select the optimal number of sample and view nodes.\\n2. The experiments only evaluate the model on five datasets, and it is unclear whether the results would generalize to other datasets with different characteristics.\",\n  \"Questions\": \"1. How does the model handle cases where the view-specific structures are highly heterogeneous or noisy?\\n2. Can the method be extended to incorporate other types of structural information, such as temporal or spatial information?\"\n}"}
{"paper_id": "x5l5PRtvul", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant issue in SVGD (variance collapse) and proposes a novel solution (h-SVGD) that does not incur additional computational cost.\\n2. The theoretical study is thorough, providing a solid foundation for the proposed method.\\n3. The experiments demonstrate the effectiveness of h-SVGD in high-dimensional inference tasks.\",\n  \"Weaknesses\": \"1. The paper could benefit from a clearer discussion of the limitations of h-SVGD, particularly in comparison to other variants of SVGD.\\n2. The conclusion mentions the need for further refinement of kernel scaling techniques, but it is unclear how this relates to the specific contributions of the paper.\",\n  \"Questions\": \"1. How does the proposed h-SVGD method perform in scenarios where the target density has multiple modes?\\n2. Can the hybrid kernel approach be generalized to other inference algorithms beyond SVGD?\"\n}"}
{"paper_id": "pOUAVXnOQP", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed STAF activation function is an innovative solution to the spectral bias issue in INRs, providing a more expressive and trainable activation function. The use of a Fourier series with trainable amplitude, frequency, and phase is a clever approach.\\n2. The experimental results demonstrate the efficacy of STAF in improving reconstruction quality and convergence speed compared to state-of-the-art methods.\\n3. The paper is well-organized and clearly presents the problem, method, and results.\",\n  \"Weaknesses\": \"1. The paper assumes that spectral bias is the primary limitation of INRs, but it does not thoroughly discuss other potential issues that may affect INR performance, such as overfitting or mode collapse.\\n2. The use of a specific initialization scheme for the STAF parameters may limit the generality of the proposed approach.\",\n  \"Questions\": \"1. How does the STAF activation function compare to other trainable activation functions in terms of expressiveness and computational cost?\\n2. Can the STAF initialization scheme be adapted to other"}
{"paper_id": "iN64nSYt0z", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a systematic and efficient method for improving LLMs to follow user instructions without additional training or resources. \\n2. The GUIDE method and Influence metric are well-motivated and provide a clear direction for future research in this area. \\n3. The paper is well-organized and clearly presented, with a good balance of theory and experimental results.\",\n  \"Weaknesses\": \"1. The novelty of the GUIDE method is somewhat limited, as the concept of using tags to highlight critical instructions in text is not entirely new. However, the systematic approach and the introduction of the Influence metric are valuable contributions. \\n2. The evaluation of GUIDE is mostly based on a single set of tasks and metrics, which may not fully capture its generalizability and limitations.\",\n  \"Questions\": \"1. How does GUIDE perform on tasks that require more complex or nuanced understanding of user instructions, such as those involving multiple steps or conditional logic?\\n2. Can the Influence metric be adapted for use with other types of models,"}
{"paper_id": "gRuZkEy49k", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper introduces a novel approach to improving the training efficiency of GFlowNets by leveraging the connection with maximum-entropy RL through MCDS.\\n2. The empirical evaluations demonstrate the effectiveness of MCDS in various discrete environments.\\n3. The use of MCTS-like operations tailored to DAG environments is a unique contribution to the field.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed explanation of the re-definition of reward functions and the adjustments made to the Backup step in MCDS.\\n2. The exploration-exploitation trade-off is a common challenge in RL and GFlowNets, but the paper could delve deeper into how MCDS specifically addresses this issue.\\n3. The paper assumes a certain level of familiarity with GFlowNets and RL, which might make it challenging for readers without a strong background in these areas.\",\n  \"Questions\": \"1. Can MCDS be adapted to handle continuous environments, or is it specifically designed for discrete settings?\\n2. How does MCDS"}
{"paper_id": "d23EVDRJ6g", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to motion synthesis using localized masked transformers with sliding window local attention and quantization techniques, addressing the limitations of existing methods.\\n2. The evaluation framework and metrics used are well-suited for the task, and the results demonstrate state-of-the-art performance.\\n3. The potential applications of MotionDreamer in temporal editing, crowd animation, and beat-aligned dance synthesis are significant and timely.\",\n  \"Weaknesses\": \"1. The dependence on a single reference motion might limit the generality of the approach, especially when dealing with complex or highly variable motion patterns.\\n2. The quantization technique used might not be universally applicable and could be sensitive to the choice of hyperparameters.\\n3. The lack of comparison with other state-of-the-art methods in more challenging scenarios, such as long-range motion sequences or multiple reference motions.\",\n  \"Questions\": \"1. How does the localized masked transformer approach handle long-range dependencies in motion sequences?\\n2. Can the quantization technique be adapted for other types"}
{"paper_id": "kQ5s9Yh0WI", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors propose a novel agent-based pipeline, AgentWrite, that enables LLMs to generate ultra-long texts, showcasing its effectiveness in producing outputs exceeding 20,000 words. \\n2. The introduction of LongWriter-6k and LongBench-Write is a significant contribution to the field, providing a much-needed dataset and benchmark for evaluating ultra-long generation capabilities. \\n3. The work demonstrates that LLMs have untapped potential for larger output windows when provided with sufficient training data.\",\n  \"Weaknesses\": \"1. The paper's focus on generating ultra-long texts may not be as impactful as addressing other pressing issues in the field, such as improving the coherence and diversity of generated texts. \\n2. The evaluation of the proposed method is primarily based on a single benchmark, LongBench-Write, which might not be representative of all possible applications and use cases.\",\n  \"Questions\": \"1. How would the proposed AgentWrite pipeline perform on other tasks that require ultra-long generation, such as writing"}
{"paper_id": "9CqkpQExe2", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Ada-K routing strategy addresses the limitation of traditional Top-K routing by dynamically adjusting the number of active experts for each token based on its contextual importance. This approach improves computational efficiency and model performance.\\n2. The method is efficiently trainable and requires minimal additional parameters.\\n3. The paper provides comprehensive evaluations across four MoE-based LLMs, varying from 14.3B to 140B parameters, and six benchmarks, demonstrating the effectiveness of Ada-K routing.\",\n  \"Weaknesses\": \"1. The paper assumes that the allocator modules are trained using the Proximal Policy Optimization (PPO) algorithm, which may not be widely used or well-understood by the MoE community.\\n2. The evaluation is focused on accuracy, FLOPs, and inference speed, but does not consider other potential metrics, such as memory usage or energy efficiency.\",\n  \"Questions\": \"1. How does the dynamic routing strategy of Ada-K routing impact the interpretability of the MoE model? Do the allocator modules provide"}
{"paper_id": "PpYy0dR3Qw", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel approach to combining Local Training and Communication Compression in Federated Learning, which is a significant contribution to the field.\\n2. The mathematical framework and theoretical guarantees provided are rigorous and comprehensive.\\n3. The algorithm's ability to adapt to diverse data distributions and achieve doubly-accelerated communication complexity is impressive.\\n4. The paper sets new standards for communication-efficient distributed learning.\",\n  \"Weaknesses\": \"1. The assumption that the compressors are unbiased might be restrictive, as real-world compressors may have biases.\\n2. The paper assumes that the model and data distribution characteristics are known, which might not always be the case in practice.\\n3. The algorithm's performance might degrade if the model is not well-suited for the data distribution.\",\n  \"Questions\": \"1. How does the algorithm handle non-uniform data distributions, where some clients have significantly more data than others?\\n2. Can the algorithm be extended to handle non-linear compressors or other types of compressors?\\n"}
{"paper_id": "UatDdAlr2x", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper provides a novel and well-motivated approach to understanding the role of transformer components in counting tasks.\\n2. The study uses a clear and controlled experiment to demonstrate the effect of architectural changes on model performance.\\n3. The theoretical constructions and experimental results provide a comprehensive understanding of how different counting strategies can be implemented in transformers.\",\n  \"Weaknesses\": \"1. The paper is somewhat narrow in scope, focusing only on the counting task and a specific set of transformer architectures.\\n2. The evaluation is limited to a generated dataset, which may not generalize to more complex or real-world scenarios.\\n3. The discussion on the role of the softmax function is not fully explored, and its impact on performance is not consistently demonstrated.\",\n  \"Questions\": \"1. How does the proposed approach generalize to more complex counting tasks or tasks that involve multiple counting strategies?\\n2. Can the authors provide more insights on the relationship between the transformer's ability to implement counting strategies and its performance on other tasks?\\n3. What are"}
{"paper_id": "IwgmgidYPS", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors propose a novel and highly impactful dataset that can advance multimodal tasks and pretraining for medical AI models. This is a significant contribution to the field, especially given the scalability and efficiency of the automated pipeline used to generate the dataset.\\n2. The paper demonstrates the value of MedTrinity-25M through the pretraining of LLaVA-Tri on it, achieving top performance on various medical visual QA benchmarks.\\n3. The dataset's multigranular annotations offer a rich resource for future research.\",\n  \"Weaknesses\": \"1. The paper does not provide a thorough comparison with other large-scale multimodal medical datasets, such as MIMIC-III or the dataset used in the work on 'Multimodal Pre-training for Medical Image Analysis'.\\n2. The impact of the automated pipeline on the quality of annotations is not thoroughly evaluated, and it is unclear whether the generated annotations are accurate and reliable.\\n3. The authors do not discuss the potential risks and limitations of relying on large multimodal"}
{"paper_id": "WG7GzGx3G9", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors propose a novel method for efficiently managing activation outliers in low-bit quantization, addressing a critical challenge in large language models. This work provides a clear solution to a significant problem.\\n2. The proposed Rotated Runtime Smooth (RRS) method demonstrates substantial improvement over state-of-the-art approaches, achieving better perplexity scores on LLaMA and Qwen models.\\n3. The paper is well-organized, clearly presented, and provides a detailed explanation of the proposed method and its benefits.\",\n  \"Weaknesses\": \"1. While RRS achieves improved perplexity scores, it is unclear whether this translates to tangible improvements in downstream tasks such as language translation or text summarization.\\n2. The paper primarily focuses on INT4 quantization; it is unclear whether RRS can be applied to other quantization methods or bit-widths.\\n3. More discussion on the potential limitations of RRS, such as its compatibility with different hardware setups or potential trade-offs between accuracy and computational overhead, would strengthen the paper.\","}
{"paper_id": "BhECSDSkAE", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses an important problem in medical imaging by proposing an efficient method for one-shot segmentation of medical videos using minimal annotations.\\n2. The proposed framework, which utilizes a memory mechanism and self-distillation, is innovative and well-structured.\\n3. The authors provide a comprehensive evaluation on the OS-I2V-Seg dataset, demonstrating the effectiveness of their approach in low-data settings.\",\n  \"Weaknesses\": \"1. The reliance on pre-trained models from static image datasets might limit the generalizability of the proposed method to other medical imaging tasks or datasets.\\n2. The authors could provide more insights into the memory bank's role in the proposed framework, as it seems to be a crucial component for adaptation to video data.\\n3. The paper does not explore the potential limitations or challenges of using self-distillation for adaptation to temporal characteristics of video data.\",\n  \"Questions\": \"1. How does the proposed framework handle cases where the initial frame or uniformly selected frames do not provide sufficient information for segmentation?\\n2"}
{"paper_id": "mnB4hDTIDr", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The method, DCScore, is effective in evaluating the diversity of LLM-generated datasets from a classification perspective.\\n2. The approach satisfies several diversity-related axioms and displays strong correlations with diversity indicators like human judgment and generation temperature.\\n3. The method offers computational efficiency without sacrificing accuracy.\",\n  \"Weaknesses\": \"1. The paper does not explore the limitations of DCScore when dealing with extremely large datasets.\\n2. The reliance on classification might not capture all aspects of diversity, such as novelty.\\n3. The evaluation of DCScore against existing methods is primarily based on correlation with diversity pseudo-truths, which may not be a comprehensive assessment of its effectiveness.\",\n  \"Questions\": \"1. How would DCScore perform on datasets with significantly different characteristics, such as those with varying levels of structure or noise?\\n2. Are there potential applications of DCScore in other areas of NLP, such as text summarization or machine translation?\\n3. Can DCScore be integrated with"}
{"paper_id": "Y0qmwm6tgy", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel method, MoreauPruner, that uses the Moreau envelope to estimate weight importance robustly, providing robustness against weight perturbations and leading to more stable and effective pruning outcomes in LLMs.\\n2. The approach incorporates \u21131-group-norm-based regularization to induce sparsity and is evaluated on various large language models, demonstrating its effectiveness in maintaining accuracy post-pruning.\\n3. The use of proximal gradient descent algorithm and post-pruning fine-tuning with LoRA to recover model performance is an interesting aspect of the method.\",\n  \"Weaknesses\": \"1. While the paper presents a robust pruning method, its generalizability to other types of neural networks beyond LLMs is not explored.\\n2. The evaluation of the method's performance is mainly focused on accuracy and does not consider other important metrics such as computational efficiency or energy consumption.\\n3. The comparison with other pruning methods could be more comprehensive, including more state-of-the-art approaches.\",\n  \"Questions\":"}
{"paper_id": "aAcOaJYbUg", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel benchmark, LAION-C, which is more challenging and relevant for evaluating the robustness of modern vision models trained on large web-scale datasets.\\n2. The creation of LAION-C and the experimental design are well-motivated and well-executed.\\n3. The psychophysical experiments with human participants provide interesting insights into the differences between model and human performance.\",\n  \"Weaknesses\": \"1. The paper assumes that the LAION dataset inherently contains many corruptions, which might not be the case for all web-scale datasets.\\n2. The psychophysical experiments are limited to 20 participants, which might not be a representative sample of human performance.\\n3. The paper does not provide a detailed analysis of the distribution of the distortions in LAION-C, which might affect the generalizability of the results.\",\n  \"Questions\": \"1. How does the performance of the models on LAION-C relate to their performance on real-world corruptions?\\n2. Can the LAION-C benchmark"}
{"paper_id": "duGygkA3QR", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The work proposes an innovative integration of DMD with GNNs, offering a novel perspective on understanding graph dynamics and improving GNN performance.\\n2. The framework is rigorously grounded in dynamical systems theory and provides a sound theoretical basis for GNNs.\\n3. The experiments demonstrate state-of-the-art performance across various graph-based learning tasks.\\n4. The approach is highly applicable to real-world scenarios where graph-structured data is prevalent.\\n5. The method provides a practical means to estimate low-rank linear operators, offering insights into complex graph dynamics.\",\n  \"Weaknesses\": \"1. The novelty of the proposed framework is somewhat limited, as the concept of applying dynamical systems theory to GNNs is not entirely new.\\n2. The generalizability of the approach to other types of graph structures or tasks is not thoroughly explored.\\n3. The method's performance may be sensitive to the choice of DMD parameters and the quality of initial state observations.\",\n  \"Questions\": \"1. How does"}
{"paper_id": "s6nYndMwG7", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an effective way to set hyperparameters for LiSSA using spectral properties of the Hessian, making influence function calculations more feasible and reliable.\\n2. The authors provide a clear and well-organized presentation of their method and results.\\n3. The empirical validation across different models is comprehensive and convincing.\",\n  \"Weaknesses\": \"1. The paper's contribution is more incremental than groundbreaking, as it builds upon existing work on LiSSA and influence functions.\\n2. The reliance on random sketching techniques for evaluating the Hessian's trace and largest eigenvalue may introduce additional variability in the results.\\n3. The paper does not provide a detailed analysis of the computational costs and trade-offs of their proposed method compared to other influence function estimation methods.\",\n  \"Questions\": \"1. How does the proposed method perform on models with non-Gaussian distributions or non-standard loss functions?\\n2. Can the authors provide more insights into the relationship between the scaling factor, batch size, and number of steps, and how"}
{"paper_id": "9BVMD3keG8", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper fills a gap in the literature by exploring the role of contextual information in the online learning problem of brokerage between traders.\\n2. The proposed algorithms for full and two-bit feedback settings achieve optimal regret bounds under the assumption of zero-mean noise with bounded density.\\n3. The paper clearly explains the problem and its significance in the context of OTC markets.\",\n  \"Weaknesses\": \"1. The paper relies on a simplifying assumption of zero-mean noise with bounded density, which might not be realistic in all scenarios.\\n2. The extension to more complex feedback mechanisms or noise distributions is not explored.\\n3. The paper could benefit from more detailed experimental results and comparisons with other algorithms.\",\n  \"Questions\": \"1. How realistic is the assumption of zero-mean noise with bounded density in real-world OTC markets?\\n2. Can the proposed algorithms be adapted to handle more complex feedback mechanisms or noise distributions?\\n3. How do the proposed algorithms perform in scenarios where the traders' valuations are not independent and ident"}
{"paper_id": "mnna9LUg7P", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a tailored quantization method, Quamba, that effectively reduces SSM model size and improves deployment efficiency.\\n2. The evaluation is thorough, comparing Quamba with baseline methods on zero-shot tasks and showing reduced model latency and slightly lower accuracy.\\n3. The paper addresses a significant challenge in deploying SSMs on cloud and edge hardware.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed comparison with other quantization methods for SSMs.\\n2. The impact of Quamba on more complex tasks, such as few-shot learning or fine-tuning, is unclear.\\n3. The paper assumes a specific SSM architecture (Mamba 2.8B) and it is unclear how well Quamba generalizes to other architectures.\",\n  \"Questions\": \"1. How does Quamba perform on more complex tasks, such as few-shot learning or fine-tuning?\\n2. Can Quamba be applied to other SSM architectures, and if so, what are the implications"}
{"paper_id": "3X3LuwzZrl", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed method, Label Influence Propagation (LIP), effectively captures high-order label influence correlations in graph data, leading to improved classification accuracy.\\n2. The method's ability to quantify and utilize label influences dynamically enhances learning, making it suitable for complex graph-based applications.\\n3. The paper provides a clear and well-structured presentation of the approach and its advantages.\",\n  \"Weaknesses\": \"1. The paper assumes the existence of a label influence graph, which may not be readily available in all scenarios.\\n2. The method's performance relies heavily on the quality of the graph and the label information, which can be challenging to obtain in real-world settings.\\n3. The proposed approach may not generalize well to graphs with highly dynamic or rapidly changing structures.\",\n  \"Questions\": \"1. How does the LIP framework handle cases where the label influence graph is incomplete or contains errors?\\n2. Can the method be extended to incorporate other types of graph data, such as temporal or spatial graphs?\\n3. Are"}
{"paper_id": "IqaQZ1Jdky", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents an innovative approach to improving neural networks by incorporating variable activation functions on edges, leading to improved accuracy and interpretability.\\n2. The use of Bernstein polynomials in the KAN framework is well-motivated and allows for robustness and flexibility in adapting to data variability.\\n3. The Bayesian optimization method used to adapt the polynomial degree is a nice touch, allowing for a balance between approximation accuracy and resource constraints.\\n4. The experimental results across multiple fields demonstrate the superiority of the proposed VBn-KAN framework.\\n5. The paper is well-organized and clearly presented, with a logical flow of ideas.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed explanation of the Weierstrass approximation theorem and its relevance to the problem at hand.\\n2. While the experimental results are promising, it would be interesting to see more thorough analysis of the robustness and flexibility of the VBn-KAN framework in the presence of noise and irregular data distributions.\\n3. Some"}
{"paper_id": "OdMqKszKSd", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed method demonstrates a scalable and practical solution for generating articulated 3D objects from a single image, which is a significant improvement over existing methods that require multi-view, multi-state images or provide limited control.\\n2. The use of a diffusion-based generative model and a coarse-to-fine generation pipeline is innovative and effective in capturing the ambiguity of part shapes and motions from a single view.\\n3. The incorporation of large pre-trained models like DINOv2 and GPT-4o enhances the generation's plausibility and detail accuracy.\\n4. The systematic evaluations on multiple datasets and user studies demonstrate the approach's effectiveness and generalization capabilities.\",\n  \"Weaknesses\": \"1. The paper does not provide a clear comparison with the current state-of-the-art methods in terms of efficiency and computational cost.\\n2. The method requires large pre-trained models like DINOv2 and GPT-4o, which may not be readily available to all researchers.\\n3. The scalability and applicability of the"}
{"paper_id": "LOBhVTtVnc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed GSTs architecture effectively addresses the limitations of traditional GNNs by incorporating equivariant spatiotemporal blocks and a Temporal Difference Graph (TDG) to capture dynamic patterns.\\n2. The model's ability to simulate long-term physical dynamics across multiple scales, including molecular, protein, and macroscopic levels, is impressive and showcases its potential applications in fields like drug discovery.\\n3. The introduction of TDG is a crucial innovation that enhances the model's ability to predict long-term trajectories accurately and efficiently.\",\n  \"Weaknesses\": \"1. The paper assumes that the input graph is a spatiotemporal graph, which may not be the case in all physical systems, and it's unclear how GSTs would perform on graphs with different structures.\\n2. The evaluation of GSTs is limited to a few datasets, and it's unclear how well the model would generalize to other domains or tasks.\",\n  \"Questions\": \"1. Can GSTs be adapted to handle graphs with different structures or domains,"}
{"paper_id": "oa5UeyUVMm", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant gap in the field of graph representation learning by adapting diffusion probabilistic models to this area.\\n2. The proposed Graffe model is well-structured and theoretically sound, with a clear and concise presentation.\\n3. The experimental setup is comprehensive, with multiple real-world datasets and a variety of GNNs used for encoding.\\n4. The authors provide a solid foundation for future exploration of diffusion models in graph contexts.\",\n  \"Weaknesses\": \"1. The paper relies heavily on existing diffusion models and GNNs, and the adaptation to graph representation learning might not be entirely novel.\\n2. The authors do not provide a detailed analysis of the computational complexity of the proposed method.\\n3. The evaluation focuses primarily on node and graph classification tasks, and it would be beneficial to explore other downstream tasks.\",\n  \"Questions\": \"1. How does the Graffe model handle large-scale graph datasets, and what are the implications for computational complexity?\\n2. Can the authors extend the proposed method to"}
{"paper_id": "5swfKRkCx7", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant gap in the current RAG methodologies by introducing a novel external knowledge attention mechanism, which dynamically integrates retrieved knowledge in a more effective manner.\\n2. The memory-based layer-wise integration strategy is a good idea and could potentially be beneficial in various scenarios.\\n3. The experimental evaluation is comprehensive, and the comparison with traditional RAG approaches and baseline LLM models is well-done.\",\n  \"Weaknesses\": \"1. The novelty of the proposed method is somewhat limited, as the concept of external knowledge attention mechanisms is not entirely new.\\n2. The authors could have more thoroughly discussed the limitations and challenges of the proposed memory-based approach, particularly in terms of computational complexity and scalability.\\n3. Some more detailed analysis of the impact of the external knowledge attention mechanism on the LLM's performance would be beneficial.\",\n  \"Questions\": \"1. How does the proposed external knowledge attention mechanism compare to other existing methods for integrating external knowledge in LLMs?\\n2. Are there any plans to extend the memory"}
{"paper_id": "5s1qpjrNvZ", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors provide a clear and well-structured paper that tackles a significant issue in RL by introducing a performance guarantee for guided learning methods.\\n2. The proposed GRL and GRL-RB algorithms demonstrate robustness across various tasks and environments, including challenging ones like AntMaze.\\n3. The paper includes a comprehensive experimental validation and comparisons with other methods to demonstrate its efficacy.\\n4. The authors provide a clear and concise explanation of the proposed method and its advantages.\",\n  \"Weaknesses\": \"1. The paper assumes that the guide policy is known or can be learned beforehand, which might not be the case in many real-world scenarios.\\n2. The authors do not provide a clear explanation of how the roll-back feature (GRL-RB) adapts to changing environments or tasks.\\n3. The experimental results are mostly based on structured environments, and it would be interesting to see the performance of GRL and GRL-RB on more complex or unstructured environments.\",\n  \"Questions\": \"1. How"}
{"paper_id": "WNb4P8aG66", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed framework, DoD, effectively integrates visual priors into the diffusion process, enhancing image generation and reducing computational costs.\\n2. The Latent Embedding Module (LEM) is an innovative approach to compress and reconstruct visual priors, allowing the diffusion model to leverage them effectively.\\n3. The experiments conducted on the ImageNet-256x256 dataset demonstrate state-of-the-art results with reduced training costs.\",\n  \"Weaknesses\": \"1. The paper lacks a thorough discussion on the potential limitations of using visual priors, particularly in scenarios where the priors may not align with the target distribution.\\n2. The evaluation of DoD's performance is limited to a single dataset, ImageNet-256x256, which may not be representative of all possible scenarios.\\n3. The impact of the LEM on the overall performance of DoD is not thoroughly analyzed.\",\n  \"Questions\": \"1. How does the LEM handle cases where the visual priors are not aligned with the target distribution?\\n2."}
{"paper_id": "UfczlMudN6", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The authors propose a unified framework that achieves strong generalization performance for both ID and OOD environment dynamics.\\n2. The method is well-motivated and the integration of a robust adaptation module within a single architecture is a significant contribution to the field of deep RL.\\n3. The evaluation is thorough, with experiments conducted on realistic simulated locomotion tasks using the Unitree Go2 quadruped robot.\",\n  \"Weaknesses\": \"1. The novelty of the GRAM algorithm is somewhat limited, as it builds upon existing ideas of contextual adaptation and adversarial RL.\\n2. The paper assumes that the robust adaptation module is the key to achieving both ID and OOD generalization, but it is unclear if other factors, such as the choice of architecture or hyperparameters, play a more significant role.\\n3. The paper does not provide a clear comparison with state-of-the-art methods that achieve both ID and OOD generalization.\",\n  \"Questions\": \"1. How does the robust adaptation module in GRAM adapt to"}
{"paper_id": "60Vd7QOXlM", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in privacy auditing of Large Language Models (LLMs) by proposing a novel approach to creating effective canaries that can detect privacy leakage.\\n2. The new token canary, in particular, demonstrates superior performance in membership inference attacks, making it a significant contribution to the field.\\n3. The paper is well-organized, clearly presented, and demonstrates a thorough understanding of the problem and proposed solution.\",\n  \"Weaknesses\": \"1. The paper primarily focuses on the theoretical aspects of creating more effective canaries, with limited empirical evaluation of its proposed methods.\\n2. While the new token canary is shown to be effective, it is unclear how it compares to other existing methods in terms of practicality and scalability.\\n3. The paper assumes that the threat model is known, which might not be the case in real-world scenarios.\",\n  \"Questions\": \"1. How can the proposed canaries be adapted to work with different threat models or unknown threat models?\\n2. Are there any"}
{"paper_id": "GqhvJ1o8m5", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 3,\n  \"Strengths\": \"1. The paper proposes a novel framework for stereo video conversion using implicit disparity guidance and a dual-branch architecture, which improves the quality of generated stereo pairs.\\n2. The introduction of the YouTube-SBS dataset fills a gap in resources for developing and evaluating stereo video generation models.\\n3. The paper demonstrates significant improvements in producing high-quality stereo videos compared to existing methods.\",\n  \"Weaknesses\": \"1. The paper's focus on implicit disparity guidance and spatial-temporal attention may not fully address the challenges of texture misalignment and object deformation in existing methods.\\n2. The evaluation metrics, such as L1, SSIM, and PSNR, may not fully capture the nuances of human perception of stereo video quality.\",\n  \"Questions\": \"1. How does the implicit disparity guidance mechanism handle occluded areas or areas with complex geometry?\\n2. Can the dual-branch architecture be adapted for other vision tasks that require spatial-temporal attention, such as video object detection or segmentation?\"\n}"}
{"paper_id": "ua5MHdsbck", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to incorporating triplet relations into preference learning models for extrapolative protein design, which significantly improves its effectiveness.\\n2. The method is well-justified and the results demonstrate its superiority over several baseline and state-of-the-art methods across different datasets and difficulty levels.\\n3. The research suggests that incorporating triplet relations into preference learning can enhance the extrapolative capabilities of generative models.\",\n  \"Weaknesses\": \"1. The paper relies heavily on the AAV and GFP datasets for evaluation, and it is unclear whether the approach would generalize to other protein design tasks.\\n2. The method assumes that the triplet relations can be effectively captured by the generative model, but it is not clear how the model handles cases where the triplet relations are complex or ambiguous.\\n3. The paper could benefit from more detailed analysis of the triplet relations and their impact on the generative model's performance.\",\n  \"Questions\": \"1. How does the proposed approach handle cases where the triplet relations are complex or ambiguous, and"}
{"paper_id": "56Zn3halhq", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel and effective method for adaptive data augmentation in time series forecasting, leveraging a model zoo to identify marginal samples and a variational masked autoencoder for augmentation.\\n2. The use of reinforcement learning to optimize the augmentation process is innovative and could be applied to other domains.\\n3. The paper demonstrates significant performance gains with minimal additional computational overhead.\\n4. The method's ability to adapt to imperfect model zoos is a notable contribution.\",\n  \"Weaknesses\": \"1. The reliance on a robust model zoo for optimal results may be a limitation, especially in scenarios where such a zoo is not readily available.\\n2. The method may not be directly applicable to other domains beyond time series forecasting.\\n3. The use of REINFORCE algorithm might be computationally expensive and time-consuming.\\n4. The paper could have benefited from a more thorough analysis of the robustness of the method to variations in the model zoo.\",\n  \"Questions\": \"1. How does the method perform when the model zoo is"}
{"paper_id": "aPTGvFqile", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper tackles the modality gap issue in CLIP and presents a clear solution through parameter-sharing and semantic regularization. This is a timely and relevant problem in the field of vision-language research. \\n2. The proposed AlignCLIP method is well-structured and the experiments demonstrate its effectiveness in improving cross-modal alignment and downstream tasks. The use of a transformer-based encoder shared between modalities and SBERT for semantic regularization is innovative and well-executed. \\n3. The paper has a clear and concise writing style.\",\n  \"Weaknesses\": \"1. The contribution of the paper may not be entirely novel, as other methods have also explored parameter-sharing and semantic regularization to address modality gaps.\\n2. The evaluation metrics used in the experiments seem to focus primarily on zero-shot classification and multi-modal retrieval, but it would be beneficial to see more comprehensive evaluation on other tasks and datasets.\\n3. The paper assumes the pre-training of the CLIP model on the CC12M dataset, but it's unclear whether the results"}
{"paper_id": "GOwNImvCWf", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The incorporation of a behavioral loss in autoencoder training improves the performance of reconstructed models by capturing features critical for high performance.\\n2. The proposed approach demonstrates the importance of both structure and behavior in learning weight space representations.\\n3. The evaluation of the approach across three model zoos and different datasets showcases its effectiveness.\",\n  \"Weaknesses\": \"1. The paper does not discuss the limitations of using a composite loss function, such as potential overfitting or computational complexity.\\n2. The selection of the input queries for the behavioral loss is not fully explained, which may affect the generalizability of the approach.\\n3. The paper assumes that the original models are available for comparison, which may not be the case in all scenarios.\",\n  \"Questions\": \"1. How does the choice of input queries for the behavioral loss impact the performance of the approach?\\n2. Can the composite loss function be adapted for other types of neural networks or tasks?\\n3. Are there any potential drawbacks to using a composite loss function"}
{"paper_id": "C9BA0T3xhq", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant challenge in offline reinforcement learning, providing a novel algorithm that extends the utility of the Bellman update to actions not explicitly in the dataset. This is a clear advancement in the field.\\n2. The approach combines expectile regression with Implicit Q-Learning, demonstrating a good understanding of the problem and a solid methodological contribution.\\n3. The experimental evaluation is thorough and demonstrates the effectiveness of EIQL on various domains and tasks.\\n4. The paper is well-organized and clearly presented, making it easy to follow and understand.\",\n  \"Weaknesses\": \"1. While EIQL is a significant advancement, its application is still limited to specific environments with sparse rewards or suboptimal and incomplete trajectories. It is unclear whether EIQL can generalize to more complex tasks or domains.\\n2. The use of a Bernoulli random variable to balance between observed in-sample actions and out-of-sample estimations may be restrictive and not applicable to all environments.\\n3. The paper does not provide a clear comparison"}
{"paper_id": "EeqlkPpaV8", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a significant contribution to the field of sampling from a target distribution, establishing lower bounds for the adaptive complexity of sampling algorithms. The use of novel constructions of hardness potentials and properties of random partitions is a strength of the work.\\n2. The paper's clear and concise writing style makes it easy to follow and understand the technical details.\\n3. The authors' analysis of both unconstrained and box-constrained settings provides a comprehensive understanding of the limitations of current sampling approaches.\",\n  \"Weaknesses\": \"1. The paper assumes a specific distribution (log-concave) and the results may not generalize to other distributions.\\n2. The paper's focus on parallel computation models may limit its applicability to other computational settings.\\n3. The authors could have explored more real-world applications of their findings.\",\n  \"Questions\": \"1. How do the authors plan to extend their work to other distributions beyond log-concave?\\n2. Can the authors provide more insights into the computational complexity of their algorithm?\\n3"}
{"paper_id": "oK1zJCWBqf", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to aligning LLMs with human preferences without a reward model, which is simpler and more flexible than existing methods.\\n2. The experimental results demonstrate the effectiveness of SPO in various alignment scenarios.\\n3. The paper provides a clear and concise explanation of the method and its advantages.\",\n  \"Weaknesses\": \"1. The paper lacks a comprehensive comparison with other methods, especially in terms of computational efficiency and generalizability.\\n2. The use of softmax exponent adjustment in SPO may not be widely applicable due to its sensitivity to the choice of hyperparameters.\\n3. The paper does not provide a clear evaluation of the robustness of SPO to noisy or biased preference data.\",\n  \"Questions\": \"1. How does SPO handle cases where the preference data is noisy or biased?\\n2. Can SPO be extended to other tasks beyond language alignment, such as image or video alignment?\\n3. What is the computational cost of SPO compared to other methods?\"\n}"}
{"paper_id": "Dq9VrVuLzV", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed framework, SyntheOcc, demonstrates a novel and efficient approach to encoding 3D geometric information using 3D semantic multi-plane images (MPIs), enabling the generation of photorealistic and geometrically controlled street view images.\\n2. The paper's use of MPIs addresses the limitations of previous methods and provides precise control over occupancy conditions, making it a valuable tool for data augmentation and scenario testing in autonomous driving.\\n3. The framework's ability to preserve detailed 3D scene information and align spatially with generated images is impressive and well-implemented.\",\n  \"Weaknesses\": \"1. While the paper provides a well-structured and clear explanation of the method and its benefits, it could be improved with more detailed descriptions of the architecture and its components, especially the MPI encoder and reweighing strategies.\\n2. The paper assumes a certain level of familiarity with 3D occupancy prediction and autonomous driving, which might limit its accessibility to a broader audience.\\n3. The evaluation metrics and comparisons to traditional"}
{"paper_id": "73Q9U0vcja", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to improve CT reconstruction efficiency by integrating generative diffusion models with active learning.\\n2. The method demonstrates significant improvements in reconstruction quality and measurement reduction, which is a significant advancement in the field.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper assumes that the generative diffusion model is already pre-trained on domain-specific data, which may not always be the case in real-world scenarios.\\n2. The method may not be applicable to all types of CT imaging, particularly in medical imaging where high-stakes applications require more conservative approaches.\",\n  \"Questions\": \"1. How does the method handle cases where the pre-trained generative diffusion model is not a good fit for the specific CT imaging task?\\n2. Can the method be adapted for other types of imaging modalities, such as MRI or ultrasound?\"\n}"}
{"paper_id": "UiEjzBRYeI", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel approach to enhancing the capabilities of vision foundation models like SAM, addressing a significant gap in semantic-aware segmentation tasks.\\n2. The introduction of composable prompts on top of SAM's capabilities is a clever idea, leveraging the strengths of both models.\\n3. The unified affinity framework effectively addresses the over-segmentation issue, making the method efficient and scalable.\\n4. The experiments on COCO and ADE20K datasets demonstrate the method's performance and robustness.\",\n  \"Weaknesses\": \"1. The paper's contribution, while significant, is not entirely novel as similar approaches have been explored in the past.\\n2. The reliance on text labels for Type-I composable prompts may limit the method's applicability to scenarios where such labels are not readily available.\\n3. The evaluation metrics used are not entirely clear, making it difficult to assess the method's performance comprehensively.\",\n  \"Questions\": \"1. How does the composable prompt framework generalize to other vision foundation models beyond SAM?\\"}
{"paper_id": "lessla98Wp", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents a comprehensive solution to the challenges of video colorization, leveraging language inputs to achieve semantically accurate, creatively flexible, and temporally consistent results.\\n2. The proposed method, L-C4, addresses the limitations of existing methods and outperforms them across several benchmarks.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The novelty of using language inputs for video colorization is not entirely new, as previous work has explored similar ideas. However, the specific approach and implementation presented in this paper are notable.\\n2. The reliance on a large dataset with 100K text-video pairs may limit the generalizability of the method to smaller or more diverse datasets.\\n3. The paper could benefit from a more thorough discussion of the potential applications and limitations of L-C4 in real-world scenarios.\",\n  \"Questions\": \"1. How does L-C4 perform on videos with complex or dynamic scenes, where object positions and deformations are more pronounced?\\n2"}
{"paper_id": "UstOpZCESc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper effectively integrates lifelong learning with privacy-aware unlearning, addressing a crucial challenge in the field. This could lead to more responsible AI applications.\\n2. The proposed method, PALL, demonstrates state-of-the-art performance, preventing catastrophic forgetting and enabling exact task unlearning, which is a significant contribution.\\n3. The paper is well-organized and clearly presents the method and results.\",\n  \"Weaknesses\": \"1. The paper assumes that the data is sequentially observed, which might not be the case in all real-world applications.\\n2. The method relies on a fixed-capacity neural network, which may not be scalable to very large models or datasets.\\n3. The paper does not provide a clear comparison with other lifelong learning methods that do not have unlearning capabilities.\",\n  \"Questions\": \"1. How does the method handle the case where the data is not sequentially observed, and how would this impact the performance of PALL?\\n2. What is the impact of the fixed-capacity neural network on the"}
{"paper_id": "LnRegTxsa4", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed CVCAM and MHSAM components improve feature interaction and representation, leading to better geo-localization accuracy.\\n2. The creation of the G2D dataset addresses the scarcity of comprehensive datasets for the cross-view object geo-localization task.\\n3. The novel dual attention approach outperforms previous state-of-the-art methods across different datasets.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of query and reference images, which might not be the case in all real-world scenarios.\\n2. The evaluation metrics used (accu@0.25 and accu@0.5) might not be comprehensive enough to fully assess the method's performance.\\n3. The paper could benefit from a more in-depth analysis of the limitations and challenges of the proposed method.\",\n  \"Questions\": \"1. How does the CVCAM and MHSAM components handle drastic viewpoint changes and scale variations?\\n2. Can the proposed method be adapted for other types of cross-view object geo-localization tasks,"}
{"paper_id": "2ErS9Bkc3O", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a comprehensive matrix-theoretic analysis that sheds light on the cause of neural network fragility, which is a long-standing open problem in the field.\\n2. The theoretical predictions are supported by numerical experiments with both linear and non-linear networks, making the results convincing.\\n3. The paper has a clear structure and is well-written.\",\n  \"Weaknesses\": \"1. The analysis is limited to random Gaussian matrices and may not generalize to other types of neural networks.\\n2. The relationship between adversarial robustness and network parameters such as depth is not explored in detail.\\n3. The paper assumes that the input dimension grows without bound, which may not be realistic in practice.\",\n  \"Questions\": \"1. Can the authors extend their analysis to more general data distributions and explore the relationship between adversarial robustness and network parameters such as depth?\\n2. How does the matrix-theoretic approach compare to other explanations for neural network fragility, such as linearity and decision boundary closeness?\"\n}"}
{"paper_id": "pK3oe2bubc", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant problem in neural networks, particularly in distributed computing environments.\\n2. The proposed method, LayerShuffle, is innovative and demonstrates the adaptability of vision transformers to arbitrary layer order executions and layer failures.\\n3. The experiments are comprehensive, including comparisons with baseline models and analyses under various conditions.\",\n  \"Weaknesses\": \"1. The impact of LayerShuffle on performance under regular execution orders is slightly reduced compared to sequential models.\\n2. The method's applicability to other types of neural networks beyond vision transformers is not explored.\",\n  \"Questions\": \"1. How does LayerShuffle perform when combined with other techniques for improving robustness in neural networks?\\n2. Can LayerShuffle be extended to handle more complex scenarios, such as node failures in parallel processing architectures?\"\n}"}
{"paper_id": "sec09tLQUl", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel approach to reducing example-level memorization in deep learning models, addressing a significant gap in existing methods.\\n2. The proposed FairDropout technique is well-designed and effective in reducing reliance on spurious correlations without requiring group labels.\\n3. The study demonstrates improvements in worst-group accuracy across multiple datasets, showcasing the method's generalizability.\",\n  \"Weaknesses\": \"1. The potential beneficial aspects of memorization are acknowledged, but the paper does not delve deeper into this topic.\\n2. The assumption on neuron roles requires further investigation, which is a limitation of the proposed method.\\n3. The study is limited to a few datasets and models, and it would be beneficial to scale the approach to larger and more diverse datasets.\",\n  \"Questions\": \"1. How does FairDropout perform on more complex models and datasets where memorization is more prevalent?\\n2. Can the proposed method be adapted for other types of models, such as transformers, or is it limited to traditional neural networks?\\"}
{"paper_id": "96jZFqM5E0", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper provides a well-motivated approach to leveraging diverse hand images from in-the-wild videos for 3D hand pose estimation pre-training.\\n2. The proposed SiMHand framework demonstrates significant improvements over state-of-the-art methods on various benchmarks.\\n3. The adaptive weighting mechanism for contrastive loss is a useful innovation.\",\n  \"Weaknesses\": \"1. The paper relies heavily on the quality of the in-the-wild datasets, such as Ego4D and 100DOH, which may have biases and limitations.\\n2. The PCA-based dimension reduction for identifying similar hand poses might not be robust to varying lighting conditions or occlusions.\\n3. The paper does not provide a thorough comparison with other self-supervised pre-training methods beyond contrastive learning.\",\n  \"Questions\": \"1. How does the paper's approach generalize to other in-the-wild datasets with varying levels of annotation quality and diversity?\\n2. Can the adaptive weighting mechanism be applied to other contrastive learning tasks beyond 3"}
{"paper_id": "uNd289HjLi", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The Corruption2Self (C2S) method achieves state-of-the-art performance among self-supervised denoising methods and performs competitively against supervised approaches.\\n2. The approach effectively reduces noise while preserving important imaging details.\\n3. The study shows C2S's potential to generalize in clinical MRI settings without requiring high-SNR training data.\",\n  \"Weaknesses\": \"1. The paper assumes that MRI data suffers from ambient noise, but it's unclear whether this assumption holds in all real-world scenarios.\\n2. The proposed method relies on a reparameterization of noise levels, which might not be directly applicable to other imaging modalities.\\n3. The impact of the detail refinement extension on the overall performance is not thoroughly discussed.\",\n  \"Questions\": \"1. How does the Corruption2Self method handle cases where the noise levels are not known or are varying across different regions of the image?\\n2. Can the C2S framework be extended to other types of medical imaging modalities, such as CT or"}
{"paper_id": "e2ONKX6qzJ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant issue in diffusion models, improving the quality of image generations while reducing oversaturation.\\n2. The proposed adaptive projected guidance (APG) is a novel and effective approach that can be applied to various diffusion models and samplers.\\n3. The evaluation is comprehensive, using multiple metrics like FID, recall, and saturation scores to demonstrate the superiority of APG over traditional CFG.\",\n  \"Weaknesses\": \"1. The paper assumes a good understanding of diffusion models and their applications, which might limit its accessibility to a broader audience.\\n2. The method relies on orthogonal projection and rescaling, which might be computationally expensive for large-scale models.\\n3. The paper could benefit from more detailed comparisons with other methods and a more thorough discussion of the limitations of the proposed approach.\",\n  \"Questions\": \"1. Can APG be applied to other generative models beyond diffusion models, such as normalizing flows or GANs?\\n2. How does APG handle the trade-off between"}
{"paper_id": "a2eBgp4sjH", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a comprehensive theoretical framework for MultiFilterANN, addressing the need for a general and efficient approach.\\n2. The novel algorithms incorporating ANN and subset query algorithms achieve robust space-time trade-offs and competitive empirical performance.\\n3. The study releases new datasets to support further research, enhancing the field's progress.\\n4. The paper's contributions are well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The paper's innovation may be somewhat limited by its focus on graph-based methods, which might not generalize to all types of filter constraints.\\n2. The empirical evaluation could benefit from a more extensive comparison with a broader range of state-of-the-art solutions.\\n3. The impact of the proposed approach on real-world applications may be underexplored.\",\n  \"Questions\": \"1. How do the proposed algorithms scale to very large datasets or a large number of filters?\\n2. Can the approach be extended to handle more complex filter constraints or types of queries?\\n3. What are the potential limitations"}
{"paper_id": "EIXZXPz7jU", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed flow-matching sampling approach effectively addresses the challenges of singular PDE source functions, improving the accuracy and efficiency of PINN solutions.\\n2. The use of diffusion models and optimal transport coupling flow-matching is innovative and well-motivated.\\n3. The experiments demonstrate the efficacy of the approach on complex PDE examples.\",\n  \"Weaknesses\": \"1. The paper assumes that the diffusion model can accurately capture the distribution of PDE residuals, which may not always be the case.\\n2. The approach may not generalize to other types of singularities or PDEs.\\n3. The experimental evaluation is limited to a few complex PDE examples.\",\n  \"Questions\": \"1. Can the flow-matching sampling approach be extended to other types of PDEs or singularities?\\n2. How does the approach handle cases where the PDE residuals are not well-captured by the diffusion model?\\n3. Are there any potential applications of this approach in other fields beyond PDEs?\"\n}"}
{"paper_id": "QO4bF6MHza", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel benchmark, MathHay, which effectively evaluates long-context mathematical reasoning capabilities of LLMs. This is a significant contribution to the field, as it addresses a critical gap in existing benchmarks.\\n2. The paper provides a clear and well-organized presentation of the problem, method, and results, making it easy to follow and understand.\\n3. The experiments are thorough and well-designed, with a good selection of models and input lengths.\",\n  \"Weaknesses\": \"1. The paper assumes that the lack of long-context mathematical reasoning capabilities in LLMs is due to the absence of a suitable benchmark, which might not be entirely accurate. There could be other factors at play, such as the models themselves or the training data.\\n2. The paper could benefit from more discussion on the limitations of the MathHay benchmark and potential future directions for improvement.\\n3. The paper does not provide a clear explanation of how the 'haystacks' of mixed relevant and irrelevant documents were created.\",\n  \"Questions"}
{"paper_id": "GULx8rzzjC", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 3,\n  \"Strengths\": \"1. The paper proposes an effective method for efficiently selecting and acquiring useful data subsets from external data owners under restricted data-sharing conditions.\\n2. The evaluation is comprehensive and systematic, comparing Mycroft's performance to full-information and random sampling baselines across two domains.\\n3. The paper is well-organized and clearly presented.\",\n  \"Weaknesses\": \"1. The novelty of the approach is somewhat limited, as the concept of using feature space distances and gradient matching is not entirely new.\\n2. The paper assumes that data owners are willing to share data based on the identified subsets, which might not always be the case in real-world scenarios.\\n3. The experiments are limited to two domains and more extensive evaluation on a broader range of tasks would strengthen the results.\",\n  \"Questions\": \"1. How does Mycroft handle scenarios where data owners are unwilling to share data, even after identifying useful subsets?\\n2. Can Mycroft be adapted for more complex tasks, such as regression or clustering, where the concept of a 'use"}
{"paper_id": "PnZ2lbQaao", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The proposed Domain Indexing Collaborative Filtering (DICF) framework effectively improves cross-domain recommendation performance and provides interpretability through domain indices.\\n2. The adversarial Bayesian framework is well-suited for modeling the recommendation problem and inferring domain indices.\\n3. The empirical evaluation on synthetic and real-world datasets showcases generalization and interpretability improvements.\\n4. The framework outperformed state-of-the-art methods in both synthetic and real-world datasets.\",\n  \"Weaknesses\": \"1. The paper does not discuss potential challenges in applying the framework to large-scale datasets or real-world systems.\\n2. The reliance on adversarial learning might lead to overfitting or mode collapse.\\n3. The interpretation of domain indices and their relationship to semantic or geographical proximities is not thoroughly explored.\",\n  \"Questions\": \"1. How does the framework handle the cold-start problem for new items that do not have any user interactions?\\n2. Can the domain indexing approach be extended to other recommendation tasks such as ranking or top-N"}
{"paper_id": "AT64R0ivUO", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents an effective method to enhance LLMs' comprehension of input contexts by steering their attention. This addresses a significant challenge in open-book QA tasks.\\n2. The method is well-explained and easy to understand, with a clear description of the iterative prompting and attention steering process.\\n3. The experimental results demonstrate significant improvements over baseline prompting methods.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed analysis of the attention head selection process, as it is a crucial aspect of the SteerPrompt method.\\n2. While the method shows promise, its applicability to other tasks beyond open-book QA is unclear, and more exploration of its generalizability would strengthen the contribution.\\n3. The evaluation metrics used in the experiments could be more diverse to provide a more comprehensive understanding of the method's effectiveness.\",\n  \"Questions\": \"1. How does SteerPrompt handle situations where the key sentences are not clearly identified by the LLM, potentially leading to a suboptimal selection of"}
{"paper_id": "nGiGXLnKhl", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents a well-motivated approach to reduce the computational complexity of Vision Transformers while maintaining their strengths.\\n2. The proposed modifications to the RWKV architecture, such as Q-Shift and Bi-WKV, are innovative and address a significant challenge in the field.\\n3. The experiments are comprehensive and demonstrate the effectiveness of VRWKV in various vision tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that RWKV is a suitable starting point for vision tasks, which may not be universally true.\\n2. The comparison with ViT models is not entirely fair, as VRWKV is trained on larger datasets.\\n3. The impact of the modifications on the model's interpretability and explainability is not discussed.\",\n  \"Questions\": \"1. How does the Q-Shift and Bi-WKV modifications affect the model's performance on tasks that require more complex reasoning, such as object detection and semantic segmentation?\\n2. What are the potential limitations of VRWKV when applied to very large and complex"}
{"paper_id": "TBJCtWTvXJ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel optimizer, SignSoftSGD (S3), which leverages a generalized sign-like formulation with a flexible p-th order momentum in the denominator. This allows for larger learning rates and faster convergence.\\n2. The theoretical analysis and extensive experiments on vision and language tasks demonstrate the effectiveness and efficiency of S3.\\n3. The paper provides a clear explanation of the sign-like descent property and its relation to Adam's performance.\\n4. The comparison with Adam and AdamW shows that S3 achieves similar or better results in half the training steps.\",\n  \"Weaknesses\": \"1. The paper assumes that the sign-like descent property is the primary reason for Adam's effectiveness, which might not be universally applicable.\\n2. The use of Nesterov's accelerated gradient (NAG) in S3 might not be necessary for all tasks.\\n3. The paper does not discuss the potential trade-offs between the flexibility of the p-th order momentum and the increased risk of loss spikes.\",\n  \"Questions\":"}
{"paper_id": "8gSrJOL2oc", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an innovative framework, TRIDENT, which addresses the limitations of existing compositional zero-shot learning methods.\\n2. The use of Multimodal Large Language Model (MLLM) embeddings and attribute smoothing is a novel approach that shows promise.\\n3. The paper provides a comprehensive evaluation on challenging datasets and achieves state-of-the-art performance.\",\n  \"Weaknesses\": \"1. The paper assumes that MLLM embeddings are superior to existing word embeddings, but it would be beneficial to compare them more rigorously.\\n2. The method relies heavily on the quality of the LLaVA v1.5 embeddings, which may not generalize well to other datasets.\\n3. The paper does not provide a clear explanation of how the attribute smoothing component improves the model's performance.\",\n  \"Questions\": \"1. How does the TRIDENT framework handle cases where the attribute-object interaction is complex or nuanced?\\n2. Can the MLLM embeddings be used in other computer vision tasks beyond compositional zero-shot learning?\\n"}
{"paper_id": "yheQRc5xWB", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed Mamba-CDSP model effectively addresses the limitations of traditional methods in sequence modeling and bias correction, demonstrating significant improvements in prediction accuracy and computational efficiency.\\n2. The approach introduces a novel Covariate-based Decorrelation towards Selective Parameters (CDSP) to de-correlate current treatments from historical information, which is a valuable contribution to the field of time-varying counterfactual prediction.\\n3. The evaluation is comprehensive, comparing with existing baselines on synthetic, semi-synthetic, and real-world datasets, and the results demonstrate the superiority of Mamba-CDSP.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more detailed discussion on the theoretical foundations of the proposed CDSP method, providing a deeper understanding of its properties and limitations.\\n2. While the model shows impressive performance, the evaluation on real-world datasets is limited to a single application, and it would be beneficial to explore its generalizability to other domains.\\n3. The paper assumes that the covariates"}
{"paper_id": "HxKSzulSD1", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper provides a comprehensive analysis of the weak-to-strong deception phenomenon, a critical concern in the development of superintelligent systems. The study is well-designed, and the results are clear and compelling.\\n2. The authors' method for investigating deception in multi-objective alignment scenarios is innovative and insightful, shedding light on the potential risks of superalignment.\\n3. The paper's conclusions are well-supported and underscore the need for reliable superalignment in intelligent systems.\",\n  \"Weaknesses\": \"1. The paper assumes a relatively narrow scope, focusing solely on the weak-to-strong deception phenomenon, without exploring other potential risks associated with superalignment.\\n2. While the study is well-designed, the evaluation metrics and datasets used may not capture the full complexity of real-world superalignment scenarios.\\n3. The paper could benefit from more detailed discussion on potential mitigations or strategies for addressing the weak-to-strong deception issue.\",\n  \"Questions\": \"1. How might the weak-to-strong deception phenomenon be mitigated in practice, and what are"}
{"paper_id": "wH8XXUOUZU", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes an effective method to enhance the reconstruction accuracy of high spatial-compression autoencoders using Residual Autoencoding and Decoupled High-Resolution Adaptation techniques. This work has the potential to improve the efficiency of latent diffusion models.\\n2. The evaluation is comprehensive, comparing DC-AE with state-of-the-art models and demonstrating significant gains in inference and training throughput while maintaining or improving image quality metrics like FID.\\n3. The paper is well-organized and clearly presented, with a logical flow of ideas.\",\n  \"Weaknesses\": \"1. The paper assumes that the optimization difficulty and generalization issues are primarily due to high compression ratios, without considering other factors that may contribute to these problems.\\n2. The DC-AE method may not generalize well to other types of autoencoders or diffusion models beyond latent diffusion models.\",\n  \"Questions\": \"1. How does the DC-AE method handle the trade-off between compression ratio and reconstruction accuracy, and what is the optimal compression ratio for different types of"}
{"paper_id": "QWIg5e6mtT", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in existing research on heterogeneous team games, proposing a novel framework for improving coordination among teammates.\\n2. The introduction of Heterogeneous-PSRO demonstrates a clear and well-structured approach to sequential correlation mechanisms within the PSRO framework.\\n3. The experimental results on matrix heterogeneous games and complex settings like StarCraft and Google Research Football are comprehensive and convincing.\",\n  \"Weaknesses\": \"1. The reliance on sequential optimization could be a limiting factor in extremely large-scale games.\\n2. The adaptation to continuous action spaces needs further exploration.\\n3. The paper could benefit from more detailed explanations of the sequential correlation mechanisms and how they improve the policy search space.\",\n  \"Questions\": \"1. How does the Heterogeneous-PSRO framework handle cases where the number of teammates is large and the role diversity is high?\\n2. Can the sequential optimization mechanism be parallelized to improve scalability?\\n3. Are there any potential applications of H-PSRO in other domains beyond game theory"}
{"paper_id": "kbSU5bwoRv", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel approach to zero-shot singing voice conversion (SVC) with impressive results.\\n2. The authors provide a comprehensive comparison with existing methods and demonstrate significant improvements in SVC quality.\\n3. The model, SaMoye, is well-designed and utilizes a large and diverse dataset for training.\",\n  \"Weaknesses\": \"1. The paper assumes the availability of a sufficiently large and diverse dataset for training, which may not be feasible for all research groups or applications.\\n2. The approach relies heavily on feature disentanglement techniques, which may not generalize well to all types of music or singing styles.\\n3. The evaluation metrics used are primarily focused on objective quality measures, and it would be beneficial to include more subjective evaluations.\",\n  \"Questions\": \"1. How does the model handle cases where the source singer's voice is significantly different from the target singer's voice?\\n2. Can the authors provide more insight into the specific feature disentanglement techniques used in SaMoye and"}
{"paper_id": "KyqtKhv6q1", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel framework, Differentiable Map Priors (DMP), to incorporate historical spatial priors into 3D perception systems, which can improve performance in tasks like 3D object detection and semantic map segmentation.\\n2. The framework is efficient, scalable, and effectively utilizes historical context to improve perception in real-world applications.\\n3. The authors provide extensive experiments using the nuScenes dataset, integrating DMP with various baseline architectures.\",\n  \"Weaknesses\": \"1. The paper lacks a clear explanation of how the historical spatial priors are learned and updated over time.\\n2. The authors do not discuss the potential limitations of relying on historical data, such as data drift or concept drift.\\n3. The paper assumes that the historical data is available and consistent, but does not address the case where the historical data is incomplete or noisy.\",\n  \"Questions\": \"1. How does the framework handle the case where the historical data is incomplete or noisy?\\n2. Can the framework be extended to other"}
{"paper_id": "lTL4t68BNc", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper introduces a novel method, RGA-IB, that leverages the Information Bottleneck principle to improve the robustness of Graph Neural Networks (GNNs) against adversarial attacks.\\n2. The approach provides a theoretical explanation for the effectiveness of attention-based GNNs against attacks.\\n3. The experiments demonstrate significant improvements in node classification accuracy under various adversarial attack scenarios.\\n4. The paper's conclusion is well-supported by the results and the proposed method shows a notable improvement in robustness.\\n5. The use of Information Bottleneck principle is innovative and could have broader implications for GNNs.\\n6. The paper is well-organized and clearly presented, making it easy to follow.\",\n  \"Weaknesses\": \"1. The paper assumes that the Information Bottleneck principle is a suitable measure of robustness, but it would be interesting to explore other metrics for evaluating robustness.\\n2. The method's reliance on a specific graph attention mechanism might limit its applicability to other types of GNN"}
{"paper_id": "hWmwL9gizZ", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The proposed model ProVaccine effectively integrates dual attention mechanisms with pre-trained protein sequence and structure embeddings to improve immunogenicity prediction accuracy and generalizability.\\n2. The study utilizes a comprehensive dataset and benchmark datasets for validation, providing a strong foundation for the model's effectiveness.\\n3. The model's ability to identify potential vaccine candidates and its robust performance across various pathogens are notable strengths.\\n4. The paper sets a new benchmark for future research in the field of reverse vaccinology.\",\n  \"Weaknesses\": \"1. The reliance on pre-trained embeddings and the use of dual attention mechanisms may not be novel or groundbreaking, and the concept of using comprehensive embeddings for immunogenicity prediction has been explored before.\\n2. The study does not provide a clear explanation for why the dual attention mechanism is necessary or how it improves the model's performance.\\n3. The model's performance may be sensitive to the quality and size of the training data, which could impact its generalizability.\",\n  \"Questions\": \"1."}
{"paper_id": "IL85Ebjg9j", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 3,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a real-world problem in multi-view classification, where existing methods assume equal importance and alignment of views. The proposed trust-based discounting method is a novel and effective approach to resolve view-specific conflicts in multi-view data.\\n2. The use of Binomial opinion theory to transform view-specific predictions into a degree of trust is an interesting and useful concept.\\n3. The evaluation metrics used, including AUROC and Multi-View Agreement with Ground Truth, are comprehensive and well-chosen.\",\n  \"Weaknesses\": \"1. The paper assumes that the reliability of view-specific predictions can be captured using Binomial opinion theory, which might not always hold true in real-world scenarios.\\n2. The method's performance is evaluated on a limited number of datasets, and it is unclear how it would generalize to other, more complex scenarios.\\n3. The paper could benefit from a more detailed analysis of the computational complexity and scalability of the proposed method.\",\n  \"Questions\": \"1. How does the trust-based discounting method handle"}
{"paper_id": "cnKhHxN3xj", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel metric to quantify neuronal entanglement, which can be used to improve the effectiveness of sparsification techniques in large language models. This work has the potential to impact the field of neural network interpretability.\\n2. The experimental framework, Sparse Expansion, is well-designed and effectively demonstrates the importance of disentangling neuron outputs under high sparsity.\\n3. The paper provides a clear and concise explanation of the problem and the proposed solution.\",\n  \"Weaknesses\": \"1. The authors' claim that their method can disentangle all neurons is too strong, and it is unclear whether their approach can handle all types of entangled neurons.\\n2. The paper relies heavily on the Wasserstein distance as a metric for entanglement, but it is not clear if this is the best metric to use in all cases.\\n3. The paper does not provide a thorough analysis of the computational complexity of their method, which may be a limitation for large-scale applications.\",\n  \"Questions\": \"1."}
{"paper_id": "dgR6i4TSng", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper presents a novel and promising approach to parameter-efficient fine-tuning of large models by leveraging quantum-inspired parameterizations.\\n2. The authors demonstrate a significant reduction in trainable parameters compared to conventional methods like LoRA, with competitive performance.\\n3. The paper has a clear structure and the writing is clear and concise.\",\n  \"Weaknesses\": \"1. The paper relies on a relatively new area of research (quantum-inspired parameterizations), which might make it challenging for some readers to fully understand the concepts.\\n2. The experimental results are mostly focused on language and vision tasks, and it would be beneficial to see more comprehensive evaluation on other domains.\\n3. The paper assumes that the quantum-inspired parameterization will lead to a logarithmic scaling of parameters with the ambient dimension, which might not be the case in all scenarios.\",\n  \"Questions\": \"1. How does the choice of quantum circuits (specifically, RY and controlled-Z gates) impact the performance of the proposed method?\\n2. Can the authors"}
{"paper_id": "ye1mxb79lw", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The authors propose a novel and effective bilevel Bayesian optimization algorithm, BILBO, that efficiently manages the exploration of the search space through trusted sets and a strategic function query method, providing theoretical guarantees of performance in terms of regret bounds. This work has the potential to significantly impact various fields, including machine learning, economics, and energy management.\\n2. The paper is well-organized and clearly presented, with a logical flow of ideas and a concise writing style.\\n3. The experimental results demonstrate substantial improvements over baseline methods in terms of regret and convergence speed, showcasing the effectiveness of BILBO in both synthetic and real-world scenarios.\",\n  \"Weaknesses\": \"1. The paper assumes that the lower-level problem is Gaussian process-based, which might not be suitable for all bilevel optimization problems.\\n2. The authors should provide more details about the computation complexity and time cost of BILBO, as this is crucial for its practical applicability in real-world scenarios.\",\n  \"Questions\": \"1. Can BILBO be"}
{"paper_id": "1fwZJzGdKj", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel multi-agent collaborative data selection mechanism for LLM pretraining, which effectively resolves inherent conflicts between different data selection methods and enhances data efficiency.\\n2. The experimental results show a significant improvement in data efficiency and convergence acceleration, achieving up to a 10.5% average performance gain across multiple language model benchmarks.\\n3. The framework is well-organized and clearly presented, with a detailed process for agents to sample, score, and update data prioritization through interaction with a model being trained.\",\n  \"Weaknesses\": \"1. The novelty of the approach relies heavily on the integration of multiple data selection methods, which may not be as impactful if individual methods are not well-designed.\\n2. The dynamic adjustment of agent influence using influence functions may require careful tuning and may not generalize well across different LLM pretraining tasks.\\n3. The paper does not provide a detailed analysis of the computational cost of the multi-agent framework and its potential impact on the overall training time.\",\n  \"Questions\": \"1."}
{"paper_id": "pISLZG7ktL", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper establishes a clear gap in the field of robotics and imitation learning, providing a compelling motivation for the proposed work.\\n2. The authors demonstrate a novel and effective approach to data scaling in robotics, showing that increasing diversity of environments and objects leads to better generalization.\\n3. The paper is well-organized, and the experiments are thorough and well-presented, making it easy to follow and understand the results.\\n4. The study's implications for the field of robotics and imitation learning are significant, and the proposed method has the potential to be widely applicable.\",\n  \"Weaknesses\": \"1. The paper could benefit from a more in-depth discussion of the limitations of the proposed method and potential challenges in scaling up to more complex tasks or environments.\\n2. While the results are promising, it is unclear how the proposed method would perform in scenarios with a large number of unseen objects or environments.\\n3. The paper assumes that the diversity of environments and objects is sufficient to achieve generalization, but it is unclear whether"}
{"paper_id": "dML3XGvWmy", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 3,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel self-evolving framework, G\u00f6del Agent, which demonstrates promising results in recursive self-improvement capabilities.\\n2. The G\u00f6del Agent framework leverages large language models to dynamically modify its own logic and behavior, showcasing adaptability and efficiency.\\n3. The paper provides a clear and concise presentation of the method and its results.\",\n  \"Weaknesses\": \"1. The paper lacks a clear explanation of how the G\u00f6del Agent framework overcomes the limitations of traditional agent systems, and the paper could benefit from a more thorough comparison with existing methods.\\n2. The experiments conducted on tasks like coding, science, and math are limited in scope, and the paper could benefit from a more comprehensive evaluation across various domains.\\n3. The paper does not provide a thorough discussion on the potential risks and challenges associated with self-evolving AI systems.\",\n  \"Questions\": \"1. How does the G\u00f6del Agent framework ensure that the self-improvement process does not lead to unintended consequences or biases?\\n2"}
{"paper_id": "xlxGsX1pc7", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 3,\n  \"Rating\": 7,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper addresses a significant gap in the field of evaluating LLMs' mathematical reasoning capabilities, particularly at the university level.\\n2. The introduction of U-MATH and \u00b5-MATH datasets provides a comprehensive framework for assessing LLMs' performance on advanced mathematical problems.\\n3. The study highlights the limitations of current LLMs in processing complex mathematical problems and emphasizes the need for better models and evaluation techniques.\",\n  \"Weaknesses\": \"1. The paper's contribution might be somewhat limited by the fact that the introduced benchmark and evaluation methods are primarily focused on university-level mathematics, which may not generalize to other domains or types of complex problems.\\n2. The evaluation of LLMs' performance on meta-evaluation tasks seems to be somewhat restricted to a specific dataset (\u00b5-MATH) and might not fully capture the breadth of LLMs' capabilities in evaluating mathematical solutions.\",\n  \"Questions\": \"1. How generalizable are the findings of this study to other domains or types of complex problems beyond university-level mathematics?\\"}
{"paper_id": "AjXkRZIvjB", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper addresses a significant gap in the current understanding of Large Language Models (LLMs) by introducing GSM-Symbolic, a new benchmark for evaluating their mathematical reasoning capabilities. This allows for a more comprehensive assessment of their performance across various complexities.\\n2. The study provides a large-scale analysis of 25 state-of-the-art LLMs, offering valuable insights into their fragility in reasoning tasks and their tendency to rely on pattern matching rather than genuine reasoning.\\n3. The introduction of GSM-NoOp reveals a critical flaw in LLMs' reasoning process, indicating the need for further research.\",\n  \"Weaknesses\": \"1. The study's focus on mathematical reasoning might limit its generalizability to other domains.\\n2. The GSM-Symbolic benchmark, while novel, relies heavily on the GSM8K dataset, which may introduce data contamination risks and limited question variability.\\n3. The paper does not provide a clear solution to the identified issues with LLMs' reasoning capabilities.\",\n  \"Questions\": \"1"}
{"paper_id": "IJiTI0fB0e", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 3,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a novel information-theoretic framework for evaluating diversity in prompt-based generative models, addressing a significant gap in existing metrics. This work has the potential to improve the development of AI models with better diversity characteristics.\\n2. The Conditional-Vendi and Information-Vendi scores provide a clear and intuitive understanding of model-induced and prompt-induced diversity, respectively.\\n3. The experimental results demonstrate the effectiveness of the proposed method in capturing diversity across different generative tasks.\",\n  \"Weaknesses\": \"1. The paper assumes that the input prompts are fixed and not learned, which might limit the applicability of the proposed framework to some real-world scenarios where prompts are dynamically generated.\\n2. The proposed metrics might not capture all aspects of diversity, such as novelty or creativity, which are important in certain applications.\\n3. The paper does not provide a clear direction for improving the diversity of AI models using the proposed framework.\",\n  \"Questions\": \"1. How can the proposed framework be extended to handle dynamic or learned prompts?\\"}
{"paper_id": "fs2Z2z3GRx", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel approach to guiding the reverse-time sampling process using measurement interpolants, which significantly improves the efficiency and effectiveness of solving linear inverse problems.\\n2. The theoretical justification for the method is well-motivated and provides a solid foundation for the proposed approach.\\n3. The experiments demonstrate competitive results in various linear image reconstruction tasks, especially in challenging scenarios.\",\n  \"Weaknesses\": \"1. The paper assumes that the pre-trained flow or diffusion model is available and does not discuss how to train such a model from scratch.\\n2. The method may not be generalizable to non-linear inverse problems.\\n3. The evaluation metrics used are limited to memory and runtime consumption, which may not fully capture the complexity of the problem.\",\n  \"Questions\": \"1. How does the choice of pre-trained flow or diffusion model affect the performance of FIG?\\n2. Can FIG be extended to handle non-linear inverse problems?\\n3. Are there any potential issues with the interpolant guidance that could lead to overfit"}
{"paper_id": "H4FSx06FCZ", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 4,\n  \"Strengths\": \"1. The paper proposes a secure steganography framework, SecureGS, that improves security and efficiency for 3D Gaussian splatting.\\n2. The framework leverages a hybrid decoupled Gaussian encryption mechanism and a density region-aware anchor growing and pruning strategy.\\n3. SecureGS outperforms existing methods in terms of rendering fidelity, speed, and security, effectively ensuring both file format and geometric structure security.\\n4. The paper provides extensive experiments demonstrating the effectiveness of SecureGS.\",\n  \"Weaknesses\": \"1. The paper assumes that the anchor points are publicly accessible, which may not be the case in all scenarios.\\n2. The security of the framework relies heavily on the privacy-preserving neural networks, which may have limitations in certain applications.\\n3. The paper does not provide a thorough comparison with other steganography methods that do not use Gaussian splatting.\",\n  \"Questions\": \"1. How does the paper address the potential vulnerability of anchor points being publicly accessible?\\n2. Can the framework"}
{"paper_id": "OGtUfA6Amo", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper proposes a novel hierarchical patch graph network (Hi-Patch) to effectively capture multi-scale dynamics and inter-variable correlations in Irregular Multivariate Time Series (IMTS), outperforming existing models.\\n2. The Hi-Patch architecture leverages intra-patch and inter-patch graph layers to process scales progressively, adapting to both sparse and dense sampling over variables.\\n3. The experimental evaluation on eight datasets demonstrates the robustness and efficacy of Hi-Patch in both forecasting and classification tasks.\",\n  \"Weaknesses\": \"1. The paper does not provide a detailed analysis of the computational complexity and scalability of the proposed Hi-Patch architecture, which may be a concern for large-scale applications.\\n2. The evaluation of Hi-Patch is limited to eight datasets, and it is unclear how well the model generalizes to other IMTS datasets or real-world applications.\\n3. The paper does not discuss the interpretability of the learned hierarchical representations and correlations in the Hi-Patch model.\",\n  \"Questions\": \"1."}
{"paper_id": "ujpAYpFDEA", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper fills a critical gap in the research on watermarking for LLMs by investigating the imperceptibility of watermarks. This is a significant contribution to the field.\\n2. The authors propose two innovative methods, Water-Probe and Water-Bag, to detect and enhance watermark imperceptibility, respectively.\\n3. The experimental results demonstrate the effectiveness of Water-Probe and the trade-off between watermark imperceptibility and detectability.\",\n  \"Weaknesses\": \"1. The authors may have benefited from providing more details about the specific watermarking algorithms used in their experiments.\\n2. It is unclear how the proposed methods would perform in real-world scenarios, where users may not be aware of the watermark presence.\\n3. The paper does not discuss potential countermeasures that adversaries might employ to evade watermark detection.\",\n  \"Questions\": \"1. How do the authors envision the deployment of Water-Probe and Water-Bag in real-world applications, and what are the potential challenges they may face?\\n2. Are"}
{"paper_id": "7UKHNQIErp", "review": "{\n  \"Soundness\": 4,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 9,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a novel and rigorous framework for formalizing DPA loss functions using symbolic logic, which can aid both analysis and development of novel losses.\\n2. The probabilistic logic framework for translating existing DPA losses into symbolic programs is well-defined and systematic.\\n3. The study provides a clear semantic foundation for understanding existing losses and deriving new algorithms, potentially enhancing human-AI alignment.\\n4. The paper showcases the potential for significant improvements in human-AI alignment by exploring the structured landscape of DPA losses.\",\n  \"Weaknesses\": \"1. The paper may benefit from a more in-depth analysis of the limitations and potential challenges of applying the proposed framework to real-world scenarios.\\n2. The experimental evaluation could be strengthened by including a comparison with state-of-the-art methods on more challenging human-AI alignment tasks.\\n3. The paper assumes a high degree of familiarity with symbolic logic and probabilistic inference, which may limit its accessibility to a broader audience.\",\n  \"Questions\": \"1. How can the proposed framework"}
{"paper_id": "CpgWRFqxhD", "review": "{\n  \"Soundness\": 3,\n  \"Presentation\": 4,\n  \"Contribution\": 4,\n  \"Rating\": 8,\n  \"Confidence\": 5,\n  \"Strengths\": \"1. The paper presents a comprehensive approach to address the challenges in audio-driven talking video generation, proposing a novel memory-guided temporal module and emotion-aware audio module.\\n2. The model, MEMO, demonstrates superior performance in video quality and synchronization, and shows robustness in both standard and out-of-distribution datasets.\\n3. The paper includes a thorough evaluation and ablation studies to confirm the importance of its components.\",\n  \"Weaknesses\": \"1. The novelty of the memory-guided temporal module and emotion-aware audio module is not clearly established, as these concepts are not entirely new in the field of video generation.\\n2. The paper assumes a large dataset without facial inductive biases, which might not be feasible for all scenarios.\\n3. The model's generalizability to diverse audio inputs and reference images is not extensively explored.\",\n  \"Questions\": \"1. How does the memory-guided temporal module handle the trade-off between short-term and long-term dependencies in video generation?\\n2. Can the emotion-aware audio"}
